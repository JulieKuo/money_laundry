{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from torch import nn\n",
    "import torch.optim as optim\n",
    "import json, copy, pickle, torch\n",
    "from tqdm import tqdm\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## custinfo & ccba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "info_raw = pd.read_csv(\"data/inverse/info.csv\")\n",
    "ccba_raw = pd.read_csv(\"data/inverse/ccba.csv\")\n",
    "cdtx_raw = pd.read_csv(\"data/inverse/cdtx.csv\")\n",
    "dp_raw = pd.read_csv(\"data/inverse/dp.csv\")\n",
    "remit_raw = pd.read_csv(\"data/inverse/remit.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alert_key</th>\n",
       "      <th>date</th>\n",
       "      <th>sar_flag</th>\n",
       "      <th>cust_id</th>\n",
       "      <th>risk_rank</th>\n",
       "      <th>occupation_code</th>\n",
       "      <th>total_asset</th>\n",
       "      <th>AGE</th>\n",
       "      <th>lupay</th>\n",
       "      <th>cycam</th>\n",
       "      <th>usgam</th>\n",
       "      <th>clamt</th>\n",
       "      <th>csamt</th>\n",
       "      <th>inamt</th>\n",
       "      <th>cucsm</th>\n",
       "      <th>cucah</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>171142</td>\n",
       "      <td>2021-04-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>a39fea9aec90969fe66a2b2b4d1b86368a2d38e8b8d4bf...</td>\n",
       "      <td>3</td>\n",
       "      <td>12.0</td>\n",
       "      <td>241719.0</td>\n",
       "      <td>3</td>\n",
       "      <td>12565.0</td>\n",
       "      <td>150744.0</td>\n",
       "      <td>82748.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12477.0</td>\n",
       "      <td>12477.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>171152</td>\n",
       "      <td>2021-04-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7e42b5dca9b28ee8e5545beb834361e90e6197d176b389...</td>\n",
       "      <td>3</td>\n",
       "      <td>13.0</td>\n",
       "      <td>599497.0</td>\n",
       "      <td>6</td>\n",
       "      <td>3581.0</td>\n",
       "      <td>324783.0</td>\n",
       "      <td>64363.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4981.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>171177</td>\n",
       "      <td>2021-04-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>a6cdf6302aead77112013168c6d546d2df3bcb551956d2...</td>\n",
       "      <td>1</td>\n",
       "      <td>19.0</td>\n",
       "      <td>51160.0</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>171178</td>\n",
       "      <td>2021-04-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1a3efa69705f611c7ef2384a715c8142e2ee801cfec9df...</td>\n",
       "      <td>3</td>\n",
       "      <td>9.0</td>\n",
       "      <td>3634343.0</td>\n",
       "      <td>6</td>\n",
       "      <td>829364.0</td>\n",
       "      <td>7666339.0</td>\n",
       "      <td>2343836.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>781279.0</td>\n",
       "      <td>781279.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>171180</td>\n",
       "      <td>2021-04-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>67f8cbb64dd3d447e992b1b299e0ceed3372188e47c88e...</td>\n",
       "      <td>1</td>\n",
       "      <td>17.0</td>\n",
       "      <td>4076287.0</td>\n",
       "      <td>4</td>\n",
       "      <td>636.0</td>\n",
       "      <td>256134.0</td>\n",
       "      <td>3538.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3410.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   alert_key        date  sar_flag  \\\n",
       "0     171142  2021-04-01       0.0   \n",
       "1     171152  2021-04-01       0.0   \n",
       "2     171177  2021-04-01       0.0   \n",
       "3     171178  2021-04-01       0.0   \n",
       "4     171180  2021-04-01       0.0   \n",
       "\n",
       "                                             cust_id  risk_rank  \\\n",
       "0  a39fea9aec90969fe66a2b2b4d1b86368a2d38e8b8d4bf...          3   \n",
       "1  7e42b5dca9b28ee8e5545beb834361e90e6197d176b389...          3   \n",
       "2  a6cdf6302aead77112013168c6d546d2df3bcb551956d2...          1   \n",
       "3  1a3efa69705f611c7ef2384a715c8142e2ee801cfec9df...          3   \n",
       "4  67f8cbb64dd3d447e992b1b299e0ceed3372188e47c88e...          1   \n",
       "\n",
       "   occupation_code  total_asset  AGE     lupay      cycam      usgam  clamt  \\\n",
       "0             12.0     241719.0    3   12565.0   150744.0    82748.0    0.0   \n",
       "1             13.0     599497.0    6    3581.0   324783.0    64363.0    0.0   \n",
       "2             19.0      51160.0    4       NaN        NaN        NaN    NaN   \n",
       "3              9.0    3634343.0    6  829364.0  7666339.0  2343836.0    0.0   \n",
       "4             17.0    4076287.0    4     636.0   256134.0     3538.0    0.0   \n",
       "\n",
       "   csamt     inamt     cucsm  cucah  \n",
       "0    0.0   12477.0   12477.0    0.0  \n",
       "1    0.0       0.0    4981.0    0.0  \n",
       "2    NaN       NaN       NaN    NaN  \n",
       "3    0.0  781279.0  781279.0    0.0  \n",
       "4    0.0       0.0    3410.0    0.0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "info_raw[\"month\"] = info_raw[\"date\"].apply(lambda X: X[:7])\n",
    "ccba_raw[\"month\"] = ccba_raw[\"byymm\"].apply(lambda X: X[:7])\n",
    "info_raw = pd.merge(info_raw, ccba_raw, on = [\"cust_id\", \"month\"], how = \"left\")\n",
    "info_raw = info_raw.drop([\"month\", \"byymm\"], axis = 1)\n",
    "info_raw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alert_key</th>\n",
       "      <th>date</th>\n",
       "      <th>sar_flag</th>\n",
       "      <th>cust_id</th>\n",
       "      <th>risk_rank</th>\n",
       "      <th>occupation_code</th>\n",
       "      <th>total_asset</th>\n",
       "      <th>AGE</th>\n",
       "      <th>lupay</th>\n",
       "      <th>cycam</th>\n",
       "      <th>usgam</th>\n",
       "      <th>clamt</th>\n",
       "      <th>csamt</th>\n",
       "      <th>inamt</th>\n",
       "      <th>cucsm</th>\n",
       "      <th>cucah</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>171142</td>\n",
       "      <td>2021-04-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>a39fea9aec90969fe66a2b2b4d1b86368a2d38e8b8d4bf...</td>\n",
       "      <td>3</td>\n",
       "      <td>12.0</td>\n",
       "      <td>241719.0</td>\n",
       "      <td>3</td>\n",
       "      <td>12565.0</td>\n",
       "      <td>150744.0</td>\n",
       "      <td>82748.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12477.0</td>\n",
       "      <td>12477.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>171152</td>\n",
       "      <td>2021-04-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7e42b5dca9b28ee8e5545beb834361e90e6197d176b389...</td>\n",
       "      <td>3</td>\n",
       "      <td>13.0</td>\n",
       "      <td>599497.0</td>\n",
       "      <td>6</td>\n",
       "      <td>3581.0</td>\n",
       "      <td>324783.0</td>\n",
       "      <td>64363.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4981.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>171177</td>\n",
       "      <td>2021-04-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>a6cdf6302aead77112013168c6d546d2df3bcb551956d2...</td>\n",
       "      <td>1</td>\n",
       "      <td>19.0</td>\n",
       "      <td>51160.0</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>171178</td>\n",
       "      <td>2021-04-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1a3efa69705f611c7ef2384a715c8142e2ee801cfec9df...</td>\n",
       "      <td>3</td>\n",
       "      <td>9.0</td>\n",
       "      <td>3634343.0</td>\n",
       "      <td>6</td>\n",
       "      <td>829364.0</td>\n",
       "      <td>7666339.0</td>\n",
       "      <td>2343836.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>781279.0</td>\n",
       "      <td>781279.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>171180</td>\n",
       "      <td>2021-04-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>67f8cbb64dd3d447e992b1b299e0ceed3372188e47c88e...</td>\n",
       "      <td>1</td>\n",
       "      <td>17.0</td>\n",
       "      <td>4076287.0</td>\n",
       "      <td>4</td>\n",
       "      <td>636.0</td>\n",
       "      <td>256134.0</td>\n",
       "      <td>3538.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3410.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25746</th>\n",
       "      <td>365001</td>\n",
       "      <td>2022-04-29</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18ee644a371548e9780d701aaa7e0c8c42a7794cdee755...</td>\n",
       "      <td>1</td>\n",
       "      <td>17.0</td>\n",
       "      <td>135072.0</td>\n",
       "      <td>3</td>\n",
       "      <td>7918.0</td>\n",
       "      <td>313340.0</td>\n",
       "      <td>58134.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25747</th>\n",
       "      <td>365004</td>\n",
       "      <td>2022-04-29</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7f69fa9eab8f397d367e2bb61ee1fa008999a0aab91e06...</td>\n",
       "      <td>3</td>\n",
       "      <td>12.0</td>\n",
       "      <td>2285386.0</td>\n",
       "      <td>3</td>\n",
       "      <td>284394.0</td>\n",
       "      <td>342995.0</td>\n",
       "      <td>79765.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>97941.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25748</th>\n",
       "      <td>365008</td>\n",
       "      <td>2022-04-29</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12c9e6d35500d2a96fc2b22a9da8e3deb6048de515a16e...</td>\n",
       "      <td>3</td>\n",
       "      <td>19.0</td>\n",
       "      <td>1230244.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>120106.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25749</th>\n",
       "      <td>365009</td>\n",
       "      <td>2022-04-29</td>\n",
       "      <td>NaN</td>\n",
       "      <td>d24d46c19002ab1f9a02801af5e4be6a154b3c5adc0417...</td>\n",
       "      <td>1</td>\n",
       "      <td>17.0</td>\n",
       "      <td>162418.0</td>\n",
       "      <td>2</td>\n",
       "      <td>843074.0</td>\n",
       "      <td>31322.0</td>\n",
       "      <td>16124.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>817962.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25750</th>\n",
       "      <td>365073</td>\n",
       "      <td>2022-04-29</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7224e3a067b5e90c9b2a5bdbcfe81884505ab44f0566ae...</td>\n",
       "      <td>3</td>\n",
       "      <td>19.0</td>\n",
       "      <td>83133.0</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25635 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       alert_key        date  sar_flag  \\\n",
       "0         171142  2021-04-01       0.0   \n",
       "1         171152  2021-04-01       0.0   \n",
       "2         171177  2021-04-01       0.0   \n",
       "3         171178  2021-04-01       0.0   \n",
       "4         171180  2021-04-01       0.0   \n",
       "...          ...         ...       ...   \n",
       "25746     365001  2022-04-29       NaN   \n",
       "25747     365004  2022-04-29       NaN   \n",
       "25748     365008  2022-04-29       NaN   \n",
       "25749     365009  2022-04-29       NaN   \n",
       "25750     365073  2022-04-29       NaN   \n",
       "\n",
       "                                                 cust_id  risk_rank  \\\n",
       "0      a39fea9aec90969fe66a2b2b4d1b86368a2d38e8b8d4bf...          3   \n",
       "1      7e42b5dca9b28ee8e5545beb834361e90e6197d176b389...          3   \n",
       "2      a6cdf6302aead77112013168c6d546d2df3bcb551956d2...          1   \n",
       "3      1a3efa69705f611c7ef2384a715c8142e2ee801cfec9df...          3   \n",
       "4      67f8cbb64dd3d447e992b1b299e0ceed3372188e47c88e...          1   \n",
       "...                                                  ...        ...   \n",
       "25746  18ee644a371548e9780d701aaa7e0c8c42a7794cdee755...          1   \n",
       "25747  7f69fa9eab8f397d367e2bb61ee1fa008999a0aab91e06...          3   \n",
       "25748  12c9e6d35500d2a96fc2b22a9da8e3deb6048de515a16e...          3   \n",
       "25749  d24d46c19002ab1f9a02801af5e4be6a154b3c5adc0417...          1   \n",
       "25750  7224e3a067b5e90c9b2a5bdbcfe81884505ab44f0566ae...          3   \n",
       "\n",
       "       occupation_code  total_asset  AGE     lupay      cycam      usgam  \\\n",
       "0                 12.0     241719.0    3   12565.0   150744.0    82748.0   \n",
       "1                 13.0     599497.0    6    3581.0   324783.0    64363.0   \n",
       "2                 19.0      51160.0    4       NaN        NaN        NaN   \n",
       "3                  9.0    3634343.0    6  829364.0  7666339.0  2343836.0   \n",
       "4                 17.0    4076287.0    4     636.0   256134.0     3538.0   \n",
       "...                ...          ...  ...       ...        ...        ...   \n",
       "25746             17.0     135072.0    3    7918.0   313340.0    58134.0   \n",
       "25747             12.0    2285386.0    3  284394.0   342995.0    79765.0   \n",
       "25748             19.0    1230244.0    2       0.0   120106.0        0.0   \n",
       "25749             17.0     162418.0    2  843074.0    31322.0    16124.0   \n",
       "25750             19.0      83133.0    3       NaN        NaN        NaN   \n",
       "\n",
       "       clamt  csamt     inamt     cucsm  cucah  \n",
       "0        0.0    0.0   12477.0   12477.0    0.0  \n",
       "1        0.0    0.0       0.0    4981.0    0.0  \n",
       "2        NaN    NaN       NaN       NaN    NaN  \n",
       "3        0.0    0.0  781279.0  781279.0    0.0  \n",
       "4        0.0    0.0       0.0    3410.0    0.0  \n",
       "...      ...    ...       ...       ...    ...  \n",
       "25746    0.0    0.0       0.0       0.0    0.0  \n",
       "25747    0.0    0.0       0.0   97941.0    0.0  \n",
       "25748    0.0    0.0       0.0       0.0    0.0  \n",
       "25749    0.0    0.0       0.0  817962.0    0.0  \n",
       "25750    NaN    NaN       NaN       NaN    NaN  \n",
       "\n",
       "[25635 rows x 16 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "info_raw = info_raw[~info_raw[\"occupation_code\"].isnull()]\n",
    "info_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = info_raw.drop(\"sar_flag\", axis = 1)\n",
    "y = info_raw[\"sar_flag\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cyclical_feat_encode(df):\n",
    "    df[\"date\"] = pd.to_datetime(df[\"date\"])\n",
    "\n",
    "    df['month'] = df[\"date\"].dt.month\n",
    "    df['day'] = df[\"date\"].dt.day\n",
    "\n",
    "    df['month_sin'] = np.sin(2 * np.pi *  df['month']/ df[\"month\"].max())\n",
    "    df['month_cos'] = np.cos(2 * np.pi * df['month'] / df[\"month\"].max())\n",
    "\n",
    "    df['day_sin'] = np.sin(2 * np.pi * df['day'] / df[\"day\"].max())\n",
    "    df['day_cos'] = np.cos(2 * np.pi * df['day'] / df[\"day\"].max())\n",
    "\n",
    "    df = df.drop([\"month\", \"day\", \"date\"], axis = 1)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alert_key</th>\n",
       "      <th>cust_id</th>\n",
       "      <th>risk_rank</th>\n",
       "      <th>occupation_code</th>\n",
       "      <th>total_asset</th>\n",
       "      <th>AGE</th>\n",
       "      <th>lupay</th>\n",
       "      <th>cycam</th>\n",
       "      <th>usgam</th>\n",
       "      <th>clamt</th>\n",
       "      <th>csamt</th>\n",
       "      <th>inamt</th>\n",
       "      <th>cucsm</th>\n",
       "      <th>cucah</th>\n",
       "      <th>month_sin</th>\n",
       "      <th>month_cos</th>\n",
       "      <th>day_sin</th>\n",
       "      <th>day_cos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>171142</td>\n",
       "      <td>a39fea9aec90969fe66a2b2b4d1b86368a2d38e8b8d4bf...</td>\n",
       "      <td>3</td>\n",
       "      <td>12.0</td>\n",
       "      <td>241719.0</td>\n",
       "      <td>3</td>\n",
       "      <td>12565.0</td>\n",
       "      <td>150744.0</td>\n",
       "      <td>82748.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12477.0</td>\n",
       "      <td>12477.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>0.201299</td>\n",
       "      <td>0.97953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>171152</td>\n",
       "      <td>7e42b5dca9b28ee8e5545beb834361e90e6197d176b389...</td>\n",
       "      <td>3</td>\n",
       "      <td>13.0</td>\n",
       "      <td>599497.0</td>\n",
       "      <td>6</td>\n",
       "      <td>3581.0</td>\n",
       "      <td>324783.0</td>\n",
       "      <td>64363.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4981.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>0.201299</td>\n",
       "      <td>0.97953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>171177</td>\n",
       "      <td>a6cdf6302aead77112013168c6d546d2df3bcb551956d2...</td>\n",
       "      <td>1</td>\n",
       "      <td>19.0</td>\n",
       "      <td>51160.0</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>0.201299</td>\n",
       "      <td>0.97953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>171178</td>\n",
       "      <td>1a3efa69705f611c7ef2384a715c8142e2ee801cfec9df...</td>\n",
       "      <td>3</td>\n",
       "      <td>9.0</td>\n",
       "      <td>3634343.0</td>\n",
       "      <td>6</td>\n",
       "      <td>829364.0</td>\n",
       "      <td>7666339.0</td>\n",
       "      <td>2343836.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>781279.0</td>\n",
       "      <td>781279.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>0.201299</td>\n",
       "      <td>0.97953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>171180</td>\n",
       "      <td>67f8cbb64dd3d447e992b1b299e0ceed3372188e47c88e...</td>\n",
       "      <td>1</td>\n",
       "      <td>17.0</td>\n",
       "      <td>4076287.0</td>\n",
       "      <td>4</td>\n",
       "      <td>636.0</td>\n",
       "      <td>256134.0</td>\n",
       "      <td>3538.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3410.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>0.201299</td>\n",
       "      <td>0.97953</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   alert_key                                            cust_id  risk_rank  \\\n",
       "0     171142  a39fea9aec90969fe66a2b2b4d1b86368a2d38e8b8d4bf...          3   \n",
       "1     171152  7e42b5dca9b28ee8e5545beb834361e90e6197d176b389...          3   \n",
       "2     171177  a6cdf6302aead77112013168c6d546d2df3bcb551956d2...          1   \n",
       "3     171178  1a3efa69705f611c7ef2384a715c8142e2ee801cfec9df...          3   \n",
       "4     171180  67f8cbb64dd3d447e992b1b299e0ceed3372188e47c88e...          1   \n",
       "\n",
       "   occupation_code  total_asset  AGE     lupay      cycam      usgam  clamt  \\\n",
       "0             12.0     241719.0    3   12565.0   150744.0    82748.0    0.0   \n",
       "1             13.0     599497.0    6    3581.0   324783.0    64363.0    0.0   \n",
       "2             19.0      51160.0    4       NaN        NaN        NaN    NaN   \n",
       "3              9.0    3634343.0    6  829364.0  7666339.0  2343836.0    0.0   \n",
       "4             17.0    4076287.0    4     636.0   256134.0     3538.0    0.0   \n",
       "\n",
       "   csamt     inamt     cucsm  cucah  month_sin  month_cos   day_sin  day_cos  \n",
       "0    0.0   12477.0   12477.0    0.0   0.866025       -0.5  0.201299  0.97953  \n",
       "1    0.0       0.0    4981.0    0.0   0.866025       -0.5  0.201299  0.97953  \n",
       "2    NaN       NaN       NaN    NaN   0.866025       -0.5  0.201299  0.97953  \n",
       "3    0.0  781279.0  781279.0    0.0   0.866025       -0.5  0.201299  0.97953  \n",
       "4    0.0       0.0    3410.0    0.0   0.866025       -0.5  0.201299  0.97953  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = cyclical_feat_encode(X)\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alert_key</th>\n",
       "      <th>cust_id</th>\n",
       "      <th>risk_rank</th>\n",
       "      <th>occupation_code</th>\n",
       "      <th>total_asset</th>\n",
       "      <th>AGE</th>\n",
       "      <th>lupay</th>\n",
       "      <th>cycam</th>\n",
       "      <th>usgam</th>\n",
       "      <th>clamt</th>\n",
       "      <th>csamt</th>\n",
       "      <th>inamt</th>\n",
       "      <th>cucsm</th>\n",
       "      <th>cucah</th>\n",
       "      <th>month_sin</th>\n",
       "      <th>month_cos</th>\n",
       "      <th>day_sin</th>\n",
       "      <th>day_cos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>171142</td>\n",
       "      <td>4927</td>\n",
       "      <td>3</td>\n",
       "      <td>12.0</td>\n",
       "      <td>241719.0</td>\n",
       "      <td>3</td>\n",
       "      <td>12565.0</td>\n",
       "      <td>150744.0</td>\n",
       "      <td>82748.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12477.0</td>\n",
       "      <td>12477.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>0.201299</td>\n",
       "      <td>0.97953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>171152</td>\n",
       "      <td>3745</td>\n",
       "      <td>3</td>\n",
       "      <td>13.0</td>\n",
       "      <td>599497.0</td>\n",
       "      <td>6</td>\n",
       "      <td>3581.0</td>\n",
       "      <td>324783.0</td>\n",
       "      <td>64363.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4981.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>0.201299</td>\n",
       "      <td>0.97953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>171177</td>\n",
       "      <td>5017</td>\n",
       "      <td>1</td>\n",
       "      <td>19.0</td>\n",
       "      <td>51160.0</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>0.201299</td>\n",
       "      <td>0.97953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>171178</td>\n",
       "      <td>786</td>\n",
       "      <td>3</td>\n",
       "      <td>9.0</td>\n",
       "      <td>3634343.0</td>\n",
       "      <td>6</td>\n",
       "      <td>829364.0</td>\n",
       "      <td>7666339.0</td>\n",
       "      <td>2343836.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>781279.0</td>\n",
       "      <td>781279.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>0.201299</td>\n",
       "      <td>0.97953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>171180</td>\n",
       "      <td>3057</td>\n",
       "      <td>1</td>\n",
       "      <td>17.0</td>\n",
       "      <td>4076287.0</td>\n",
       "      <td>4</td>\n",
       "      <td>636.0</td>\n",
       "      <td>256134.0</td>\n",
       "      <td>3538.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3410.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>0.201299</td>\n",
       "      <td>0.97953</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   alert_key  cust_id  risk_rank  occupation_code  total_asset  AGE     lupay  \\\n",
       "0     171142     4927          3             12.0     241719.0    3   12565.0   \n",
       "1     171152     3745          3             13.0     599497.0    6    3581.0   \n",
       "2     171177     5017          1             19.0      51160.0    4       NaN   \n",
       "3     171178      786          3              9.0    3634343.0    6  829364.0   \n",
       "4     171180     3057          1             17.0    4076287.0    4     636.0   \n",
       "\n",
       "       cycam      usgam  clamt  csamt     inamt     cucsm  cucah  month_sin  \\\n",
       "0   150744.0    82748.0    0.0    0.0   12477.0   12477.0    0.0   0.866025   \n",
       "1   324783.0    64363.0    0.0    0.0       0.0    4981.0    0.0   0.866025   \n",
       "2        NaN        NaN    NaN    NaN       NaN       NaN    NaN   0.866025   \n",
       "3  7666339.0  2343836.0    0.0    0.0  781279.0  781279.0    0.0   0.866025   \n",
       "4   256134.0     3538.0    0.0    0.0       0.0    3410.0    0.0   0.866025   \n",
       "\n",
       "   month_cos   day_sin  day_cos  \n",
       "0       -0.5  0.201299  0.97953  \n",
       "1       -0.5  0.201299  0.97953  \n",
       "2       -0.5  0.201299  0.97953  \n",
       "3       -0.5  0.201299  0.97953  \n",
       "4       -0.5  0.201299  0.97953  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "le = preprocessing.LabelEncoder()\n",
    "X[\"cust_id\"] = le.fit_transform(X[\"cust_id\"])\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "alert_key = X.pop(\"alert_key\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X.iloc[:-1845]\n",
    "X_test = X.iloc[-1845:]\n",
    "y_train = y.iloc[:-1845]\n",
    "y_test = y.iloc[-1845:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cust_id</th>\n",
       "      <th>risk_rank</th>\n",
       "      <th>occupation_code</th>\n",
       "      <th>total_asset</th>\n",
       "      <th>AGE</th>\n",
       "      <th>lupay</th>\n",
       "      <th>cycam</th>\n",
       "      <th>usgam</th>\n",
       "      <th>clamt</th>\n",
       "      <th>csamt</th>\n",
       "      <th>inamt</th>\n",
       "      <th>cucsm</th>\n",
       "      <th>cucah</th>\n",
       "      <th>month_sin</th>\n",
       "      <th>month_cos</th>\n",
       "      <th>day_sin</th>\n",
       "      <th>day_cos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.002141</td>\n",
       "      <td>0.007585</td>\n",
       "      <td>241719.0</td>\n",
       "      <td>0.011447</td>\n",
       "      <td>12565.0</td>\n",
       "      <td>150744.0</td>\n",
       "      <td>82748.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12477.0</td>\n",
       "      <td>12477.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>0.201299</td>\n",
       "      <td>0.97953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.642763e-07</td>\n",
       "      <td>0.002141</td>\n",
       "      <td>0.016930</td>\n",
       "      <td>599497.0</td>\n",
       "      <td>0.005569</td>\n",
       "      <td>3581.0</td>\n",
       "      <td>324783.0</td>\n",
       "      <td>64363.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4981.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>0.201299</td>\n",
       "      <td>0.97953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.645325e-03</td>\n",
       "      <td>0.012996</td>\n",
       "      <td>0.009420</td>\n",
       "      <td>51160.0</td>\n",
       "      <td>0.008417</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>0.201299</td>\n",
       "      <td>0.97953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.385270e-16</td>\n",
       "      <td>0.002141</td>\n",
       "      <td>0.005630</td>\n",
       "      <td>3634343.0</td>\n",
       "      <td>0.005569</td>\n",
       "      <td>829364.0</td>\n",
       "      <td>7666339.0</td>\n",
       "      <td>2343836.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>781279.0</td>\n",
       "      <td>781279.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>0.201299</td>\n",
       "      <td>0.97953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8.178964e-09</td>\n",
       "      <td>0.012996</td>\n",
       "      <td>0.010621</td>\n",
       "      <td>4076287.0</td>\n",
       "      <td>0.008417</td>\n",
       "      <td>636.0</td>\n",
       "      <td>256134.0</td>\n",
       "      <td>3538.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3410.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>0.201299</td>\n",
       "      <td>0.97953</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        cust_id  risk_rank  occupation_code  total_asset       AGE     lupay  \\\n",
       "0  0.000000e+00   0.002141         0.007585     241719.0  0.011447   12565.0   \n",
       "1  1.642763e-07   0.002141         0.016930     599497.0  0.005569    3581.0   \n",
       "2  2.645325e-03   0.012996         0.009420      51160.0  0.008417       NaN   \n",
       "3  3.385270e-16   0.002141         0.005630    3634343.0  0.005569  829364.0   \n",
       "4  8.178964e-09   0.012996         0.010621    4076287.0  0.008417     636.0   \n",
       "\n",
       "       cycam      usgam  clamt  csamt     inamt     cucsm  cucah  month_sin  \\\n",
       "0   150744.0    82748.0    0.0    0.0   12477.0   12477.0    0.0   0.866025   \n",
       "1   324783.0    64363.0    0.0    0.0       0.0    4981.0    0.0   0.866025   \n",
       "2        NaN        NaN    NaN    NaN       NaN       NaN    NaN   0.866025   \n",
       "3  7666339.0  2343836.0    0.0    0.0  781279.0  781279.0    0.0   0.866025   \n",
       "4   256134.0     3538.0    0.0    0.0       0.0    3410.0    0.0   0.866025   \n",
       "\n",
       "   month_cos   day_sin  day_cos  \n",
       "0       -0.5  0.201299  0.97953  \n",
       "1       -0.5  0.201299  0.97953  \n",
       "2       -0.5  0.201299  0.97953  \n",
       "3       -0.5  0.201299  0.97953  \n",
       "4       -0.5  0.201299  0.97953  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import category_encoders as ce\n",
    "\n",
    "cat_feat = [\"cust_id\", \"risk_rank\", \"occupation_code\", \"AGE\"]\n",
    "ce_target = ce.TargetEncoder(cols = cat_feat)\n",
    "X_train = ce_target.fit_transform(X_train, y_train)\n",
    "X_test = ce_target.transform(X_test)\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import KNNImputer\n",
    "\n",
    "imputer = KNNImputer()\n",
    "X_train1 = imputer.fit_transform(X_train)\n",
    "X_train = pd.DataFrame(X_train1, columns = imputer.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test1 = imputer.transform(X_test)\n",
    "X_test = pd.DataFrame(X_test1, columns = imputer.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "sar1_idx = (y_train == 1).tolist()\n",
    "sar0_idx = (y_train == 0).tolist()\n",
    "\n",
    "X_train1 = X_train[sar1_idx]\n",
    "X_train0 = X_train[sar0_idx]\n",
    "y_train1 = y_train[sar1_idx]\n",
    "y_train0 = y_train[sar0_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>OneClassSVM()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">OneClassSVM</label><div class=\"sk-toggleable__content\"><pre>OneClassSVM()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "OneClassSVM()"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "clf = svm.OneClassSVM()\n",
    "clf.fit(X_train0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "outlier = clf.predict(X_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(234, 234, 234)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(outlier), len(X_train1), len(y_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1, -1,  1, -1,  1,  1, -1, -1, -1,  1,  1, -1,  1,  1, -1,  1,  1,\n",
       "       -1, -1,  1,  1, -1,  1, -1,  1,  1, -1,  1,  1,  1, -1,  1,  1,  1,\n",
       "        1, -1, -1,  1,  1, -1,  1, -1, -1,  1,  1,  1,  1,  1, -1, -1,  1,\n",
       "       -1,  1,  1, -1, -1, -1, -1, -1,  1, -1,  1, -1,  1,  1, -1,  1,  1,\n",
       "       -1,  1, -1,  1, -1, -1,  1,  1,  1,  1,  1, -1,  1, -1, -1, -1,  1,\n",
       "       -1,  1,  1,  1,  1, -1,  1, -1,  1, -1, -1, -1, -1,  1,  1, -1,  1,\n",
       "        1,  1,  1,  1, -1, -1,  1,  1,  1,  1,  1,  1,  1, -1,  1,  1,  1,\n",
       "        1,  1,  1,  1,  1, -1, -1,  1, -1,  1, -1, -1,  1,  1, -1, -1,  1,\n",
       "        1, -1, -1,  1, -1,  1,  1,  1,  1, -1,  1,  1, -1, -1,  1, -1, -1,\n",
       "        1, -1,  1,  1,  1,  1, -1,  1,  1,  1, -1,  1, -1,  1,  1, -1,  1,\n",
       "        1, -1, -1, -1, -1, -1,  1,  1,  1, -1, -1,  1,  1,  1, -1,  1, -1,\n",
       "       -1, -1,  1,  1, -1,  1, -1,  1,  1,  1, -1,  1,  1,  1,  1, -1,  1,\n",
       "       -1,  1, -1, -1,  1,  1,  1,  1,  1,  1, -1,  1,  1, -1,  1, -1, -1,\n",
       "        1, -1, -1, -1, -1,  1,  1, -1, -1,  1,  1, -1,  1], dtype=int64)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outlier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1: 136\n",
      "-1: 98\n"
     ]
    }
   ],
   "source": [
    "print(\"1:\", (outlier == 1).sum())\n",
    "print(\"-1:\", (outlier == -1).sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from torch import nn\n",
    "import torch.optim as optim\n",
    "import json, copy, pickle, torch\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pickle.load(open('data/inverse/cust_id2.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_process(data, mode = \"train\"):\n",
    "    data_X = []\n",
    "    data_Y = []\n",
    "    for k1, v1 in data.items():\n",
    "        for k2, v2 in v1.items():\n",
    "            # 判斷要抓的是train data還是test data\n",
    "            if mode == \"train\":\n",
    "                if v2[\"data_type\"] == \"test\":\n",
    "                    continue\n",
    "            else:\n",
    "                if v2[\"data_type\"] == \"train\":\n",
    "                    continue\n",
    "            \n",
    "            idx = [[] for _ in range(4)]\n",
    "            data2 = [[] for _ in range(4)]\n",
    "\n",
    "            max_idx = len(v2[\"data\"]) - 1\n",
    "\n",
    "            for i, trade in enumerate(v2[\"data\"]):\n",
    "                source = trade[\"source\"]\n",
    "                trade1 = {k: v for k, v in trade.items() if k not in [\"date\", \"source\", \"alert_key\"]} #刪除日期跟資料來源\n",
    "\n",
    "                if i == max_idx:\n",
    "                    data_Y.append(trade[\"sar_flag\"])\n",
    "                    trade1[\"sar_flag\"] = 2\n",
    "                \n",
    "\n",
    "                idx[source].append(i)\n",
    "                data2[source].append(list(trade1.values()))\n",
    "\n",
    "            data_X.append([idx, data2, trade[\"alert_key\"]])\n",
    "\n",
    "\n",
    "    # train - X shape = (總樣本數(23906), 該樣本下的交易index、內容和alert_key(3), 資料源(4), 數據)\n",
    "    print(f\"Mode: {mode}, Total sample: {len(data_X)}\")\n",
    "\n",
    "    return data_X, data_Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mode: train, Total sample: 23906\n",
      "Mode: test, Total sample: 1845\n"
     ]
    }
   ],
   "source": [
    "X_train, y_train = data_process(data, mode = \"train\")\n",
    "X_test, y_test = data_process(data, mode = \"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train - 0: 234, 1: 23672, total: 23906, 0/1: 101\n"
     ]
    }
   ],
   "source": [
    "sar1 = sum(y_train)\n",
    "sar0 = len(y_train) - sum(y_train)\n",
    "total = len(y_train)\n",
    "\n",
    "print(f\"train - 0: {sar1}, 1: {sar0}, total: {total}, 0/1: {round(sar0/sar1)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train, y_train, test_size = 0.2, shuffle = True, stratify = y_train, random_state = 99)\n",
    "print(f\"X_train: {len(X_train)}, X_valid: {len(X_valid)}, X_test: {len(X_test)}\\ny_train: {len(y_train)}, y_valid: {len(y_valid)}, y_test: {len(y_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "print(f\"train - 0: {len(y_train) - sum(y_train)}, 1: {sum(y_train)}, total: {len(y_train)}\")\n",
    "print(f\"valid - 0: {len(y_valid) - sum(y_valid)}, 1: {sum(y_valid)}, total: {len(y_valid)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "\n",
    "del data\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, Dataset\n",
    "class Dataset_transform(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.n_samples = len(y)\n",
    "        self.X = X\n",
    "        self.y = torch.tensor(y).float().reshape(-1, 1)\n",
    "                                            \n",
    "    def __len__(self):\n",
    "        return self.n_samples\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        seq_idx = self.X[idx][0]\n",
    "        x1 = self.X[idx][1]\n",
    "        alert_key = self.X[idx][2]\n",
    "        y1 = self.y[idx]\n",
    "\n",
    "\n",
    "        return [torch.tensor(s).long() for s in seq_idx], [torch.tensor(x2) for x2 in x1], y1, alert_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = Dataset_transform(X_train, y_train)\n",
    "# valid_dataset = Dataset_transform(X_valid, y_valid)\n",
    "test_dataset = Dataset_transform(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def BatchCollate(data):\n",
    "    batch_idxs = [torch.tensor([], dtype = torch.long) for i in range(4)]\n",
    "    seq_idxs = [torch.tensor([], dtype = torch.long) for i in range(4)]\n",
    "    xs = [torch.tensor([]) for i in range(4)]\n",
    "    targets = torch.tensor([])\n",
    "    alert_keys = []\n",
    "\n",
    "    for batch, d in enumerate(data):\n",
    "        for i in range(4):\n",
    "            seq_idxs[i] = torch.cat((seq_idxs[i], d[0][i]))\n",
    "            xs[i] = torch.cat((xs[i], d[1][i]))\n",
    "            \n",
    "            batch1 = torch.tensor([batch] * len(d[0][i])).long()\n",
    "            batch_idxs[i] = torch.cat((batch_idxs[i], batch1))\n",
    "\n",
    "        targets = torch.cat((targets, d[2]))\n",
    "        alert_keys.append(d[3])\n",
    "\n",
    "\n",
    "    return [batch_idxs, seq_idxs, xs], targets.reshape(-1, 1), alert_keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "train_dataloader = DataLoader(train_dataset, batch_size = batch_size, shuffle = True, collate_fn = BatchCollate)\n",
    "# valid_dataloader = DataLoader(valid_dataset, batch_size = len(valid_dataset), collate_fn = BatchCollate)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size = len(test_dataset), collate_fn = BatchCollate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"feats_type.json\", newline='') as file:\n",
    "    feats_type = json.load(file)\n",
    "\n",
    "with open(\"category_num.json\", newline='') as file:\n",
    "    category_num = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    \"\"\"\n",
    "    src: https://github.com/baosenguo/Kaggle-MoA-2nd-Place-Solution/blob/main/training/1d-cnn-train.ipynb\n",
    "    \"\"\"\n",
    "    def __init__(self, num_features, embed_output=128, hidden_size=512, dropout=0.3):\n",
    "        super().__init__()\n",
    "        cha_1 = 64\n",
    "        cha_2 = 128\n",
    "        cha_3 = 128\n",
    "\n",
    "        cha_1_reshape = int(hidden_size/cha_1)\n",
    "        cha_po_1 = int(hidden_size/cha_1/2)\n",
    "        cha_po_2 = int(hidden_size/cha_1/2/2) * cha_3\n",
    "\n",
    "        self.cha_1 = cha_1\n",
    "        self.cha_2 = cha_2\n",
    "        self.cha_3 = cha_3\n",
    "        self.cha_1_reshape = cha_1_reshape\n",
    "        self.cha_po_1 = cha_po_1\n",
    "        self.cha_po_2 = cha_po_2\n",
    "\n",
    "        self.batch_norm1 = nn.BatchNorm1d(num_features)\n",
    "        self.dropout1 = nn.Dropout(dropout)\n",
    "        self.dense1 = nn.utils.weight_norm(nn.Linear(num_features, hidden_size))\n",
    "\n",
    "        self.batch_norm_c1 = nn.BatchNorm1d(cha_1)\n",
    "        self.dropout_c1 = nn.Dropout(dropout*0.9)\n",
    "        self.conv1 = nn.utils.weight_norm(nn.Conv1d(cha_1,cha_2, kernel_size = 5, stride = 1, padding=2,  bias=False),dim=None)\n",
    "\n",
    "        self.ave_po_c1 = nn.AdaptiveAvgPool1d(output_size = cha_po_1)\n",
    "\n",
    "        self.batch_norm_c2 = nn.BatchNorm1d(cha_2)\n",
    "        self.dropout_c2 = nn.Dropout(dropout*0.8)\n",
    "        self.conv2 = nn.utils.weight_norm(nn.Conv1d(cha_2,cha_2, kernel_size = 3, stride = 1, padding=1, bias=True),dim=None)\n",
    "\n",
    "        self.batch_norm_c2_1 = nn.BatchNorm1d(cha_2)\n",
    "        self.dropout_c2_1 = nn.Dropout(dropout*0.6)\n",
    "        self.conv2_1 = nn.utils.weight_norm(nn.Conv1d(cha_2,cha_2, kernel_size = 3, stride = 1, padding=1, bias=True),dim=None)\n",
    "\n",
    "        self.batch_norm_c2_2 = nn.BatchNorm1d(cha_2)\n",
    "        self.dropout_c2_2 = nn.Dropout(dropout*0.5)\n",
    "        self.conv2_2 = nn.utils.weight_norm(nn.Conv1d(cha_2,cha_3, kernel_size = 5, stride = 1, padding=2, bias=True),dim=None)\n",
    "\n",
    "        self.max_po_c2 = nn.MaxPool1d(kernel_size=4, stride=2, padding=1)\n",
    "\n",
    "        self.flt = nn.Flatten()\n",
    "        \n",
    "        self.batch_norm3 = nn.BatchNorm1d(cha_po_2)\n",
    "        self.dropout3 = nn.Dropout(dropout)\n",
    "        self.dense3 = nn.utils.weight_norm(nn.Linear(cha_po_2, embed_output))\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        x = self.batch_norm1(x)\n",
    "        x = self.dropout1(x)\n",
    "        x = F.celu(self.dense1(x), alpha=0.06)\n",
    "\n",
    "        x = x.reshape(x.shape[0],self.cha_1,\n",
    "                        self.cha_1_reshape)\n",
    "\n",
    "        x = self.batch_norm_c1(x)\n",
    "        x = self.dropout_c1(x)\n",
    "        x = F.relu(self.conv1(x))\n",
    "\n",
    "        x = self.ave_po_c1(x)\n",
    "\n",
    "        x = self.batch_norm_c2(x)\n",
    "        x = self.dropout_c2(x)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x_s = x\n",
    "\n",
    "        x = self.batch_norm_c2_1(x)\n",
    "        x = self.dropout_c2_1(x)\n",
    "        x = F.relu(self.conv2_1(x))\n",
    "\n",
    "        x = self.batch_norm_c2_2(x)\n",
    "        x = self.dropout_c2_2(x)\n",
    "        x = F.relu(self.conv2_2(x))\n",
    "        x =  x * x_s\n",
    "\n",
    "        x = self.max_po_c2(x)\n",
    "\n",
    "        x = self.flt(x)\n",
    "\n",
    "        x = self.batch_norm3(x)\n",
    "        x = self.dropout3(x)\n",
    "        x = self.dense3(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from traceback import format_exc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeatureEmbedder(torch.nn.Module):\n",
    "    def __init__(self, feat_type, category_num, embed_dim = 4, embed_output = 32, hidden_size = 256, dropout = 0.3):\n",
    "        super().__init__()\n",
    "\n",
    "        feat_type = {k: v for k, v in feat_type.items() if v in [\"category\", \"int\", \"float\"]}\n",
    "\n",
    "        layers = []\n",
    "        for k, v in feat_type.items():\n",
    "            if v == \"category\":\n",
    "                layers.append(nn.Embedding(category_num[k], embed_dim))\n",
    "            else:\n",
    "                layers.append(nn.Linear(1, embed_dim))\n",
    "        self.embeddings = torch.nn.ModuleList(layers)\n",
    "\n",
    "        self.encoder = Encoder(\n",
    "            num_features = len(feat_type) * embed_dim, \n",
    "            embed_output = embed_output, \n",
    "            hidden_size = hidden_size,\n",
    "            dropout = dropout\n",
    "        )\n",
    "\n",
    "        self.feat_type = feat_type\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # 透過embedding把每個feature的數據轉成(embed_dim)維的向量\n",
    "        embs = []\n",
    "        \n",
    "        for i, (type_, emb_layer) in enumerate(zip(self.feat_type.values(), self.embeddings)):\n",
    "            if type_ == \"category\": # 類別變數\n",
    "                x1 = emb_layer(x[:, i].long())\n",
    "            else: # 連續變數\n",
    "                x1 = emb_layer(x[:, i].reshape(-1, 1))\n",
    "            \n",
    "            embs.append(x1)\n",
    "        \n",
    "        \n",
    "        embs = torch.cat(embs, dim=1)# 把所有feature的向量合併\n",
    "        embs = self.encoder(embs) # 透過encoder轉換，統一輸出維度(embed_output)\n",
    "            \n",
    "        return embs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_dim = 4\n",
    "embed_output = 32\n",
    "embed_hidden_size = 256\n",
    "embed_dropout = 0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 每個資料源建一個embedder\n",
    "layers = []\n",
    "for k, v in feats_type.items():\n",
    "    embedder = FeatureEmbedder(v, category_num, embed_dim, embed_output, embed_hidden_size, embed_dropout)\n",
    "    layers.append(embedder)\n",
    "embedders = torch.nn.ModuleList(layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from temporal_aggregator import *\n",
    "\n",
    "class Model(nn.Module):\n",
    "    def __init__(self, embedders, input_size, max_len, hidden_size, temporal_aggregator_type=\"TemporalDebertaAggregator\", \n",
    "                temporal_aggregator_args={\n",
    "                    \"hidden_size\": 32,\n",
    "                    \"num_layers\": 3,\n",
    "                    \"dropout\": 0.3,\n",
    "                    \"max_len\": 512\n",
    "                }\n",
    "                ):\n",
    "        super().__init__()\n",
    "        self.embedders = embedders\n",
    "        \n",
    "        self.max_len = max_len\n",
    "        self.input_size = input_size\n",
    "\n",
    "        self.temporal_aggregator = eval(\n",
    "            f\"{temporal_aggregator_type}\")(**temporal_aggregator_args)\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(temporal_aggregator_args[\"hidden_size\"], 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    \n",
    "    def forward(self, x, batch):\n",
    "        with torch.no_grad():\n",
    "            # 透過embedder統一各資料源的feature數量\n",
    "            for s in range(4):\n",
    "                if len(x[2][s]) == 0:\n",
    "                    continue\n",
    "                elif len(x[2][s]) == 1:\n",
    "                    x[2][s] = torch.zeros(1, self.input_size)# 只有1個sample，沒辦法做batch_norm1，encoder會出錯，直接給0\n",
    "                else:\n",
    "                    x[2][s] = self.embedders[s](x[2][s].to(device))\n",
    "            \n",
    "\n",
    "            x1 = torch.zeros(batch, self.max_len, self.input_size).to(device) # shape: (batch, max_len, features)\n",
    "            mask = torch.zeros((batch, self.max_len)).long().to(device)\n",
    "            \n",
    "            # 合併各資料源的資料\n",
    "            for s in range(4):\n",
    "                for i in range(len(x[0][s])):\n",
    "                    batch_idx, seq_idx, features = x[0][s][i], x[1][s][i], x[2][s][i]\n",
    "                    x1[batch_idx][seq_idx] = features\n",
    "                    mask[batch_idx, seq_idx] = 1\n",
    "\n",
    "\n",
    "        out = self.temporal_aggregator(x1, mask)\n",
    "        out = self.classifier(out).squeeze(-1)\n",
    "\n",
    "        return out.reshape(-1, 1), x1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_size = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 100\n",
    "model = Model(embedders, embed_output, max_len, hidden_size).to(device)\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr = 1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recall_n(output, target):\n",
    "    comb = list(zip(output, target))\n",
    "    comb.sort(key=lambda x:x[0])\n",
    "    flag = False\n",
    "    for i, (out, gt) in enumerate(comb):\n",
    "        if gt == 1:\n",
    "            if flag:\n",
    "                break\n",
    "            flag = True\n",
    "\n",
    "    recall = ((sum(target)-1) / (len(target)-i))\n",
    "    \n",
    "    return recall.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_weight(labels):\n",
    "    weight = []\n",
    "    for label in labels:\n",
    "        if label == 1:\n",
    "            weight.append(75)\n",
    "        elif label == 0:\n",
    "            weight.append(1)\n",
    "            \n",
    "    return torch.tensor(weight).reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# validate、test預測後的損失函數，以及相關分數\n",
    "def eval_score(dataloader, model, criterion, mode = \"eval\"):\n",
    "    with torch.no_grad():\n",
    "        losses = 0\n",
    "        pred1, y1 = torch.Tensor([]).to(device), torch.Tensor([]).to(device)\n",
    "        for batch, batch_data in enumerate(dataloader):\n",
    "            X, y, alert_key = batch_data\n",
    "            y = y.to(device)\n",
    "\n",
    "            pred = model(X, len(y)) #預測\n",
    "\n",
    "            if mode == \"train\":\n",
    "                weight = loss_weight(y)\n",
    "                criterion = nn.BCELoss(weight = weight).to(device)\n",
    "                loss = criterion(pred, y) #計算損失函數\n",
    "                losses += loss.item()\n",
    "\n",
    "            pred1 = torch.concat([pred1, pred])\n",
    "            y1 = torch.concat([y1, y])\n",
    "\n",
    "\n",
    "        if mode == \"train\":\n",
    "            losses /= (batch + 1)\n",
    "            \n",
    "            recall = recall_n(pred1, y1)\n",
    "\n",
    "            return losses, recall\n",
    "            \n",
    "    return pred1, alert_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Model(\n",
       "  (embedders): ModuleList(\n",
       "    (0): FeatureEmbedder(\n",
       "      (embeddings): ModuleList(\n",
       "        (0): Embedding(7708, 4)\n",
       "        (1): Embedding(128, 4)\n",
       "        (2): Embedding(51, 4)\n",
       "        (3): Linear(in_features=1, out_features=4, bias=True)\n",
       "        (4): Linear(in_features=1, out_features=4, bias=True)\n",
       "        (5): Linear(in_features=1, out_features=4, bias=True)\n",
       "        (6): Linear(in_features=1, out_features=4, bias=True)\n",
       "        (7): Linear(in_features=1, out_features=4, bias=True)\n",
       "      )\n",
       "      (encoder): Encoder(\n",
       "        (batch_norm1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (dropout1): Dropout(p=0.3, inplace=False)\n",
       "        (dense1): Linear(in_features=32, out_features=256, bias=True)\n",
       "        (batch_norm_c1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (dropout_c1): Dropout(p=0.27, inplace=False)\n",
       "        (conv1): Conv1d(64, 128, kernel_size=(5,), stride=(1,), padding=(2,), bias=False)\n",
       "        (ave_po_c1): AdaptiveAvgPool1d(output_size=2)\n",
       "        (batch_norm_c2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (dropout_c2): Dropout(p=0.24, inplace=False)\n",
       "        (conv2): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "        (batch_norm_c2_1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (dropout_c2_1): Dropout(p=0.18, inplace=False)\n",
       "        (conv2_1): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "        (batch_norm_c2_2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (dropout_c2_2): Dropout(p=0.15, inplace=False)\n",
       "        (conv2_2): Conv1d(128, 128, kernel_size=(5,), stride=(1,), padding=(2,))\n",
       "        (max_po_c2): MaxPool1d(kernel_size=4, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "        (flt): Flatten(start_dim=1, end_dim=-1)\n",
       "        (batch_norm3): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (dropout3): Dropout(p=0.3, inplace=False)\n",
       "        (dense3): Linear(in_features=128, out_features=32, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (1): FeatureEmbedder(\n",
       "      (embeddings): ModuleList(\n",
       "        (0): Embedding(7708, 4)\n",
       "        (1): Embedding(2, 4)\n",
       "        (2): Embedding(3, 4)\n",
       "        (3): Linear(in_features=1, out_features=4, bias=True)\n",
       "        (4): Linear(in_features=1, out_features=4, bias=True)\n",
       "        (5): Embedding(22, 4)\n",
       "        (6): Embedding(30, 4)\n",
       "        (7): Embedding(350, 4)\n",
       "        (8): Embedding(2, 4)\n",
       "        (9): Embedding(2, 4)\n",
       "        (10): Linear(in_features=1, out_features=4, bias=True)\n",
       "        (11): Linear(in_features=1, out_features=4, bias=True)\n",
       "        (12): Linear(in_features=1, out_features=4, bias=True)\n",
       "        (13): Linear(in_features=1, out_features=4, bias=True)\n",
       "      )\n",
       "      (encoder): Encoder(\n",
       "        (batch_norm1): BatchNorm1d(56, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (dropout1): Dropout(p=0.3, inplace=False)\n",
       "        (dense1): Linear(in_features=56, out_features=256, bias=True)\n",
       "        (batch_norm_c1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (dropout_c1): Dropout(p=0.27, inplace=False)\n",
       "        (conv1): Conv1d(64, 128, kernel_size=(5,), stride=(1,), padding=(2,), bias=False)\n",
       "        (ave_po_c1): AdaptiveAvgPool1d(output_size=2)\n",
       "        (batch_norm_c2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (dropout_c2): Dropout(p=0.24, inplace=False)\n",
       "        (conv2): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "        (batch_norm_c2_1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (dropout_c2_1): Dropout(p=0.18, inplace=False)\n",
       "        (conv2_1): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "        (batch_norm_c2_2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (dropout_c2_2): Dropout(p=0.15, inplace=False)\n",
       "        (conv2_2): Conv1d(128, 128, kernel_size=(5,), stride=(1,), padding=(2,))\n",
       "        (max_po_c2): MaxPool1d(kernel_size=4, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "        (flt): Flatten(start_dim=1, end_dim=-1)\n",
       "        (batch_norm3): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (dropout3): Dropout(p=0.3, inplace=False)\n",
       "        (dense3): Linear(in_features=128, out_features=32, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (2): FeatureEmbedder(\n",
       "      (embeddings): ModuleList(\n",
       "        (0): Embedding(7708, 4)\n",
       "        (1): Embedding(5, 4)\n",
       "        (2): Linear(in_features=1, out_features=4, bias=True)\n",
       "        (3): Linear(in_features=1, out_features=4, bias=True)\n",
       "        (4): Linear(in_features=1, out_features=4, bias=True)\n",
       "        (5): Linear(in_features=1, out_features=4, bias=True)\n",
       "        (6): Linear(in_features=1, out_features=4, bias=True)\n",
       "      )\n",
       "      (encoder): Encoder(\n",
       "        (batch_norm1): BatchNorm1d(28, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (dropout1): Dropout(p=0.3, inplace=False)\n",
       "        (dense1): Linear(in_features=28, out_features=256, bias=True)\n",
       "        (batch_norm_c1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (dropout_c1): Dropout(p=0.27, inplace=False)\n",
       "        (conv1): Conv1d(64, 128, kernel_size=(5,), stride=(1,), padding=(2,), bias=False)\n",
       "        (ave_po_c1): AdaptiveAvgPool1d(output_size=2)\n",
       "        (batch_norm_c2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (dropout_c2): Dropout(p=0.24, inplace=False)\n",
       "        (conv2): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "        (batch_norm_c2_1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (dropout_c2_1): Dropout(p=0.18, inplace=False)\n",
       "        (conv2_1): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "        (batch_norm_c2_2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (dropout_c2_2): Dropout(p=0.15, inplace=False)\n",
       "        (conv2_2): Conv1d(128, 128, kernel_size=(5,), stride=(1,), padding=(2,))\n",
       "        (max_po_c2): MaxPool1d(kernel_size=4, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "        (flt): Flatten(start_dim=1, end_dim=-1)\n",
       "        (batch_norm3): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (dropout3): Dropout(p=0.3, inplace=False)\n",
       "        (dense3): Linear(in_features=128, out_features=32, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (3): FeatureEmbedder(\n",
       "      (embeddings): ModuleList(\n",
       "        (0): Embedding(3, 4)\n",
       "        (1): Embedding(7708, 4)\n",
       "        (2): Embedding(4, 4)\n",
       "        (3): Embedding(22, 4)\n",
       "        (4): Linear(in_features=1, out_features=4, bias=True)\n",
       "        (5): Embedding(11, 4)\n",
       "        (6): Linear(in_features=1, out_features=4, bias=True)\n",
       "        (7): Linear(in_features=1, out_features=4, bias=True)\n",
       "        (8): Linear(in_features=1, out_features=4, bias=True)\n",
       "        (9): Linear(in_features=1, out_features=4, bias=True)\n",
       "        (10): Linear(in_features=1, out_features=4, bias=True)\n",
       "        (11): Linear(in_features=1, out_features=4, bias=True)\n",
       "        (12): Linear(in_features=1, out_features=4, bias=True)\n",
       "        (13): Linear(in_features=1, out_features=4, bias=True)\n",
       "        (14): Linear(in_features=1, out_features=4, bias=True)\n",
       "        (15): Linear(in_features=1, out_features=4, bias=True)\n",
       "        (16): Linear(in_features=1, out_features=4, bias=True)\n",
       "        (17): Linear(in_features=1, out_features=4, bias=True)\n",
       "      )\n",
       "      (encoder): Encoder(\n",
       "        (batch_norm1): BatchNorm1d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (dropout1): Dropout(p=0.3, inplace=False)\n",
       "        (dense1): Linear(in_features=72, out_features=256, bias=True)\n",
       "        (batch_norm_c1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (dropout_c1): Dropout(p=0.27, inplace=False)\n",
       "        (conv1): Conv1d(64, 128, kernel_size=(5,), stride=(1,), padding=(2,), bias=False)\n",
       "        (ave_po_c1): AdaptiveAvgPool1d(output_size=2)\n",
       "        (batch_norm_c2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (dropout_c2): Dropout(p=0.24, inplace=False)\n",
       "        (conv2): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "        (batch_norm_c2_1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (dropout_c2_1): Dropout(p=0.18, inplace=False)\n",
       "        (conv2_1): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "        (batch_norm_c2_2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (dropout_c2_2): Dropout(p=0.15, inplace=False)\n",
       "        (conv2_2): Conv1d(128, 128, kernel_size=(5,), stride=(1,), padding=(2,))\n",
       "        (max_po_c2): MaxPool1d(kernel_size=4, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "        (flt): Flatten(start_dim=1, end_dim=-1)\n",
       "        (batch_norm3): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (dropout3): Dropout(p=0.3, inplace=False)\n",
       "        (dense3): Linear(in_features=128, out_features=32, bias=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (temporal_aggregator): TemporalDebertaAggregator(\n",
       "    (encoder): DebertaV2Encoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): DebertaV2Layer(\n",
       "          (attention): DebertaV2Attention(\n",
       "            (self): DisentangledSelfAttention(\n",
       "              (query_proj): Linear(in_features=32, out_features=32, bias=True)\n",
       "              (key_proj): Linear(in_features=32, out_features=32, bias=True)\n",
       "              (value_proj): Linear(in_features=32, out_features=32, bias=True)\n",
       "              (pos_dropout): StableDropout()\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "            (output): DebertaV2SelfOutput(\n",
       "              (dense): Linear(in_features=32, out_features=32, bias=True)\n",
       "              (LayerNorm): LayerNorm((32,), eps=1e-07, elementwise_affine=True)\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): DebertaV2Intermediate(\n",
       "            (dense): Linear(in_features=32, out_features=128, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): DebertaV2Output(\n",
       "            (dense): Linear(in_features=128, out_features=32, bias=True)\n",
       "            (LayerNorm): LayerNorm((32,), eps=1e-07, elementwise_affine=True)\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "        (1): DebertaV2Layer(\n",
       "          (attention): DebertaV2Attention(\n",
       "            (self): DisentangledSelfAttention(\n",
       "              (query_proj): Linear(in_features=32, out_features=32, bias=True)\n",
       "              (key_proj): Linear(in_features=32, out_features=32, bias=True)\n",
       "              (value_proj): Linear(in_features=32, out_features=32, bias=True)\n",
       "              (pos_dropout): StableDropout()\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "            (output): DebertaV2SelfOutput(\n",
       "              (dense): Linear(in_features=32, out_features=32, bias=True)\n",
       "              (LayerNorm): LayerNorm((32,), eps=1e-07, elementwise_affine=True)\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): DebertaV2Intermediate(\n",
       "            (dense): Linear(in_features=32, out_features=128, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): DebertaV2Output(\n",
       "            (dense): Linear(in_features=128, out_features=32, bias=True)\n",
       "            (LayerNorm): LayerNorm((32,), eps=1e-07, elementwise_affine=True)\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "        (2): DebertaV2Layer(\n",
       "          (attention): DebertaV2Attention(\n",
       "            (self): DisentangledSelfAttention(\n",
       "              (query_proj): Linear(in_features=32, out_features=32, bias=True)\n",
       "              (key_proj): Linear(in_features=32, out_features=32, bias=True)\n",
       "              (value_proj): Linear(in_features=32, out_features=32, bias=True)\n",
       "              (pos_dropout): StableDropout()\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "            (output): DebertaV2SelfOutput(\n",
       "              (dense): Linear(in_features=32, out_features=32, bias=True)\n",
       "              (LayerNorm): LayerNorm((32,), eps=1e-07, elementwise_affine=True)\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): DebertaV2Intermediate(\n",
       "            (dense): Linear(in_features=32, out_features=128, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): DebertaV2Output(\n",
       "            (dense): Linear(in_features=128, out_features=32, bias=True)\n",
       "            (LayerNorm): LayerNorm((32,), eps=1e-07, elementwise_affine=True)\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (rel_embeddings): Embedding(1026, 32)\n",
       "    )\n",
       "  )\n",
       "  (classifier): Sequential(\n",
       "    (0): Linear(in_features=32, out_features=1, bias=True)\n",
       "    (1): Sigmoid()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(f\"model/20221206.pt\")) # 更改model權重\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 374/374 [02:28<00:00,  2.53it/s]\n"
     ]
    }
   ],
   "source": [
    "X_embeds = torch.tensor([], device=device)\n",
    "y_trains = torch.tensor([], device=device)\n",
    "for batch, batch_data in enumerate(tqdm(train_dataloader)):\n",
    "    X_train1, y_train1, alert_key = batch_data\n",
    "    y_train1 = y_train1.to(device)\n",
    "\n",
    "    train_pred, X_embed = model(X_train1, len(y_train1)) #預測\n",
    "    X_embeds = torch.concat((X_embeds, X_embed))\n",
    "    y_trains = torch.concat((y_trains, y_train1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([23906, 256, 32]), torch.Size([23906, 1]))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_embeds.shape, y_trains.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([23906, 8192])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = X_embeds.cpu().view(23906, -1)\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = y_trains.cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "sar1_idx = (y_train == 1).view(-1)\n",
    "sar0_idx = (y_train == 0).view(-1)\n",
    "\n",
    "X_train1 = X_train[sar1_idx]\n",
    "X_train0 = X_train[sar0_idx]\n",
    "y_train1 = y_train[sar1_idx]\n",
    "y_train0 = y_train[sar0_idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from sklearn.cluster import DBSCAN\n",
    "clustering = DBSCAN().fit(X_train0)\n",
    "outlier1 = clustering.labels_\n",
    "outlier1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(outlier1 == 1).sum(), pd.DataFrame(y_train)[(outlier1 == 1)].sum()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "        1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "        1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1, -1,  1,  1,\n",
       "        1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "        1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1, -1,  1,  1,  1,\n",
       "        1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "        1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "        1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "        1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "        1, -1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1, -1,\n",
       "        1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "        1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "        1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "        1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1])"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import IsolationForest\n",
    "clf = IsolationForest(random_state=0).fit(X_train0)\n",
    "outlier2 = clf.predict(X_train1)\n",
    "outlier2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total: 234\n",
      "1: 230\n",
      "-1: 4\n"
     ]
    }
   ],
   "source": [
    "print(\"total:\", len(outlier))\n",
    "print(\"1:\", (outlier2 == 1).sum())\n",
    "print(\"-1:\", (outlier2 == -1).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1, -1,  1,  1,  1,  1,  1,  1, -1,  1,  1,  1, -1, -1, -1,  1,  1,\n",
       "        1, -1,  1, -1, -1, -1, -1,  1,  1,  1,  1, -1,  1,  1,  1,  1,  1,\n",
       "       -1, -1,  1,  1, -1,  1,  1, -1,  1, -1,  1,  1,  1, -1,  1, -1, -1,\n",
       "       -1, -1, -1, -1,  1, -1, -1, -1, -1,  1,  1, -1,  1, -1,  1,  1,  1,\n",
       "        1, -1, -1, -1,  1,  1, -1, -1,  1,  1,  1,  1,  1,  1, -1,  1,  1,\n",
       "       -1,  1, -1,  1,  1,  1, -1,  1, -1, -1,  1,  1,  1,  1,  1, -1, -1,\n",
       "       -1,  1, -1, -1, -1,  1,  1,  1,  1, -1,  1,  1, -1,  1, -1,  1,  1,\n",
       "        1, -1, -1,  1,  1,  1, -1,  1,  1, -1,  1, -1, -1, -1,  1,  1, -1,\n",
       "       -1, -1,  1,  1, -1,  1,  1,  1,  1,  1,  1,  1, -1,  1,  1, -1,  1,\n",
       "       -1,  1, -1, -1, -1,  1,  1,  1,  1,  1,  1,  1, -1,  1,  1,  1,  1,\n",
       "       -1,  1,  1, -1,  1, -1, -1, -1,  1, -1,  1, -1,  1,  1,  1,  1,  1,\n",
       "       -1, -1,  1, -1, -1,  1,  1, -1,  1,  1,  1,  1,  1, -1,  1, -1,  1,\n",
       "        1, -1, -1,  1,  1,  1, -1,  1, -1,  1, -1, -1,  1, -1,  1, -1,  1,\n",
       "       -1, -1,  1,  1,  1, -1, -1, -1,  1,  1,  1,  1,  1], dtype=int64)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "clf = svm.OneClassSVM().fit(X_train0)\n",
    "outlier3 = clf.predict(X_train1)\n",
    "outlier3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total: 234\n",
      "1: 140\n",
      "-1: 94\n"
     ]
    }
   ],
   "source": [
    "print(\"total:\", len(outlier3))\n",
    "print(\"1:\", (outlier3 == 1).sum())\n",
    "print(\"-1:\", (outlier3 == -1).sum())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.7 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6a07fcf0145f94b3f971c13d061528107de20ab7b779375f96dab9bbac6a85db"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
