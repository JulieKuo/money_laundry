{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import skew\n",
    "from sklearn.preprocessing import PowerTransformer, StandardScaler, RobustScaler\n",
    "from tqdm import tqdm\n",
    "from torch import nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "import json, copy, pickle, torch, warnings, datetime\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (9716, 189)\n",
      "\n",
      "train counts of 1 & 0:\n",
      "0.0    7466\n",
      "1.0     245\n",
      "Name: sar_flag, dtype: int64\n",
      "\n",
      "test counts of 1 & 0:\n",
      "Series([], Name: sar_flag, dtype: int64)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sample</th>\n",
       "      <th>alert_key</th>\n",
       "      <th>date</th>\n",
       "      <th>sar_flag</th>\n",
       "      <th>cust_id</th>\n",
       "      <th>risk_rank</th>\n",
       "      <th>occupation_code</th>\n",
       "      <th>total_asset</th>\n",
       "      <th>AGE</th>\n",
       "      <th>total_asset_pct</th>\n",
       "      <th>...</th>\n",
       "      <th>dp_db_sum_1m</th>\n",
       "      <th>dp_db_max_median_1m</th>\n",
       "      <th>dp_cr_ct_1m</th>\n",
       "      <th>dp_cr_min_1m</th>\n",
       "      <th>dp_cr_max_1m</th>\n",
       "      <th>dp_cr_mean_1m</th>\n",
       "      <th>dp_cr_median_1m</th>\n",
       "      <th>dp_cr_sum_1m</th>\n",
       "      <th>dp_cr_min_median_1m</th>\n",
       "      <th>period</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train</td>\n",
       "      <td>171320</td>\n",
       "      <td>2021-04-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1038.0</td>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>train</td>\n",
       "      <td>171357</td>\n",
       "      <td>2021-04-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>19.0</td>\n",
       "      <td>104.0</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>train</td>\n",
       "      <td>171362</td>\n",
       "      <td>2021-04-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>13.0</td>\n",
       "      <td>462187.0</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 189 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  sample  alert_key       date  sar_flag  cust_id  risk_rank  occupation_code  \\\n",
       "0  train     171320 2021-04-01       0.0       14          1             12.0   \n",
       "1  train     171357 2021-04-01       0.0       16          1             19.0   \n",
       "2  train     171362 2021-04-01       0.0       18          1             13.0   \n",
       "\n",
       "   total_asset  AGE  total_asset_pct  ...  dp_db_sum_1m  dp_db_max_median_1m  \\\n",
       "0       1038.0    6              NaN  ...           NaN                  NaN   \n",
       "1        104.0    5              NaN  ...           NaN                  NaN   \n",
       "2     462187.0    4              NaN  ...           NaN                  NaN   \n",
       "\n",
       "   dp_cr_ct_1m  dp_cr_min_1m  dp_cr_max_1m  dp_cr_mean_1m  dp_cr_median_1m  \\\n",
       "0          NaN           NaN           NaN            NaN              NaN   \n",
       "1          NaN           NaN           NaN            NaN              NaN   \n",
       "2          NaN           NaN           NaN            NaN              NaN   \n",
       "\n",
       "   dp_cr_sum_1m  dp_cr_min_median_1m  period  \n",
       "0           NaN                  NaN       0  \n",
       "1           NaN                  NaN       0  \n",
       "2           NaN                  NaN       0  \n",
       "\n",
       "[3 rows x 189 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"data/inverse/FG.csv\", parse_dates = [\"date\"])\n",
    "\n",
    "print(\"shape:\", df.shape)\n",
    "print(f'''\\ntrain counts of 1 & 0:\\n{df.query(\"sample == 'train'\")['sar_flag'].value_counts()}''')\n",
    "print(f'''\\ntest counts of 1 & 0:\\n{df.query(\"sample == 'test'\")['sar_flag'].value_counts()}''')\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = \"sar_flag\"\n",
    "cat_feats = ['risk_rank', 'occupation_code', 'AGE']\n",
    "othet_feats = ['alert_key', 'date', 'cust_id']\n",
    "time = \"period\"\n",
    "alert_key = \"alert_key\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "188\n"
     ]
    }
   ],
   "source": [
    "num_feats = list(set(df.columns) - set([target]) - set(cat_feats) - set(othet_feats) - set([\"sample\"]))\n",
    "print(len(num_feats) + len(cat_feats) + len(othet_feats) + 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Missing value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[num_feats] = df[num_feats].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50 / 9716 = 0.00515\n",
      "sar_flag次數: 0.0\n"
     ]
    }
   ],
   "source": [
    "# 職業為missing value的樣本有116個，占比不高，都在train data，且sar_flag皆為0，刪除\n",
    "occu_null = df[\"occupation_code\"].isnull()\n",
    "print(f\"{occu_null.sum()} / {len(df)} = {round(occu_null.sum() / len(df), 5)}\")\n",
    "print(\"sar_flag次數:\", df[occu_null][\"sar_flag\"].sum())\n",
    "df = df[~occu_null].reset_index(drop = True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Label encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "le = preprocessing.LabelEncoder()\n",
    "for feat in cat_feats:\n",
    "    df[feat] = le.fit_transform(df[feat])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split Train & Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: 7661, test: 2005\n"
     ]
    }
   ],
   "source": [
    "train = df.query(\"sample == 'train'\").copy()\n",
    "test = df.query(\"sample == 'test'\").copy()\n",
    "\n",
    "print(f\"train: {len(train)}, test: {len(test)}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 刪除變數數值超過變數在sar_flag = 1的最大/小值之樣本"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "num_feats1 = [\"dp_ct_1w\", \"cdtx_ct_1w\", \"remit_ct_1w\"]\n",
    "des1 = test[test[target] == 1][num_feats].describe()\n",
    "des1 = des1.loc[[\"min\", \"max\"]]\n",
    "des1 = des1[num_feats1]#, \"dp_db_max_1w\", \"dp_cr_min_1w\"\n",
    "des1 = des1.to_dict()\n",
    "des1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "drop_index = []\n",
    "print(f\"init: {len(train)}\")\n",
    "for feat in num_feats1:\n",
    "    drop_idx = train[(train[feat] < des1[feat][\"min\"]) | (train[feat] >  des1[feat][\"max\"])].index\n",
    "    drop_index.extend(drop_idx)\n",
    "drop_index = set(drop_index)\n",
    "print(f\"drop: {len(drop_index)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train.loc[drop_index][\"sar_flag\"].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train = train.drop(drop_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "drop_index = []\n",
    "print(f\"init: {len(test)}\")\n",
    "for feat in num_feats1:\n",
    "    drop_idx = test[(test[feat] < des1[feat][\"min\"]) | (test[feat] >  des1[feat][\"max\"])].index\n",
    "    drop_index.extend(drop_idx)\n",
    "drop_index = set(drop_index)\n",
    "print(f\"{feat}: {len(drop_index)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "test.loc[drop_index][\"sar_flag\"].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "test = test.drop(drop_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "print(f\"train: {len(train)}, test: {len(test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train[num_feats] = train[num_feats].fillna(0)\n",
    "test[num_feats] = test[num_feats].fillna(0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Outlier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "for feat in num_feats:\n",
    "    q3 = train[feat].quantile(0.75)\n",
    "    q1 = train[feat].quantile(0.25)\n",
    "    iqr = q3 - q1\n",
    "\n",
    "    max_ = q3 + iqr\n",
    "    min_ = q1 + iqr\n",
    "    \n",
    "    train[feat] = train[feat].apply(lambda X: max_ if X > max_ else X)\n",
    "    train[feat] = train[feat].apply(lambda X: min_ if X < min_ else X)\n",
    "\n",
    "    test[feat] = test[feat].apply(lambda X: max_ if X > max_ else X)\n",
    "    test[feat] = test[feat].apply(lambda X: min_ if X < min_ else X)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Qusi-constant feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "89"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_selection import VarianceThreshold\n",
    "\n",
    "selector = VarianceThreshold(threshold = 0.05)\n",
    "selector.fit(train[num_feats])\n",
    "selector.get_support()\n",
    "drop_feats = [feat for feat, keep in zip(num_feats, selector.get_support()) if not keep]\n",
    "\n",
    "train = train.drop(drop_feats, axis = 1)\n",
    "test = test.drop(drop_feats, axis = 1)\n",
    "\n",
    "num_feats = [feat for feat, keep in zip(num_feats, selector.get_support()) if keep]\n",
    "len(drop_feats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adversarial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier, plot_importance, cv\n",
    "\n",
    "def adversarial(train, test):\n",
    "    # add train, test label\n",
    "    train[\"AV\"] = 0\n",
    "    test[\"AV\"] = 1\n",
    "\n",
    "    # merge train, test\n",
    "    df1 = pd.concat([train, test], ignore_index = True)\n",
    "\n",
    "    # shuffle data\n",
    "    df1_shuffled = df1.sample(frac=1)\n",
    "\n",
    "    # create XGBoost data structure\n",
    "    X = df1_shuffled.drop(['AV'], axis=1)\n",
    "    y = df1_shuffled['AV']\n",
    "    XGBdata = xgb.DMatrix(data = X, label = y)\n",
    "\n",
    "    # XGBoost parameters\n",
    "    params = {\n",
    "        \"objective\": \"binary:logistic\",\n",
    "        \"eval_metric\": \"logloss\",\n",
    "        'learning_rate': 0.05,\n",
    "        'max_depth': 5\n",
    "        }\n",
    "\n",
    "    # perform cross validation with XGBoost\n",
    "    cross_val_results = cv(\n",
    "        dtrain = XGBdata,\n",
    "        params = params, \n",
    "        nfold = 5,\n",
    "        metrics = \"auc\", \n",
    "        num_boost_round = 200,\n",
    "        early_stopping_rounds = 20,\n",
    "        as_pandas = True\n",
    "        )\n",
    "\n",
    "    # final result\n",
    "    print(\"Accuracy:\", cross_val_results[\"test-auc-mean\"].iloc[-1])\n",
    "\n",
    "\n",
    "    classifier = XGBClassifier(eval_metric = 'logloss', use_label_encoder = False)\n",
    "    classifier.fit(X, y)\n",
    "    fig, ax = plt.subplots(figsize=(10, 7))\n",
    "    plot_importance(classifier, ax=ax, max_num_features = 80, height  = 0.5)\n",
    "    plt.show()\n",
    "\n",
    "    return classifier, [i.get_text() for i in ax.axes.get_yticklabels()]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "drop_feat = [\"sar_flag\", \"sample\", \"date\", \"alert_key\", 'cust_id']\n",
    "\n",
    "train1 = train.drop(drop_feat, axis = 1)\n",
    "test1 = test.drop(drop_feat, axis = 1)\n",
    "\n",
    "#adversarial validation\n",
    "classifier, drop_feat1 = adversarial(train1, test1)\n",
    "\n",
    "\n",
    "drop_feat = drop_feat + drop_feat1\n",
    "train1 = train.drop(drop_feat, axis = 1)\n",
    "test1 = test.drop(drop_feat, axis = 1)\n",
    "\n",
    "#adversarial validation\n",
    "classifier, drop_feat2 = adversarial(train1, test1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train = train.drop(drop_feat1, axis = 1)\n",
    "test = test.drop(drop_feat1, axis = 1)\n",
    "print(train.shape, test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "num_feats = [i for i in num_feats if i not in drop_feat1]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Skew"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from scipy.stats import skew\n",
    "\n",
    "skewness = train[num_feats].apply(lambda X: skew(X)).sort_values(ascending=False)\n",
    "skewness = pd.DataFrame({'Feature' : skewness.index, 'Skew' : skewness.values})\n",
    "skewness = skewness.query(\"(Skew > 0.75) | (Skew < -0.75)\")\n",
    "skewness = skewness.reset_index(drop = True)\n",
    "skewness"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from sklearn.preprocessing import PowerTransformer\n",
    "\n",
    "pt = PowerTransformer(method = 'yeo-johnson')\n",
    "train[skewness[\"Feature\"]] = pt.fit_transform(train[skewness[\"Feature\"]])\n",
    "test[skewness[\"Feature\"]] = pt.transform(test[skewness[\"Feature\"]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from scipy.stats import skew\n",
    "\n",
    "skewness = train[num_feats].apply(lambda X: skew(X)).sort_values(ascending=False)\n",
    "skewness = pd.DataFrame({'Feature' : skewness.index, 'Skew' : skewness.values})\n",
    "skewness = skewness.query(\"(Skew > 0.75) | (Skew < -0.75)\")\n",
    "skewness = skewness.reset_index(drop = True)\n",
    "skewness"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sample</th>\n",
       "      <th>alert_key</th>\n",
       "      <th>date</th>\n",
       "      <th>sar_flag</th>\n",
       "      <th>cust_id</th>\n",
       "      <th>risk_rank</th>\n",
       "      <th>occupation_code</th>\n",
       "      <th>total_asset</th>\n",
       "      <th>AGE</th>\n",
       "      <th>info_ct</th>\n",
       "      <th>...</th>\n",
       "      <th>dp_db_sum_1m</th>\n",
       "      <th>dp_db_max_median_1m</th>\n",
       "      <th>dp_cr_ct_1m</th>\n",
       "      <th>dp_cr_min_1m</th>\n",
       "      <th>dp_cr_max_1m</th>\n",
       "      <th>dp_cr_mean_1m</th>\n",
       "      <th>dp_cr_median_1m</th>\n",
       "      <th>dp_cr_sum_1m</th>\n",
       "      <th>dp_cr_min_median_1m</th>\n",
       "      <th>period</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train</td>\n",
       "      <td>171320</td>\n",
       "      <td>2021-04-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>train</td>\n",
       "      <td>171357</td>\n",
       "      <td>2021-04-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>train</td>\n",
       "      <td>171362</td>\n",
       "      <td>2021-04-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>train</td>\n",
       "      <td>171363</td>\n",
       "      <td>2021-04-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>train</td>\n",
       "      <td>171375</td>\n",
       "      <td>2021-04-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 100 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  sample  alert_key       date  sar_flag  cust_id  risk_rank  occupation_code  \\\n",
       "0  train     171320 2021-04-01       0.0       14          1               12   \n",
       "1  train     171357 2021-04-01       0.0       16          1               19   \n",
       "2  train     171362 2021-04-01       0.0       18          1               13   \n",
       "3  train     171363 2021-04-01       0.0       19          1                9   \n",
       "4  train     171375 2021-04-01       0.0       25          1                9   \n",
       "\n",
       "   total_asset  AGE  info_ct  ...  dp_db_sum_1m  dp_db_max_median_1m  \\\n",
       "0          0.0    6      0.0  ...           0.0                  0.0   \n",
       "1          0.0    5      0.0  ...           0.0                  0.0   \n",
       "2          0.0    4      0.0  ...           0.0                  0.0   \n",
       "3          1.0    6      0.0  ...           0.0                  0.0   \n",
       "4          1.0    6      0.0  ...           0.0                  0.0   \n",
       "\n",
       "   dp_cr_ct_1m  dp_cr_min_1m  dp_cr_max_1m  dp_cr_mean_1m  dp_cr_median_1m  \\\n",
       "0          0.0           0.0           0.0            0.0              0.0   \n",
       "1          0.0           0.0           0.0            0.0              0.0   \n",
       "2          0.0           0.0           0.0            0.0              0.0   \n",
       "3          0.0           0.0           0.0            0.0              0.0   \n",
       "4          0.0           0.0           0.0            0.0              0.0   \n",
       "\n",
       "   dp_cr_sum_1m  dp_cr_min_median_1m  period  \n",
       "0           0.0                  0.0     0.0  \n",
       "1           0.0                  0.0     0.0  \n",
       "2           0.0                  0.0     0.0  \n",
       "3           0.0                  0.0     0.0  \n",
       "4           0.0                  0.0     0.0  \n",
       "\n",
       "[5 rows x 100 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler, RobustScaler\n",
    "scaler = MinMaxScaler()\n",
    "train[num_feats] = scaler.fit_transform(train[num_feats])\n",
    "test[num_feats] = scaler.transform(test[num_feats])\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split train、valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5362, 100) (2299, 100) (2005, 100)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_data, valid_data = train_test_split(train, test_size = 0.3, random_state = 99, stratify = train[target])\n",
    "test_data = test.copy()\n",
    "print(train_data.shape, valid_data.shape, test_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4886 / 164 =  29.793\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.0    5191\n",
       "1.0     171\n",
       "Name: sar_flag, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"4886 / 164 = \", round(4886 / 164, 3))\n",
    "train_data.loc[train_data[\"alert_key\"].drop_duplicates().index][\"sar_flag\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2095 / 70 =  29.929\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.0    2225\n",
       "1.0      74\n",
       "Name: sar_flag, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"2095 / 70 = \", round(2095 / 70, 3))\n",
    "valid_data.loc[valid_data[\"alert_key\"].drop_duplicates().index][\"sar_flag\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1835 / 10 =  183.5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Series([], Name: sar_flag, dtype: int64)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"1835 / 10 = \", round(1835 / 10, 3))\n",
    "test_data.loc[test_data[\"alert_key\"].drop_duplicates().index][\"sar_flag\"].value_counts()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataFrame transform to Torch Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset_transform(Dataset):\n",
    "    def __init__(self, df, features, target, alert_key):\n",
    "        self.n_samples = len(df)\n",
    "        self.X = torch.Tensor(df[features].values)#.to(device)\n",
    "        self.y = torch.Tensor(df[target].values.reshape(-1, 1))#.to(device)\n",
    "        self.alert_key = torch.Tensor(df[alert_key].values.reshape(-1, 1)).long()#.to(device)\n",
    "                                            \n",
    "    def __len__(self):\n",
    "        return self.n_samples\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.X[index], self.y[index], self.alert_key[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = num_feats + cat_feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = Dataset_transform(train_data, features, target, alert_key)\n",
    "valid_dataset = Dataset_transform(valid_data, features, target, alert_key)\n",
    "test_dataset = Dataset_transform(test_data, features, target, alert_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([ 0.0000,  0.0000,  0.0000,  0.0000,  1.0000,  0.0000,  1.0000,  0.0000,\n",
       "          0.0000,  0.6667,  0.2500,  0.0000,  0.0000,  0.0000,  0.0000,  1.0000,\n",
       "          0.0000,  0.0000,  0.4545,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.7368,  1.0000,  0.3333,\n",
       "          0.0000,  0.5000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.7418,  1.0000,  1.0000,\n",
       "          0.0000,  0.7665,  0.0000,  1.0000,  0.1667,  1.0000,  0.0000,  0.0000,\n",
       "          1.0000,  0.0000,  1.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.7500,  0.0000,  0.0000,  0.9635,  0.0000,  0.6667,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  1.0000,  0.0000,  0.0000,  0.4545,\n",
       "          0.0000,  0.0000,  0.0000,  1.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          1.0000,  0.0000,  1.0000,  0.0000,  3.0000, 17.0000,  4.0000]),\n",
       " tensor([0.]),\n",
       " tensor([305694]))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.__getitem__(3)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataLoader for batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "train_dataloader = DataLoader(train_dataset, batch_size = batch_size, shuffle = True)\n",
    "valid_dataloader = DataLoader(valid_dataset, batch_size = batch_size)#, batch_size = len(valid_dataset))\n",
    "test_dataloader = DataLoader(test_dataset, batch_size = batch_size)#, batch_size = len(test_dataset))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embedding structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'risk_rank': {'input': 4, 'output': 2},\n",
       " 'occupation_code': {'input': 21, 'output': 3},\n",
       " 'AGE': {'input': 11, 'output': 2}}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_feats_num = df[cat_feats].nunique()\n",
    "cat_feats_num = pd.DataFrame(cat_feats_num, columns = [\"input\"])\n",
    "cat_feats_num[\"output\"] = np.ceil(cat_feats_num ** (0.25)).astype(int)\n",
    "cat_feats_num = cat_feats_num.T.to_dict()\n",
    "cat_feats_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Embedder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        layers = [nn.Embedding(v[\"input\"], v[\"output\"]) for v in cat_feats_num.values()]\n",
    "        self.embeddings = torch.nn.ModuleList(layers)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        num_x = x[:, :-len(cat_feats_num)]\n",
    "        cat_x = x[:, -len(cat_feats_num):]\n",
    "\n",
    "        emb_x = []\n",
    "        for i, feat_embedder in enumerate(self.embeddings):\n",
    "            feat_x = feat_embedder(cat_x[:, i].long())\n",
    "            emb_x.append(feat_x)\n",
    "            \n",
    "        emb_x = torch.cat(emb_x, dim=1)# 把所有feature的向量合併\n",
    "        new_x = torch.cat((num_x, emb_x), dim = 1)\n",
    "\n",
    "        return new_x"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, input_size, embedder):\n",
    "        super().__init__()\n",
    "        self.embedder = embedder\n",
    "\n",
    "        self.net  = nn.Sequential(\n",
    "            nn.Linear(input_size, 128),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Dropout(0.4),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Dropout(0.4),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.Linear(64, 32),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Dropout(0.4),\n",
    "            nn.BatchNorm1d(32),\n",
    "            nn.Linear(32, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.embedder(x)\n",
    "        x = self.net(x)\n",
    "        return x"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 500\n",
    "input_size = len(features) - len(cat_feats) + sum([v[\"output\"] for v in cat_feats_num.values()])\n",
    "\n",
    "embedder = Embedder()\n",
    "\n",
    "model = Model(input_size, embedder)#.to(device)\n",
    "criterion = nn.BCELoss()#.to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr = 1e-4)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#初始化權重，使其符合常態分布\n",
    "for m in model.modules():\n",
    "    if isinstance(m, (nn.Linear)):\n",
    "        nn.init.kaiming_normal_(m.weight)\n",
    "        nn.init.constant_(m.bias, 0)\n",
    "    elif isinstance(m, nn.BatchNorm1d):\n",
    "        nn.init.constant_(m.weight, 1)\n",
    "        nn.init.constant_(m.bias, 0)\n",
    "    elif isinstance(m, nn.Embedding):\n",
    "        nn.init.kaiming_normal_(m.weight)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weight of loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(31.26938775510204, 1.0330366774541533)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos = len(train[target]) / (train[target].sum())\n",
    "neg = len(train[target]) / (len(train[target]) - (train[target].sum()))\n",
    "# pos = 1; neg = 1\n",
    "pos, neg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_weight(labels, pos, neg):\n",
    "    weight = []\n",
    "    for label in labels:\n",
    "        if label == 1:\n",
    "            weight.append(pos)\n",
    "        elif label == 0:\n",
    "            weight.append(neg)\n",
    "            \n",
    "    return torch.tensor(weight).reshape(-1, 1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_train(dataloader, model, criterion, _tqdm):\n",
    "    model.train() # 模型為訓練模式\n",
    "    losses = 0\n",
    "    for  batch, (X, y, alert) in enumerate(dataloader):\n",
    "        pred = model(X) #預測\n",
    "\n",
    "        weight = loss_weight(y, pos, neg)\n",
    "        criterion = nn.BCELoss(weight = weight)\n",
    "        loss = criterion(pred, y) #計算損失函數\n",
    "        losses += loss.item()\n",
    "        \n",
    "        optimizer.zero_grad() # 梯度在反向傳播前先清零\n",
    "        loss.backward() # 反向傳播，計算權重對損失函數的梯度\n",
    "        optimizer.step()  # 根據梯度更新權重\n",
    "\n",
    "        _tqdm.set_postfix({\"train_loss\" : loss.item()})\n",
    "        _tqdm.update(1)\n",
    "\n",
    "    losses /= (batch + 1)\n",
    "\n",
    "    return model, losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_eval(dataloader, model, criterion, mode = \"train\"):\n",
    "    model.eval() # 模型為訓練模式\n",
    "    preds, ys, alerts = torch.Tensor([]), torch.Tensor([]), torch.Tensor([])\n",
    "    with torch.no_grad():\n",
    "        losses = 0\n",
    "        for  batch, (X, y, alert) in enumerate(dataloader):\n",
    "            pred = model(X) #預測\n",
    "\n",
    "            if mode != \"test\":\n",
    "                weight = loss_weight(y, pos, neg)\n",
    "                criterion = nn.BCELoss(weight = weight)\n",
    "                loss = criterion(pred, y) #計算損失函數\n",
    "                losses += loss.item()\n",
    "\n",
    "            preds = torch.concat([preds, pred])\n",
    "            ys = torch.concat([ys, y])\n",
    "            alerts = torch.concat([alerts, alert])\n",
    "\n",
    "        if mode != \"test\":\n",
    "            losses /= (batch + 1)\n",
    "\n",
    "            return losses\n",
    "        \n",
    "        return preds, ys, alerts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 1/500: 100%|████████████████████████████████████████████████████████████████████████████████| 42/42 [00:01<00:00, 40.79it/s, train_loss=1.9, valid_loss=1.44, best_loss=1.44]\n",
      "epoch: 2/500: 100%|██████████████████████████████████████████████████████████████████████████████| 42/42 [00:00<00:00, 114.10it/s, train_loss=1.76, valid_loss=1.29, best_loss=1.29]\n",
      "epoch: 3/500: 100%|██████████████████████████████████████████████████████████████████████████████| 42/42 [00:00<00:00, 106.17it/s, train_loss=1.69, valid_loss=1.17, best_loss=1.17]\n",
      "epoch: 4/500: 100%|██████████████████████████████████████████████████████████████████████████████| 42/42 [00:00<00:00, 118.45it/s, train_loss=1.64, valid_loss=1.13, best_loss=1.13]\n",
      "epoch: 5/500: 100%|██████████████████████████████████████████████████████████████████████████████| 42/42 [00:00<00:00, 115.20it/s, train_loss=1.56, valid_loss=1.06, best_loss=1.06]\n",
      "epoch: 6/500: 100%|███████████████████████████████████████████████████████████████████████████████| 42/42 [00:00<00:00, 113.64it/s, train_loss=1.5, valid_loss=1.03, best_loss=1.03]\n",
      "epoch: 7/500: 100%|████████████████████████████████████████████████████████████████████████████████████| 42/42 [00:00<00:00, 105.90it/s, train_loss=1.43, valid_loss=1, best_loss=1]\n",
      "epoch: 8/500: 100%|████████████████████████████████████████████████████████████████████████████| 42/42 [00:00<00:00, 112.58it/s, train_loss=1.43, valid_loss=0.983, best_loss=0.983]\n",
      "epoch: 9/500: 100%|████████████████████████████████████████████████████████████████████████████| 42/42 [00:00<00:00, 105.94it/s, train_loss=1.35, valid_loss=0.971, best_loss=0.971]\n",
      "epoch: 10/500: 100%|█████████████████████████████████████████████████████████████████████████████| 42/42 [00:00<00:00, 105.45it/s, train_loss=1.45, valid_loss=0.95, best_loss=0.95]\n",
      "epoch: 11/500: 100%|██████████████████████████████████████████████████████████████████████████████| 42/42 [00:00<00:00, 111.09it/s, train_loss=1.4, valid_loss=0.94, best_loss=0.94]\n",
      "epoch: 12/500: 100%|███████████████████████████████████████████████████████████████████████████| 42/42 [00:00<00:00, 111.82it/s, train_loss=1.36, valid_loss=0.929, best_loss=0.929]\n",
      "epoch: 13/500: 100%|███████████████████████████████████████████████████████████████████████████| 42/42 [00:00<00:00, 114.42it/s, train_loss=1.28, valid_loss=0.914, best_loss=0.914]\n",
      "epoch: 14/500: 100%|███████████████████████████████████████████████████████████████████████████| 42/42 [00:00<00:00, 115.04it/s, train_loss=1.35, valid_loss=0.903, best_loss=0.903]\n",
      "epoch: 15/500: 100%|████████████████████████████████████████████████████████████████████████████| 42/42 [00:00<00:00, 116.15it/s, train_loss=1.3, valid_loss=0.899, best_loss=0.899]\n",
      "epoch: 16/500: 100%|███████████████████████████████████████████████████████████████████████████| 42/42 [00:00<00:00, 110.50it/s, train_loss=1.25, valid_loss=0.896, best_loss=0.896]\n",
      "epoch: 17/500: 100%|███████████████████████████████████████████████████████████████████████████| 42/42 [00:00<00:00, 114.42it/s, train_loss=1.24, valid_loss=0.877, best_loss=0.877]\n",
      "epoch: 18/500: 100%|█████████████████████████████████████████████████████████████████████████████| 42/42 [00:00<00:00, 115.68it/s, train_loss=1.2, valid_loss=0.88, best_loss=0.877]\n",
      "epoch: 19/500: 100%|███████████████████████████████████████████████████████████████████████████| 42/42 [00:00<00:00, 112.88it/s, train_loss=1.25, valid_loss=0.878, best_loss=0.877]\n",
      "epoch: 20/500: 100%|███████████████████████████████████████████████████████████████████████████| 42/42 [00:00<00:00, 114.11it/s, train_loss=1.19, valid_loss=0.861, best_loss=0.861]\n",
      "epoch: 21/500: 100%|███████████████████████████████████████████████████████████████████████████| 42/42 [00:00<00:00, 104.58it/s, train_loss=1.23, valid_loss=0.865, best_loss=0.861]\n",
      "epoch: 22/500: 100%|███████████████████████████████████████████████████████████████████████████| 42/42 [00:00<00:00, 106.85it/s, train_loss=1.27, valid_loss=0.857, best_loss=0.857]\n",
      "epoch: 23/500: 100%|████████████████████████████████████████████████████████████████████████████| 42/42 [00:00<00:00, 112.27it/s, train_loss=1.15, valid_loss=0.86, best_loss=0.857]\n",
      "epoch: 24/500: 100%|█████████████████████████████████████████████████████████████████████████████| 42/42 [00:00<00:00, 114.10it/s, train_loss=1.14, valid_loss=0.85, best_loss=0.85]\n",
      "epoch: 25/500: 100%|███████████████████████████████████████████████████████████████████████████| 42/42 [00:00<00:00, 109.21it/s, train_loss=1.13, valid_loss=0.842, best_loss=0.842]\n",
      "epoch: 26/500: 100%|███████████████████████████████████████████████████████████████████████████| 42/42 [00:00<00:00, 109.64it/s, train_loss=1.13, valid_loss=0.834, best_loss=0.834]\n",
      "epoch: 27/500: 100%|███████████████████████████████████████████████████████████████████████████| 42/42 [00:00<00:00, 111.38it/s, train_loss=1.13, valid_loss=0.832, best_loss=0.832]\n",
      "epoch: 28/500: 100%|███████████████████████████████████████████████████████████████████████████| 42/42 [00:00<00:00, 110.36it/s, train_loss=1.15, valid_loss=0.831, best_loss=0.831]\n",
      "epoch: 29/500: 100%|███████████████████████████████████████████████████████████████████████████| 42/42 [00:00<00:00, 109.49it/s, train_loss=1.13, valid_loss=0.813, best_loss=0.813]\n",
      "epoch: 30/500: 100%|███████████████████████████████████████████████████████████████████████████| 42/42 [00:00<00:00, 108.22it/s, train_loss=1.14, valid_loss=0.823, best_loss=0.813]\n",
      "epoch: 31/500: 100%|█████████████████████████████████████████████████████████████████████████████| 42/42 [00:00<00:00, 97.65it/s, train_loss=1.14, valid_loss=0.82, best_loss=0.813]\n",
      "epoch: 32/500: 100%|██████████████████████████████████████████████████████████████████████████████| 42/42 [00:00<00:00, 97.54it/s, train_loss=1.12, valid_loss=0.81, best_loss=0.81]\n",
      "epoch: 33/500: 100%|███████████████████████████████████████████████████████████████████████████| 42/42 [00:00<00:00, 103.55it/s, train_loss=1.12, valid_loss=0.803, best_loss=0.803]\n",
      "epoch: 34/500: 100%|███████████████████████████████████████████████████████████████████████████| 42/42 [00:00<00:00, 106.04it/s, train_loss=1.16, valid_loss=0.812, best_loss=0.803]\n",
      "epoch: 35/500: 100%|███████████████████████████████████████████████████████████████████████████| 42/42 [00:00<00:00, 104.98it/s, train_loss=1.13, valid_loss=0.795, best_loss=0.795]\n",
      "epoch: 36/500: 100%|███████████████████████████████████████████████████████████████████████████| 42/42 [00:00<00:00, 104.45it/s, train_loss=1.11, valid_loss=0.784, best_loss=0.784]\n",
      "epoch: 37/500: 100%|████████████████████████████████████████████████████████████████████████████| 42/42 [00:00<00:00, 96.98it/s, train_loss=1.11, valid_loss=0.787, best_loss=0.784]\n",
      "epoch: 38/500: 100%|███████████████████████████████████████████████████████████████████████████| 42/42 [00:00<00:00, 100.33it/s, train_loss=1.14, valid_loss=0.783, best_loss=0.783]\n",
      "epoch: 39/500: 100%|███████████████████████████████████████████████████████████████████████████| 42/42 [00:00<00:00, 111.97it/s, train_loss=1.09, valid_loss=0.786, best_loss=0.783]\n",
      "epoch: 40/500: 100%|████████████████████████████████████████████████████████████████████████████| 42/42 [00:00<00:00, 97.88it/s, train_loss=1.09, valid_loss=0.778, best_loss=0.778]\n",
      "epoch: 41/500: 100%|███████████████████████████████████████████████████████████████████████████| 42/42 [00:00<00:00, 106.57it/s, train_loss=1.05, valid_loss=0.789, best_loss=0.778]\n",
      "epoch: 42/500: 100%|███████████████████████████████████████████████████████████████████████████| 42/42 [00:00<00:00, 109.64it/s, train_loss=1.03, valid_loss=0.774, best_loss=0.774]\n",
      "epoch: 43/500: 100%|███████████████████████████████████████████████████████████████████████████| 42/42 [00:00<00:00, 110.50it/s, train_loss=1.02, valid_loss=0.773, best_loss=0.773]\n",
      "epoch: 44/500: 100%|███████████████████████████████████████████████████████████████████████████| 42/42 [00:00<00:00, 108.78it/s, train_loss=1.09, valid_loss=0.772, best_loss=0.772]\n",
      "epoch: 45/500: 100%|███████████████████████████████████████████████████████████████████████████| 42/42 [00:00<00:00, 104.19it/s, train_loss=1.04, valid_loss=0.774, best_loss=0.772]\n",
      "epoch: 46/500: 100%|███████████████████████████████████████████████████████████████████████████| 42/42 [00:00<00:00, 109.35it/s, train_loss=1.04, valid_loss=0.769, best_loss=0.769]\n",
      "epoch: 47/500: 100%|███████████████████████████████████████████████████████████████████████████| 42/42 [00:00<00:00, 106.31it/s, train_loss=1.08, valid_loss=0.758, best_loss=0.758]\n",
      "epoch: 48/500: 100%|███████████████████████████████████████████████████████████████████████████| 42/42 [00:00<00:00, 103.94it/s, train_loss=1.08, valid_loss=0.754, best_loss=0.754]\n",
      "epoch: 49/500: 100%|███████████████████████████████████████████████████████████████████████████| 42/42 [00:00<00:00, 106.31it/s, train_loss=1.03, valid_loss=0.757, best_loss=0.754]\n",
      "epoch: 50/500: 100%|███████████████████████████████████████████████████████████████████████████| 42/42 [00:00<00:00, 103.42it/s, train_loss=1.04, valid_loss=0.763, best_loss=0.754]\n",
      "epoch: 51/500: 100%|████████████████████████████████████████████████████████████████████████████| 42/42 [00:00<00:00, 97.43it/s, train_loss=1.03, valid_loss=0.755, best_loss=0.754]\n",
      "epoch: 52/500: 100%|███████████████████████████████████████████████████████████████████████████| 42/42 [00:00<00:00, 82.01it/s, train_loss=0.989, valid_loss=0.755, best_loss=0.754]\n",
      "epoch: 53/500: 100%|███████████████████████████████████████████████████████████████████████████| 42/42 [00:00<00:00, 109.35it/s, train_loss=1.02, valid_loss=0.743, best_loss=0.743]\n",
      "epoch: 54/500: 100%|███████████████████████████████████████████████████████████████████████████| 42/42 [00:00<00:00, 104.41it/s, train_loss=1.06, valid_loss=0.746, best_loss=0.743]\n",
      "epoch: 55/500: 100%|███████████████████████████████████████████████████████████████████████████| 42/42 [00:00<00:00, 109.92it/s, train_loss=1.01, valid_loss=0.749, best_loss=0.743]\n",
      "epoch: 56/500: 100%|████████████████████████████████████████████████████████████████████████████| 42/42 [00:00<00:00, 98.10it/s, train_loss=1.05, valid_loss=0.744, best_loss=0.743]\n",
      "epoch: 57/500: 100%|███████████████████████████████████████████████████████████████████████████| 42/42 [00:00<00:00, 109.92it/s, train_loss=1.02, valid_loss=0.747, best_loss=0.743]\n",
      "epoch: 58/500: 100%|███████████████████████████████████████████████████████████████████████████████| 42/42 [00:00<00:00, 90.11it/s, train_loss=1, valid_loss=0.739, best_loss=0.739]\n",
      "epoch: 59/500: 100%|███████████████████████████████████████████████████████████████████████████| 42/42 [00:00<00:00, 101.30it/s, train_loss=1.02, valid_loss=0.741, best_loss=0.739]\n",
      "epoch: 60/500: 100%|████████████████████████████████████████████████████████████████████████████| 42/42 [00:00<00:00, 92.90it/s, train_loss=0.973, valid_loss=0.74, best_loss=0.739]\n",
      "epoch: 61/500: 100%|███████████████████████████████████████████████████████████████████████████| 42/42 [00:00<00:00, 112.88it/s, train_loss=1.01, valid_loss=0.737, best_loss=0.737]\n",
      "epoch: 62/500: 100%|██████████████████████████████████████████████████████████████████████████| 42/42 [00:00<00:00, 114.73it/s, train_loss=0.983, valid_loss=0.737, best_loss=0.737]\n",
      "epoch: 63/500: 100%|██████████████████████████████████████████████████████████████████████████| 42/42 [00:00<00:00, 108.50it/s, train_loss=0.979, valid_loss=0.732, best_loss=0.732]\n",
      "epoch: 64/500: 100%|███████████████████████████████████████████████████████████████████████████████| 42/42 [00:00<00:00, 84.15it/s, train_loss=1, valid_loss=0.733, best_loss=0.732]\n",
      "epoch: 65/500: 100%|██████████████████████████████████████████████████████████████████████████| 42/42 [00:00<00:00, 106.58it/s, train_loss=0.982, valid_loss=0.731, best_loss=0.731]\n",
      "epoch: 66/500: 100%|███████████████████████████████████████████████████████████████████████████| 42/42 [00:00<00:00, 106.58it/s, train_loss=1.04, valid_loss=0.724, best_loss=0.724]\n",
      "epoch: 67/500: 100%|███████████████████████████████████████████████████████████████████████████| 42/42 [00:00<00:00, 99.27it/s, train_loss=0.965, valid_loss=0.728, best_loss=0.724]\n",
      "epoch: 68/500: 100%|██████████████████████████████████████████████████████████████████████████| 42/42 [00:00<00:00, 104.20it/s, train_loss=0.978, valid_loss=0.728, best_loss=0.724]\n",
      "epoch: 69/500: 100%|██████████████████████████████████████████████████████████████████████████| 42/42 [00:00<00:00, 102.17it/s, train_loss=0.934, valid_loss=0.726, best_loss=0.724]\n",
      "epoch: 70/500: 100%|███████████████████████████████████████████████████████████████████████████| 42/42 [00:00<00:00, 80.13it/s, train_loss=0.926, valid_loss=0.718, best_loss=0.718]\n",
      "epoch: 71/500: 100%|██████████████████████████████████████████████████████████████████████████| 42/42 [00:00<00:00, 101.67it/s, train_loss=0.947, valid_loss=0.727, best_loss=0.718]\n",
      "epoch: 72/500: 100%|██████████████████████████████████████████████████████████████████████████| 42/42 [00:00<00:00, 105.90it/s, train_loss=0.949, valid_loss=0.725, best_loss=0.718]\n",
      "epoch: 73/500: 100%|██████████████████████████████████████████████████████████████████████████| 42/42 [00:00<00:00, 102.04it/s, train_loss=0.956, valid_loss=0.714, best_loss=0.714]\n",
      "epoch: 74/500: 100%|███████████████████████████████████████████████████████████████████████████| 42/42 [00:00<00:00, 104.71it/s, train_loss=0.92, valid_loss=0.721, best_loss=0.714]\n",
      "epoch: 75/500: 100%|████████████████████████████████████████████████████████████████████████████| 42/42 [00:00<00:00, 111.97it/s, train_loss=0.914, valid_loss=0.71, best_loss=0.71]\n",
      "epoch: 76/500: 100%|███████████████████████████████████████████████████████████████████████████| 42/42 [00:00<00:00, 112.88it/s, train_loss=0.969, valid_loss=0.715, best_loss=0.71]\n",
      "epoch: 77/500: 100%|███████████████████████████████████████████████████████████████████████████| 42/42 [00:00<00:00, 103.68it/s, train_loss=0.958, valid_loss=0.713, best_loss=0.71]\n",
      "epoch: 78/500: 100%|████████████████████████████████████████████████████████████████████████████| 42/42 [00:00<00:00, 108.64it/s, train_loss=0.93, valid_loss=0.713, best_loss=0.71]\n",
      "epoch: 79/500: 100%|██████████████████████████████████████████████████████████████████████████| 42/42 [00:00<00:00, 103.94it/s, train_loss=0.928, valid_loss=0.707, best_loss=0.707]\n",
      "epoch: 80/500: 100%|██████████████████████████████████████████████████████████████████████████| 42/42 [00:00<00:00, 101.18it/s, train_loss=0.898, valid_loss=0.705, best_loss=0.705]\n",
      "epoch: 81/500: 100%|███████████████████████████████████████████████████████████████████████████| 42/42 [00:00<00:00, 98.11it/s, train_loss=0.959, valid_loss=0.707, best_loss=0.705]\n",
      "epoch: 82/500: 100%|██████████████████████████████████████████████████████████████████████████| 42/42 [00:00<00:00, 105.24it/s, train_loss=0.889, valid_loss=0.706, best_loss=0.705]\n",
      "epoch: 83/500: 100%|███████████████████████████████████████████████████████████████████████████| 42/42 [00:00<00:00, 99.98it/s, train_loss=0.903, valid_loss=0.704, best_loss=0.704]\n",
      "epoch: 84/500: 100%|███████████████████████████████████████████████████████████████████████████| 42/42 [00:00<00:00, 97.65it/s, train_loss=0.932, valid_loss=0.702, best_loss=0.702]\n",
      "epoch: 85/500: 100%|███████████████████████████████████████████████████████████████████████████| 42/42 [00:00<00:00, 96.52it/s, train_loss=0.888, valid_loss=0.701, best_loss=0.701]\n",
      "epoch: 86/500: 100%|████████████████████████████████████████████████████████████████████████████| 42/42 [00:00<00:00, 94.68it/s, train_loss=0.92, valid_loss=0.703, best_loss=0.701]\n",
      "epoch: 87/500: 100%|██████████████████████████████████████████████████████████████████████████| 42/42 [00:00<00:00, 107.52it/s, train_loss=0.885, valid_loss=0.701, best_loss=0.701]\n",
      "epoch: 88/500: 100%|██████████████████████████████████████████████████████████████████████████| 42/42 [00:00<00:00, 101.92it/s, train_loss=0.893, valid_loss=0.702, best_loss=0.701]\n",
      "epoch: 89/500: 100%|██████████████████████████████████████████████████████████████████████████| 42/42 [00:00<00:00, 104.84it/s, train_loss=0.906, valid_loss=0.699, best_loss=0.699]\n",
      "epoch: 90/500: 100%|███████████████████████████████████████████████████████████████████████████| 42/42 [00:00<00:00, 98.45it/s, train_loss=0.901, valid_loss=0.696, best_loss=0.696]\n",
      "epoch: 91/500: 100%|██████████████████████████████████████████████████████████████████████████| 42/42 [00:00<00:00, 107.67it/s, train_loss=0.921, valid_loss=0.697, best_loss=0.696]\n",
      "epoch: 92/500: 100%|██████████████████████████████████████████████████████████████████████████| 42/42 [00:00<00:00, 110.50it/s, train_loss=0.917, valid_loss=0.696, best_loss=0.696]\n",
      "epoch: 93/500: 100%|██████████████████████████████████████████████████████████████████████████| 42/42 [00:00<00:00, 107.12it/s, train_loss=0.891, valid_loss=0.693, best_loss=0.693]\n",
      "epoch: 94/500: 100%|██████████████████████████████████████████████████████████████████████████| 42/42 [00:00<00:00, 109.35it/s, train_loss=0.875, valid_loss=0.695, best_loss=0.693]\n",
      "epoch: 95/500: 100%|██████████████████████████████████████████████████████████████████████████| 42/42 [00:00<00:00, 100.33it/s, train_loss=0.881, valid_loss=0.697, best_loss=0.693]\n",
      "epoch: 96/500: 100%|██████████████████████████████████████████████████████████████████████████| 42/42 [00:00<00:00, 107.12it/s, train_loss=0.879, valid_loss=0.694, best_loss=0.693]\n",
      "epoch: 97/500: 100%|██████████████████████████████████████████████████████████████████████████| 42/42 [00:00<00:00, 105.37it/s, train_loss=0.877, valid_loss=0.697, best_loss=0.693]\n",
      "epoch: 98/500: 100%|██████████████████████████████████████████████████████████████████████████| 42/42 [00:00<00:00, 113.18it/s, train_loss=0.886, valid_loss=0.696, best_loss=0.693]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "early stop!\n",
      "Done!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# 建模\n",
    "best_loss = np.inf\n",
    "paitence = 5\n",
    "remain_patience = 0\n",
    "train_losses = []\n",
    "valid_losses = []\n",
    "for epoch in range(epochs):\n",
    "\n",
    "    with tqdm(total = len(train_dataloader), ncols = 180) as _tqdm: # 使用需要的參數對tqdm進行初始化\n",
    "        _tqdm.set_description('epoch: {}/{}'.format(epoch + 1, epochs))# 設置前綴 一般為epoch的信息\n",
    "        \n",
    "        # train model\n",
    "        model, train_loss = model_train(train_dataloader, model, criterion, _tqdm)\n",
    "        train_losses.append(train_loss)\n",
    "\n",
    "        # validate model\n",
    "        valid_loss = model_eval(valid_dataloader, model, criterion, mode = \"train\")\n",
    "        valid_losses.append(valid_loss)\n",
    "\n",
    "        # 損失函數連續30個epoches都沒下降的話就終止訓練\n",
    "        if valid_loss < best_loss:\n",
    "            best_loss = valid_loss\n",
    "            remain_patience = paitence\n",
    "            _tqdm.set_postfix({\"train_loss\" : train_loss, \"valid_loss\": valid_loss, \"best_loss\": best_loss})# 設置想在本次循環監視變量，可作後綴打印出來\n",
    "        else:\n",
    "            _tqdm.set_postfix({\"train_loss\" : train_loss, \"valid_loss\": valid_loss, \"best_loss\": best_loss})# 設置想在本次循環監視變量，可作後綴打印出來\n",
    "            remain_patience -= 1\n",
    "            if remain_patience == 0:\n",
    "                print('early stop!')\n",
    "                break\n",
    "        \n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'loss')"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA04AAAFzCAYAAAAJ21nbAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjYuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8o6BhiAAAACXBIWXMAAA9hAAAPYQGoP6dpAAB6g0lEQVR4nO3dd3hUZfrG8e+UZNITkpCENHrvvaogsIiIvYKiouu66s+CumtZXTv2zlp2VSzYFewFkS4dQu+k0RJCek9mzu+PkwQikEbCJOT+XNe5ZjJz5swz2Vnh5n3f57UYhmEgIiIiIiIiJ2R1dwEiIiIiIiKNnYKTiIiIiIhINRScREREREREqqHgJCIiIiIiUg0FJxERERERkWooOImIiIiIiFRDwUlERERERKQaCk4iIiIiIiLVsLu7gFPN5XKxf/9+/P39sVgs7i5HRERERETcxDAMcnJyiIyMxGqtekyp2QWn/fv3ExMT4+4yRERERESkkUhOTiY6OrrKc5pdcPL39wfMX05AQICbqxEREREREXfJzs4mJiamIiNUpdkFp/LpeQEBAQpOIiIiIiJSoyU8ag4hIiIiIiJSDQUnERERERGRaig4iYiIiIiIVKPZrXESEREREWlKDMOgtLQUp9Pp7lKaJA8PD2w220lfR8FJRERERKSRKi4u5sCBA+Tn57u7lCbLYrEQHR2Nn5/fSV1HwUlEREREpBFyuVzEx8djs9mIjIzE09OzRt3f5AjDMDh06BB79+6lY8eOJzXypOAkIiIiItIIFRcX43K5iImJwcfHx93lNFktW7YkISGBkpKSkwpOag4hIiIiItKIWa36K/vJqK9ROv2vICIiIiIiUg1N1XOjQzlFrElMJ9TPwYA2we4uR0RERERETkAjTm706cokbv5oLR8sS3R3KSIiIiIijVKbNm14+eWX3V2GRpzcqU9sEABxyZlurUNEREREpD6NHDmSPn361EvgWbVqFb6+vidf1EnSiJMb9YoOAiApPZ/DuUXuLUZERERE5BQp39S3Jlq2bNkougoqOLlRoLcH7Vua6Xn93kz3FiMiIiIijZ5hGOQXl57ywzCMGtd43XXXsXDhQl555RUsFgsWi4WZM2disVj46aef6N+/Pw6HgyVLlrB7924uuOACwsPD8fPzY+DAgfz222+VrvfnqXoWi4X//e9/XHTRRfj4+NCxY0e+/fbb+voVn5Cm6rlZn5gW7D6UR1xSJmd3CXd3OSIiIiLSiBWUOOn28C+n/H23PDYOH8+aRYdXXnmFHTt20KNHDx577DEANm/eDMB9993H888/T7t27WjRogXJycmce+65PPnkkzgcDj744AMmTpzI9u3biY2NPeF7PProozz77LM899xzvPbaa0yePJnExESCgxuu4ZpGnNysfJ3TOq1zEhEREZHTQGBgIJ6envj4+BAREUFERETFxrOPPfYYY8eOpX379gQHB9O7d2/+9re/0aNHDzp27Mjjjz9O+/btqx1Buu6667jqqqvo0KEDTz31FLm5uaxcubJBP5dGnNysb0wQAOuTM3G5DKzW+tmgS0REREROP94eNrY8Ns4t71sfBgwYUOnn3NxcHnnkEX744QcOHDhAaWkpBQUFJCUlVXmdXr16Vdz39fUlICCA1NTUeqnxRBSc3KxzhD8Ou5XswlLiD+fRvqWfu0sSERERkUbKYrHUeMpcY/Tn7nj33HMPc+fO5fnnn6dDhw54e3tz6aWXUlxcXOV1PDw8Kv1ssVhwuVz1Xu/Rmu5v/TThYbPSMyqQ1YkZxCVlKjiJiIiISJPn6emJ0+ms9rylS5dy3XXXcdFFFwHmCFRCQkIDV1c3WuPUCPQpm66n/ZxERERE5HTQpk0bVqxYQUJCAmlpaSccDerYsSNff/01cXFxrF+/nkmTJjX4yFFdKTg1AtoIV0REREROJ/fccw82m41u3brRsmXLE65ZevHFF2nRogXDhg1j4sSJjBs3jn79+p3iamvGYtSmKftpIDs7m8DAQLKysggICHB3OQDszchnxDPzsVstbHp0HF71tPhORERERJquwsJC4uPjadu2LV5eXu4up8mq6vdYm2ygEadGICrIm1A/B6Uug837s9xdjoiIiIiI/ImCUyNgsVgq1jmtS8p0ay0iIiIiInIsBadGoq/WOYmIiIiINFoKTo2EOuuJiIiIiDReCk6NRK/oQCwW2JtRQFpukbvLERERERGRoyg4NRL+Xh50KNv8Nk7rnEREREREGhUFp0ZE0/VERERERBonBadGpHwj3HXJGe4tREREREREKlFwakTKR5w2JGfhcjWrfYlFREREpJl45JFH6NOnT8XP1113HRdeeGGVrxk5ciR33nlng9ZVHbcGp0WLFjFx4kQiIyOxWCzMmTOn2tfMmjWL3r174+PjQ6tWrZg6dSqHDx9u+GJPgc7h/nh72MgpKmX3oVx3lyMiIiIi0uBeeeUVZs6c6e4yquXW4JSXl0fv3r2ZMWNGjc5funQpU6ZM4YYbbmDz5s188cUXrFy5kr/+9a8NXOmpYbdZ6RkVCMA6rXMSERERkWYgMDCQoKAgd5dRLbcGp/Hjx/PEE09w0UUX1ej8ZcuW0aZNG26//Xbatm3LiBEj+Nvf/sbKlSsbuNJTp482whURERGRJuztt98mMjISl8tV6fELLriAqVOnHnP+n6fq5eXlMWXKFPz8/GjVqhUvvPBCQ5dcI01qjdPQoUNJTk7mxx9/xDAMUlJS+PLLLzn33HNP+JqioiKys7MrHY1ZRWc9tSQXERERkT8zDCjOO/WHUfP195dddhmHDx9m/vz5FY+lp6fz888/M3ny5Gpff++997Jw4UK++eYbfv31VxYsWMDatWvr9OuqT3Z3F1Abw4cPZ9asWVxxxRUUFhZSWlrKxIkTq5zqN336dB599NFTWOXJKQ9O21NyKCh24u1pc29BIiIiItJ4lOTDU5Gn/n0f2A+evjU6tUWLFowfP56PP/6Y0aNHA/Dll18SGhrKqFGjWLx48Qlfm5ubyzvvvMNHH31U8dr333+f6Ojok/8MJ6lJjTht2bKFO+64g4cffpg1a9bw888/k5CQwM0333zC19x///1kZWVVHMnJyaew4tprFehFmL8Dp8tg474sd5cjIiIiIlJrkydP5quvvqKoqAgwG7xdeeWVWK1Vx4/du3dTXFzM4MGDKx4LDg6mc+fODVpvTTSpEafp06czfPhw7r33XgB69eqFr68vZ5xxBk888QStWrU65jUOhwOHw3GqS60zi8VCn5ggft2SQlxyBoPaBru7JBERERFpLDx8zNEfd7xvLUycOBHDMPjhhx8YOHAgixcv5qWXXmqg4k6NJhWc8vPzsdsrl2yzmVPZjFrMu2zs+sSWB6dMd5ciIiIiIo2JxVLjKXPu5OXlxcUXX8ysWbPYtWsXnTt3pl+/ftW+rn379nh4eLBixQpiY2MByMjIYMeOHZx11lkNXXaV3BqccnNz2bVrV8XP8fHxxMXFERwcTGxsLPfffz/79u3jgw8+AMzk+te//pU33niDcePGceDAAe68804GDRpEZKQb5no2EDWIEBEREZGmbvLkyZx33nls3ryZq6++ukav8fPz44YbbuDee+8lJCSEsLAwHnzwwWqn+J0Kbg1Oq1evZtSoURU/T5s2DYBrr72WmTNncuDAAZKSkiqev+6668jJyeH111/n7rvvJigoiLPPPptnnnnmlNfekHpFB2GxwP6sQlKzCwkL8HJ3SSIiIiIitXL22WcTHBzM9u3bmTRpUo1f99xzz5Gbm8vEiRPx9/fn7rvvJivL/Wv/LcbpNMetBrKzswkMDCQrK4uAgAB3l3NC415axPaUHN66pj/juke4uxwREREROcUKCwuJj4+nbdu2eHnpH9LrqqrfY22ygfvHvOS4KqbraZ2TiIiIiIjbKTg1Un1igwCtcxIRERERaQwUnBqpfrEtAFiblMGhnCI3VyMiIiIi0rwpODVSncL96B0dSFGpi/8t2ePuckREREREmjUFp0bKYrHwf2d3BOCjZYlk5BW7uSIRERERkeZLwakRG901jG6tAsgrdvLe0nh3lyMiIiIibtDMmmDXu/r6/Sk4NWLmqFMHAN77I4HswhI3VyQiIiIip4qHhwcA+fn5bq6kaSsuNmdu2Wy2k7qOWzfAleqN6x5Bp3A/dqTk8v7SBP5vdEd3lyQiIiIip4DNZiMoKIjU1FQAfHx8sFgsbq6qaXG5XBw6dAgfHx/s9pOLPgpOjZzVauHWUR2449M43lkaz/Uj2uLn0P9sIiIiIs1BREQEQEV4ktqzWq3ExsaedOjU38CbgPN6RfLybzuJT8vjo+WJ3HxWe3eXJCIiIiKngMVioVWrVoSFhVFSomUbdeHp6YnVevIrlBScmgCb1cItI9tz75cb+N/iPVw7tA3enic3R1NEREREmg6bzXbSa3Tk5Kg5RBNxYd8oolt4k5ZbzCcrk9xdjoiIiIhIs6Lg1ER42KzcMtLssPfWot0UljjdXJGIiIiISPOh4NSEXNI/ilaBXqRkF/HFmr3uLkdEREREpNlQcGpCHHZbRWOINxfsprjU5eaKRERERESaBwWnJuaKgTG09HewL7OAOev2ubscEREREZFmQcGpifHysHHTGe0AmLFgF6VOjTqJiIiIiDQ0BacmaPKQWIJ9PUk8nM9Xa7XWSURERESkoSk4NUE+nnZuGWmudXpp7k512BMRERERaWAKTk3U1UNaExnoxcHsQt7/I8Hd5YiIiIiInNYUnJooLw8bd43tBMB/Fuwmq6DEzRWJiIiIiJy+FJyasIv7RdMp3I+sghLeWrjb3eWIiIiIiJy2FJyaMJvVwr3jugDw7tJ4UrIL3VyRiIiIiMjpScGpiRvTNYz+rVtQWOLilXk73V2OiIiIiMhpScGpibNYLPzzHHPU6bNVyew5lOvmikRERERETj8KTqeBQW2DObtLGE6XwQtzd7i7HBERERGR046C02niH+d0xmKBHzYcYOPeLHeXIyIiIiJyWlFwOk10iQjgoj5RADzz8zY3VyMiIiIicnpRcDqN3DW2Ex42C0t2pbFkZ5q7yxEREREROW0oOJ1GYoJ9mDy4NWCOOrlchpsrEhERERE5PSg4nWZuO7sDvp42Nu7L4ufNB91djoiIiIjIaUHB6TQT6ufghhFtAXhr0R4MQ6NOIiIiIiInS8HpNDRlWBs87VbWJ2eyJjHD3eWIiIiIiDR5Ck6noVA/Bxf3NTvs/W9xvJurERERERFp+hScTlNTy6br/bLlIImH89xcjYiIiIhI0+bW4LRo0SImTpxIZGQkFouFOXPmVPuaoqIiHnzwQVq3bo3D4aBNmza8++67DV9sE9Mp3J+zOrXEMOC9pQnuLkdEREREpElza3DKy8ujd+/ezJgxo8avufzyy5k3bx7vvPMO27dv55NPPqFz584NWGXT9dcz2gHw+epksvJL3FyNiIiIiEjTZXfnm48fP57x48fX+Pyff/6ZhQsXsmfPHoKDgwFo06ZNA1XX9A3vEEKXCH+2Hczhk1VJ3HxWe3eXJCIiIiLSJDWpNU7ffvstAwYM4NlnnyUqKopOnTpxzz33UFBQcMLXFBUVkZ2dXeloLiwWS0Vr8plLEyhxutxckYiIiIhI09SkgtOePXtYsmQJmzZtYvbs2bz88st8+eWX3HLLLSd8zfTp0wkMDKw4YmJiTmHF7nd+n0ha+js4mF3IjxsPuLscEREREZEmqUkFJ5fLhcViYdasWQwaNIhzzz2XF198kffff/+Eo073338/WVlZFUdycvIprtq9HHYb1w5tDcB/F2tDXBERERGRumhSwalVq1ZERUURGBhY8VjXrl0xDIO9e/ce9zUOh4OAgIBKR3MzaXBrvDysbNqXzYr4dHeXIyIiIiLS5DSp4DR8+HD2799Pbm5uxWM7duzAarUSHR3txsoat2BfTy7pZ/5+tCGuiIiIiEjtuTU45ebmEhcXR1xcHADx8fHExcWRlJQEmNPspkyZUnH+pEmTCAkJ4frrr2fLli0sWrSIe++9l6lTp+Lt7e2Oj9BklG+IO29bCnsO5VZztoiIiIiIHM2twWn16tX07duXvn37AjBt2jT69u3Lww8/DMCBAwcqQhSAn58fc+fOJTMzkwEDBjB58mQmTpzIq6++6pb6m5L2Lf0Y0zUMw4B3l2rUSURERESkNixGM+sWkJ2dTWBgIFlZWc1uvdOy3Ye56r/L8fKwsuy+0bTw9XR3SSIiIiIiblObbNCk1jjJyRnSLpjukQEUlriYtSLR3eWIiIiIiDQZCk7NiMVi4a9ntAPg3aUJ5BeXurkiEREREZGmQcGpmTmvVytah/iQnlfMh8s06iQiIiIiUhMKTs2M3WbltlEdAHh70R6NOomIiIiI1ICCUzN0Ud8oWof4cDivmI+Wa9RJRERERKQ6Ck7NkN1m5dayUae3FmrUSURERESkOgpOzdRFfaOIDTZHnWYtT6r+BSIiIiIizZiCUzPlcdRap7cW7aag2OnmikREREREGi8Fp2bson5RxAR7k5ZbrH2dRERERESqoODUjB096vTmQo06iYiIiIiciIJTM3dxv2iiW2jUSURERESkKgpOzVzlUac9GnUSERERETkOBSc5atSpSKNOIiIiIiLHoeAkeNqP2tdp0R4KSzTqJCIiIiJyNAUnAeCSftFEBXlzKKeIWSu0r5OIiIiIyNEUnASoPOr05sLdFJVq1ElEREREpJyCk1S4tH80EQFeHMop4pu4/e4uR0RERESk0VBwkgqedivXDW8DwDuL4zEMw70FiYiIiIg0EgpOUslVA2Px8bSxPSWHxTvT3F2OiIiIiEijoOAklQT6eHD5gBgA/rck3s3ViIiIiIg0DgpOcoypw9titcCiHYfYfjDH3eWIiIiIiLidgpMcIzbEh3HdIwB4Z8keN1cjIiIiIuJ+Ck5yXDee0Q6AOev2k5pT6OZqRERERETcS8FJjqt/6xb0jQ2i2Onio2WJ7i5HRERERMStFJzkhP5aNur04fJECoq1Ia6IiIiINF8KTnJCf+kWTnQLbzLyS/h63d4Ge5/N+7PYvD+rwa4vIiIiInKyFJzkhOw2K1OHtwXMDXFdrvrfEDcrv4RL31jGRTP+YM+h3Hq/voiIiIhIfVBwkipdPjAGfy87e9LymL89td6vv2BHKgUlToqdLp76cWu9X19EREREpD4oOEmV/Bx2Jg2KBeC/i+u/Nfnv246Esd+2prJ456F6fw8RERERkZOl4NQYGPU/Ba4+XTe8DXarheV70tm0r/7WIpU6XSzYbgal/q1bAPDE91spdbrq7T1EREREROqDgpM7rf8M/jMUfnvE3ZVUqVWgNxN6tQLMUae8olL2Zxaw9UA2K/Yc5tfNB/lidTKfr06uVfe9NYkZZBWUEOTjwdvX9CfIx4PtKTl8uiq5oT6KiIiIiEid2N1dQLPmKoHULeAV5O5KqnXjiHZ8E7e/4jiRPYfyuG98lxpds3ya3qjOYYT4ObhrTCf+/e1mXpy7g4m9Iwn09qiX2kVERERETpZGnNwpaoB5eyAOnKVuLaU6PaMDGdM1rOJnu9VCiK8n7UJ96R0TRL/YIAC+XLO3xlPt5pUFp7O7mNedNDiWDmF+pOcV8/rvO+v3A4iIiIiInASNOLlTaCdwBEBRtjny1KqXuyuq0tvXDCAttwg/LzveHjYsFkvFcyVOF0OemkdabhGLd6YxqktYFVeCxMN57ErNxW61cGanlgB42Kz8a0JXrntvFTP/SGDS4Na0DfVt0M8kIiIiIlITGnFyJ6sVIvua9/etdm8tNWC1WggL8MLH014pNIEZes7vEwmYo07VmbfVHG0a2Ca40pS8kZ3DGNm5JSVOgyd/UHtyEREREWkc3BqcFi1axMSJE4mMjMRisTBnzpwav3bp0qXY7Xb69OnTYPWdEtEDzdu9jT84VefS/tEAzN2SQmZ+cZXnlq9vGt312JGpf03ohs1q4betKSzZmVb/hYqIiIiI1JJbg1NeXh69e/dmxowZtXpdZmYmU6ZMYfTo0Q1U2SkUXbbO6TQITt0jA+naKoBip4vv1p+4gUROYQkr4g8DR9Y3Ha1DmB/XDGkNwOPfb1F7chERERFxO7cGp/Hjx/PEE09w0UUX1ep1N998M5MmTWLo0KENVNkpVN4gIm0HFNbfHknuUj7qVNV0vSU70yhxGrQN9aVdS7/jnnPnmI4EepvtyT9brfbkIiIiIuJeTW6N03vvvceePXv497//XaPzi4qKyM7OrnQ0Kn4tISgWMGDfWndXc9Iu6BOJ3Wph/d4sdqbkHPec8m56o6toIBHk48ldYzoC8MKvO8jKL6n/YkVEREREaqhJBaedO3dy33338dFHH2G316wh4PTp0wkMDKw4YmJiGrjKOihf59QEGkRUJ9TPwcjOZiD6cu2xo05Ol8H88jbkx1nfdLTJQ1pXtCf/x1frMQyj/gsWEREREamBJhOcnE4nkyZN4tFHH6VTp041ft39999PVlZWxZGc3AinfUWdPuuc4Mh0vdlr9x2zPmn93kwO5xXj77AzsE1wldfxsFl58fLeeNqs/LI5hXeXJjRUySIiIiIiVWoywSknJ4fVq1dz2223YbfbsdvtPPbYY6xfvx673c7vv/9+3Nc5HA4CAgIqHY3O0Q0iToNRlbO7hNHCx4PUnCIW76rcFe/3sjbkZ3ZuiYet+q9fr+gg/nVeVwCm/7iVtUkZ9V+wiIiIiEg1mkxwCggIYOPGjcTFxVUcN998M507dyYuLo7Bgwe7u8S6i+gFVg/IT4PMRHdXc9I87VYu6BMFwFd/ahJRvr5pTDXT9I52zZDWTOjVilKXwW2z1pKRV3WrcxERERGR+ubW4JSbm1sRggDi4+OJi4sjKSkJMKfZTZkyBQCr1UqPHj0qHWFhYXh5edGjRw98fX3d9TFOnocXRPQw759m0/V+3ZJS0dhhf2YBWw9kY7XAWZ1qHpwsFgtPX9yTtqG+7M8qZNrncbhcTX9kTkRERESaDrcGp9WrV9O3b1/69u0LwLRp0+jbty8PP/wwAAcOHKgIUae9igYRa9xbRz3pHhlAlwh/iktdfLfB3NOpfLSpX2wLgn09a3U9fy8PZkzqh8NuZf72Q7y5aHe91ywiIiIiciJuDU4jR47EMIxjjpkzZwIwc+ZMFixYcMLXP/LIIxWjVU1eRYOIVe6to55YLJZj9nT6fWsKUH03vRPpFhnAYxd0B+D5X7azfM/heqhURERERKR6TWaN02mvvEHEgQ1Qenqs4bmgTxQ2q4W45Ew27cti6W4z6IzpGl7na14+IIaL+0XhMuD2T9ZxKKeovsoVERERETkhBafGIrgdeLcAZxGkbHR3NfWipb+DkZ1aAvCPLzdQXOoiuoU3HcP86nxNi8XCExf2oGOYH6k5Rdz52TqcWu8kIiIiIg1MwamxsFggqr95f+/psc4JjjSJ2HIgG4DRXcKwWCwndU0fTztvXN0Pbw8bS3cd5r2l8Sddp4iIiIhIVRScGpOKBhGnR2c9MNczBfl4HPVz3afpHa1DmD8PnNsFgI+WJ2LUcv+rF37dzgOzNx6zQa+IiIiIyPEoODUmp1mDCACH3cYFvSMB8PG0MaRdcL1d++J+0fh62kg4nM+qhJpvjLtlfzav/b6Lj1ck8a5Gq0RERESkBhScGpOofuZt+h7IT3dvLfVoyrA2BPl4MGlQLA67rd6u6+uwc14vM5R9vjq5xq/7aMWRTYZfnLuDxMN59VaTiIiIiJyeFJwaE59gCG5v3j9N9nMCaN/Sj7iH/8K/zutW79e+fKC5huqHDQfILSqt9vycwhLmrNsHQEywN4UlLh6YvbHWU/1EREREpHmpU3B6//33+eGHHyp+/sc//kFQUBDDhg0jMTGxildKtcrbku89fdY5NaR+sS1o19KXghInP5RttFuVOev2kV/spEOYHx9OHYzDbmXprsN8tXbfKahWRERERJqqOgWnp556Cm9vbwCWLVvGjBkzePbZZwkNDeWuu+6q1wKbndOwQURDslgsXD4gBoDPV++t8lzDMPhwuRnsJw+OpU2oL3eO6QTA499v0Z5QIiIiInJCdQpOycnJdOjQAYA5c+ZwySWXcNNNNzF9+nQWL15crwU2OxUtyVeDpo/VyMV9zY121yRmsCs194TnrUrIYEdKLt4eNi7uZ07xu/GMtnRrFUBWQQmPfb/lVJUsIiIiIk1MnYKTn58fhw8fBuDXX39l7NixAHh5eVFQUFB/1TVH4T3A5oDCTDi8293VNAlhAV6M6mxutPvFmhM3ifiobLTpgj6RBHqbLdI9bFaeuaQXVgt8t34/v29LafiCRURERKTJqVNwGjt2LDfeeCM33ngjO3bs4NxzzwVg8+bNtGnTpj7ra37sntCqt3lf0/Vq7LKy6XpfrdlHyXH2ZjqUU8RPmw4AcPWQ1pWe6xkdyI1ntAPgX7M31ajJhIiIiIg0L3UKTjNmzGDo0KEcOnSIr776ipCQEADWrFnDVVddVa8FNktqEFFrZ3cJI9TPk7TcIhZuP3TM85+vTqbEadAnJogeUYHHPH/XmE7EBvuwP6uQ53/ZfipKFhEREZEmxF6XFwUFBfH6668f8/ijjz560gUJR4KTRpxqzMNm5aK+Ufx3cTyfr05mTLfwiuecLoOPVyQBx442lfP2tPHURT25+p0VvL8sgYm9I+nfusUpqV1EREREGr86jTj9/PPPLFmypOLnGTNm0KdPHyZNmkRGRka9FddsRZUFp4MboURrxmqqfLre79tSK3XIW7gjlX2ZBQR6e3Ber1YnfP2IjqFc2j8aw4D7v95AcemxU/5EREREpHmqU3C69957yc7OBmDjxo3cfffdnHvuucTHxzNt2rR6LbBZCooF35bgKoUDG9xdTZPRKdyfPjFBlLqMik1uAT5cZjaFuKx/NF4etiqv8eC5XQn182RHSi5vLVRzDhEREREx1Sk4xcfH061bNwC++uorzjvvPJ566ilmzJjBTz/9VK8FNksWy5FRJ03Xq5UjezolYxgGyen5LNhhrnmafIJpekdr4evJQ+eZ3+3X5u8iIS2v4YoVERERkSajTsHJ09OT/Px8AH777Tf+8pe/ABAcHFwxEiUnSQ0i6uS83q3w8rCyMzWXuORMPl6ZhGHAGR1DaRvqW6NrnN87khEdQikudfHQN5swtJ+WiIiISLNXp+A0YsQIpk2bxuOPP87KlSuZMGECADt27CA6OrpeC2y2FJzqJMDLg3N7mOuYPlqexGerzH2dJg+ufrSpnMVi4YkLe+Bpt7J4ZxrfbTjQILWKiIiISNNRp+D0+uuvY7fb+fLLL3njjTeIiooC4KeffuKcc86p1wKbraj+YLVDVhKkx7u7mialYk+ntXtJzysmIsCLMV3DanWNNqG+3DaqAwCPfbeFrIKSeq9TRERERJqOOrUjj42N5fvvvz/m8ZdeeumkC5IyDn+IHghJy2DPAghu6+6KmozBbYOJDfYhKd2cTnrVoFjsttr/G8HfzmrHnLh97DmUx3O/bOOJC3vWd6kiIiIi0kTUacQJwOl08tVXX/HEE0/wxBNPMHv2bJxOZ33WJu1Gmrd7FriziibHarVwWX9zyqjNauHKQTF1uo7DbuPJsrA0a0US65LUal9ERESkuapTcNq1axddu3ZlypQpfP3113z99ddcffXVdO/end271cK53rQbZd7GLwSX9hSqjasGx9I7OpC/n9We8ACvOl9naPsQLuln7u30wOxNlDqb1v8OC7an8s6SeDW4EBERETlJdQpOt99+O+3btyc5OZm1a9eydu1akpKSaNu2Lbfffnt919h8RfUDT38oyICD2s+pNkL9HHxz2wjuGdf5pK/14ISuBPl4sPVANu8tTTj54k6RhTsOccP7q3n8+y2siE93dzkiIiIiTVqdgtPChQt59tlnCQ4OrngsJCSEp59+moULF9Zbcc2ezQPajDDv75nv3lqasWBfTx4Y3xWAF+fuYF9mgZsrqt72gzncNmstTpc50rRkZ5qbKxIRERFp2uoUnBwOBzk5Occ8npubi6en50kXJUfROqdG4dL+0QxqE0xBiZN/f7PZ3eVU6VBOEVNnriKnqJRAbw8Alu5WcBIRERE5GXUKTueddx433XQTK1aswDAMDMNg+fLl3HzzzZx//vn1XWPzVh6cEpdBSeMf6ThdWa0WnrioB3arhd+2pvD491vYtC+r3tYOxaflMWP+LvKLS0/qOoUlTv76wWr2ZRbQJsSHj/86GID1yZlkF6qluoiIiEhd1Sk4vfrqq7Rv356hQ4fi5eWFl5cXw4YNo0OHDrz88sv1XGIz17Iz+LcCZxEkr3B3Nc1ap3B//j6yPQDvLInnvNeWMOKZ+Tzy7WaW7T5c58YRhSVOps5cxXO/bOfFX3fUuT6Xy+CeL9YTl5xJoLcH7143kO6RgbQN9cVlwIo9WuckIiIiUld12scpKCiIb775hl27drF161YAunbtSocOHeq1OAEsFnPUaf0nsHv+kREocYu7xnSiY7g/P244wMIdh9iXWcDMPxKY+UcCLXw8GN01nOuGtaFHVGCNr/mf+buIT8sD4KMVidx0VjvC/GvfCfCl33bw/YYDeNgsvHVNf9q19ANgWPsQ4tPyWLorjbHdwmt9XRERERGpRXCaNm1alc/Pn3+kecGLL75Y94rkWOXBSeuc3M5qtXB+70jO7x1JYYmTxTvT+GXzQeZtTSEjv4Qv1+zl500H+fa24RXBpSo7U3J4Y6HZwj/Uz0FabhFvLtjDwxO71aqur9bs5bXfdwHw1EU9GdIupOK5ER1CmbUiiaW7tM5JREREpK5qHJzWrVtXo/MsFkudi5ETaHuWeXtgPeSng09w1efLKeHlYWNst3DGdgun1OliVUIGz/2yjbVJmfz9o7XMvnUYPp4n/r+Yy2XwwOyNlDgNRncJY8qwNlz77ko+WpHI385qV+P9p1bsOcx9X5vt6m8Z2Z7LBlTe8Hdo+xAsFtiZmktKduFJ7WslIiIi0lzVODgdPaIkp1hAK2jZBQ5tg/hF0P1Cd1ckf2K3WRnaPoQ3r+nPhFeXsD0lh3/N3sQLl/c+4T8mfLY6mVUJGfh42njswh5EBnrRv3UL1iRm8MaC3Txyfvdq33dfZgF/+2gNJU6Dc3tGcM9fjt23KsjHkx6RgWzcl8Ufu9O4qG/0SX9eERERkeamTs0hxA3ajTJvNV2vUQvz9+K1q/pis1r4et0+PlmZfNzzUnMKmf6juT5w2thORAV5Y7FYuGtMJwA+XpnEwazCKt+r1Oni9k/WkZlfQs+oQF64rA9W6/FD2vAOoQAs2Xm4rh9NREREpFlTcGoqKvZz0shfYzekXQj3jjNHfh75djMb92Ydc87j328lu7CUHlEBXDesTcXjwzuEMLBNC4pLXfxnwa4q3+fl33ayJjEDf4edGZP64e1pO+G5wzuYa57+2J1Wby3URURERJoTBaemos1wsNggIwHS491djVTjb2e2Y2y3cIqdLv4+aw2Z+cUVzy3Ynsp36/djtcDTF/fCbjvyf0OLxcJdY81Rp09XJrM/8/h7dy3dlcaMsmD11MU9iQ3xqbKegW2C8bRbOZBVyJ6yDn4iIiIiUnNuDU6LFi1i4sSJREZGYrFYmDNnTpXnf/3114wdO5aWLVsSEBDA0KFD+eWXX05Nse7m8Ifogeb9+IXurUWqZbFYeP6y3sQG+7A3o4C7P1+Py2WQX1zKv+ZsAuD64W2P27Z8WPtQBrcNptjpYsb8Y0ed0nKLuPOzOAwDrhoUw8TekdXW4+Vho39sCwD+UHc9ERERkVpza3DKy8ujd+/ezJgxo0bnL1q0iLFjx/Ljjz+yZs0aRo0axcSJE2vc8a/Jq5iut8CdVUgNBXp78J/J/fC0W5m3LZU3Fu7mld92sjejgKggb6aVjSwdT/mo0+erk9mbkV/xuMtlcPfn6zmUU0THMD8ePq/6BhLlRnQsW+ek4CQiIiJSa3XaALe+jB8/nvHjx9f4/JdffrnSz0899RTffPMN3333HX379q3n6hqh9qNg4dOwZyG4XGDVTMvGrkdUII9f0J1/frWRF37dXtFh77ELuuPrOPH//Ya0C2FouxCW7TnMjPm7mX5xTwD+t2QPC3ccwmG38no165r+bFh7c53Tst2HcboMbCdoJCEiIiIix2rSf/N2uVzk5OQQHNxM9jWK6g+eflCQDgc3uLsaqaErBsZyWf9oXAY4XQbje0Qwumt4ta8rH3X6YnUyyen5xCVn8uzP2wH498TudI7wr1UdPaMC8feyk11YyqZ9xzasEBEREZETa9LB6fnnnyc3N5fLL7/8hOcUFRWRnZ1d6WiybB7QZoR5X9P1mpTHL+xBv9ggwgMcNdqfCWBQ22BGdAil1GXwzM/b+L9P1lLqMpjQsxVXDYqp/gJ/YrdZGdLOHHVaulvT9URERERqo8kGp48//phHH32Uzz//nLCwsBOeN336dAIDAyuOmJja/4WzUdE6pybJy8PGlzcPY9l9owkP8Krx6+4a2xGA7zccIDm9gOgW3jx1cc8TbqpbnRFl+zkt1TonERERkVppksHp008/5cYbb+Tzzz9nzJgxVZ57//33k5WVVXEkJx9/Q9Imozw4JS2Dkqo3SJXGxWq1nHCD2hPp3zqYM8qaOtitFl69qi+B3h51rqF8P6dVCRkUljjrfB0RERGR5qbJBadPPvmE66+/nk8++YQJEyZUe77D4SAgIKDS0aS17AJ+EVBaCMnL3V2NnAL/mtCNLhH+ZdP9WpzUtdq39CM8wEFxqYs1iRn1VKGIiIjI6c+twSk3N5e4uDji4uIAiI+PJy4ujqSkJMAcLZoyZUrF+R9//DFTpkzhhRdeYPDgwRw8eJCDBw+SldWMFrpbLJqu18x0jvDn5zvP5KpBsSd9LYvFwnBN1xMRERGpNbcGp9WrV9O3b9+KVuLTpk2jb9++PPzwwwAcOHCgIkQBvP3225SWlnLrrbfSqlWriuOOO+5wS/1uo+AkJ2F4ewUnERERkdpy6z5OI0eOxDCMEz4/c+bMSj8vWLCgYQtqKtqdZd7uj4PcVPA7cXMMkT8rH3HauC+LrPwSAn3qvmZKREREpLlocmucBAiIhMi+gAE/TIMqwqfIn0UEetG+pS8uA5btOezucpq0/OJSd5cgIiIip4iCU1N13ktgtcPW72DdR+6uRpqY8rbkf2g/pzpxuQzu/HQdfR+by7fr97u7HBERETkFFJyaqsi+MOpB8/5P/4T0Pe6tR5qUYWXBaYnWOdXJm4t2MyduP0WlLu75Yj1rEtPdXZKIiIg0MAWnpmz4HdB6OJTkwdc3gVPThqRmhrQLwWqBPYfyOJBV4O5ympQlO9N4/pftALRv6UtxqYubPlhD0uF8N1cmIiIiDUnBqSmz2uCit8ARCHtXwaLn3F2RNBGB3h70jA4C4Kq3l3PfVxv4YnUy8Wl5VTZsaUhrEtO55p0VvDpvJ6VOl1tqqM6+zAJu/3QdLgMuHxDNd/83gh5RARzOK2bq+6vIKihxd4kiIiLSQCyGu/6W5CbZ2dkEBgaSlZXV9DfDLbfxS/jqBrDYYOrPEDPI3RVJE/DJyiQemL3xmN4ioX6e9IttwYA2LZjQK5KoIO8GrSO/uJTnftnOzD8SKmoZ0i6YV6/qS5i/10ld+1BOEWsS09mbUcC47hHEBPvU+VqFJU4uf2sZG/Zm0SMqgC9vHoaXh42U7EIueH0pB7MLGdEhlPeuH4iHTf8mJSIi0hTUJhsoOJ0uvroRNn4BLdrAzUvA4e/uiqQJSM8rZm1iBqsS01mTkMGGvVkUHzXa42mzMmlwLLeO6kBLf0e9v/8fu9O476uNJKWb09zGdgvnj11p5BU7CfVz8OpVfRhWtu9UdQzDYPehPFYnpLMqIYM1iekkHDV9zt/LzrOX9GJ8z1Z1qvX+rzfyycokgnw8+O62EZVC2Ob9WVz25jLyi51cNSiGpy7qicViqdP7VMXlMjiQXdjgYVZERKS5UHCqwmkbnAoy4c0RkJUMfa+GC2a4uyJpgopKnWzal8XqhAzmbU1lZYLZ9MDbw8b1w9vwtzPb18u+T7lFpUz/cSuzVpgbXEcGevHUxT0Z2TmM3YdyueWjtWxPycFqgWljO3HLyA5YrccGkRKniyU70/h2/X4WbE8lI7/yVDmLBTqHm/+IsO1gDgBThrbmgXO74uVhq3G9n69K5h9fbcBigZnXD+KsTi2POWfe1hT++sFqXAY8eG5X/npmuxpfvybyi0uZOnMVy/ek8+wlvbh8YEy9Xl9ERKQ5UnCqwmkbnAASlsLMCYABl38I3c53d0XSxC3dlcazv2xnfXImYI7a3HxWe64b1gZfx7H7Z5c4XWTml5BfXIrVYsFqtWC3WrBaLNisFmwWC2uTM/jX7E3syzSbUkwaHMv947vg73UkkBUUO3nom018uWYvAGd1aslLV/Qh2NcTl8tgZUI6367fz08bD1QKSw67ld4xQQxs04IBbYLpF9uCQG8PSpwunv91O28tNLtPdo8M4PVJ/Wgb6lvt72Dj3iwuefMPiktd3D22E/83uuMJz313STyPfb8FiwXevLo/47pHVP9LroGCYidTZ66q2Hcr0NuD+feMJNjXs16uLyIi0lwpOFXhtA5OAL89CkteBO8W8PdlEFC3aUki5QzDYO6WFF74dQfbU8xRm1A/T4Z3CCWroISM/BIy8orJyC8mp7DmnR1jgr155uJeFa3Rj+fz1ck8NGcTRaUuWgV6Ma57BD9vOsjB7MKKc0L9PJnQsxUTekXSJyYIT/uJ1xfN357K3Z+vJz2vGF9PG9Mv6cX5vSNPeH5GXjHnvbaEfZkFjOkaxtvXDDjuyFc5wzB4+JvNfLg8EW8PG+9PHcSgtsHV/CaqVlji5Mb3V7NkVxp+Djst/R3Ep+Vx5cAYnr6k10ldW0REpLlTcKrCaR+cSovhnbFwIA76XwcTX3F3RXKacLoMvt+wn5fm7qi0dujPLBZzap/LMHC5wGkYOF1H/jPjYbMweXBr7h3X+bijVn+29UA2t85ay560vIrH/L3snNM9gvP7RDK0XQj2WjRjOJhVyO2frKuYhnjVoFiuGhRDanYRKTmFpGQXkZpdSGpOEdsP5rAvs4DWIT58e9sIAr2rn6ZY6nRxw/urWbjjEFYL3DKyA7eP7lhloDuRwhInf/twDQt3HMLH08YHUwdhAJe9uQyLBWbfMpw+MUG1vq6IiIiYFJyqcNoHJ4DEZfDeOWDzhDs2aNRJ6lWJ08WPGw9wIKuQYB9PWvh60sLHo+zWk0BvD2x/GpUxDAOXYYYvi4Vad53LKSzh6Z+2kVNYyoRerTirU8tarVH6s1Kni1fm7eT1+buO6Sr4Z34OO1/cPJSurWr+34vcolIemrOJ2ev2AdCtVQAvXdGHzhE1b9pSVOrk7x+t5fdtqXh72Jh5/UAGtwsBYNpncXy9bh+9ogOZfcvwY37fIiIiUjMKTlVoFsEJ4N3xkPQHDL0Nxj3p7mpEGqUlO9P497ebyC0qJTzAizB/B2EBXoT7exEe4CAswEGv6CBC/erWUfDHjQd4cPZGMvJL8LRZuWdcJ24Y0a7aoFNc6uKWWWv5bWsKXh5W3r1uYKXugqk5hYx+fiE5RaU8dVFPJg2OrVN9IiIizZ2CUxWaTXDa+RvMugQ8fOGuTeBzcussRKRuUnMKuf+rjczblgrAoDbBPH9Zb2JDjr+nVInTxf99vI6fNx/EYbfyzrUDGdHx2HVg7yyJ5/HvtxDk48H8u0fSQo0iREREak3BqQrNJjgZBrx1JhzcACPvh5H3ubsikWbLMAw+X53MY99tIa/YiY+njdFdwykpdVFU6qSo1EVhiXmbmV/CvswCPG1W/nvtgOO2PgdzuuGEV5ewPSWHSYNjeeqinqf4U4mIiDR9Ck5VaDbBCWDzbPjiOvAKMkedtCmuiFslp+dz9xfrWRmfXuV5njYrb17Tj7O7hFd53oo9h7ni7eVYLPDNrcPpFR1Uj9WKiIic/hScqtCsgpPLCTMGweFd8JcnYNj/ubsikWbP5TL4YeMBUrILcXjYcNitOOxWvCru22jf0pewAK8aXe+OT9fxTdx++sQE8fXfh1XZLl1EREQqU3CqQrMKTgBrP4RvbwO/CLhzA9jrtshdRBqnlOxCzn5+AXnFTp65pCdXDDzSKCIjr5hVCemsiE9nTWIGfWKC+PfEblgsDR+uDMPg5d924uuwcdOZ7Rv8/UREROqiNtmg+k1UpGnrdQUsmA7Z+yDuYxhwvbsrEpF6FB7gxZ1jOvHkj1t55uftOOw21iRmsDI+vWLD4nJxyZl0jvDnqkEN34Xvj92HeWXeTgDahPjyl+4RDf6eIiIiDUkjTs3B8jfg5/ugRRu4bQ3YlJdFTiclThfnvrKYnam5xzzXIcyPwW2DMYCPVyTh42njx9vPoE2ob4PWdMPMVRWdBMMDHMyddhYBXtVvIFyd3KJSXvh1Oy6XQVQLb6KCfIhu4U1UC29CfD1PyWiaiIicPjTiJJX1mwKLnoOMBNgyB3pe6u6KRKQeedisPH1JT/724RrC/L0Y1DaYIe2CGdAmuGIPKpfLYM+hXJbvSeeuz+P44m9DsddyI+Kaik/LqwhNkYFe7M8q5Omftp105z+Xy2DaZ3H8uiXluM97eViJDPLm3B6tuPsvnRSiRESkXjXMn5rSuHj6wuC/m/cXvwAul3vrEZF61791MKv/NZYf7ziDR87vzjk9WlXauNdqtfDC5X3wd9hZl5TJfxbsbrBa3v8jAYCzu4Tx4hV9AHO0a8Wewyd13dfn7+LXLSl42qxMHd6Wib0j6RcbRHiAA4sFCktc7DmUx+vzd/H12n0n+SlEREQqU3BqLgbdCJ7+kLoFdv7i7mpExA2igrx57MLuALwybyfrkzPr/T2yCkr4fHUyANcPb8OQdiEVa6ru/3ojhSXOOl133tYUXvptBwCPX9idhyd247Wr+vL1LcNZ8cAYtj1+DgvvHcnNZ5mNKJ76cStZ+SX18IlERERMCk7NhXcLGDjVvL/4BXODXBFpdi7sE8WEXq1wugzu+iyOguK6BZkT+WJ1MvnFTjqG+TGiQygA943vQpi/gz1pebz2+85aX3P3oVzu/DQOw4Crh8RW6hxYzmG30TrEl2ljO9ExzI/DecU8+8u2k/48IiIi5RScmpMht4LNAXtXQcISd1cjIm5gsVh48sIehAeYQeapH7fW27WdLoOZZdP0po5oW7HGKNDbg8cv7AHAWwv3sGV/do2vmVNYwk0frCanqJSBbVrw8Hndqzzf026teK+PVyYR1wCjaiIi0jwpODUn/uHQ7xrz/vd3Qc5B99YjIm4R5OPJ85f1BuDD5YnM355aL9eduyWFvRkFBPl4cGGfqErPjesewfgeEZS6DO77egOlzurXWrpcBtM+X8/uQ3lEBHgxY3I/PO3V/7E1pF0IF/eLwjDgwdkba/Re7pBfXMqsFYkcyilydykiIlIDCk7NzRn3QEAUHN4JM89TeBJpps7o2JLrhrUB4B9fbiA9r/ikr/ne0ngAJg2KxdvTdszzj17QnQAvOxv2ZvHe0oRqr/fa77uYuyUFT7uVN6/pT5i/V41reeDcrgR6e7B5fzYfLk+s8etOFcMwuPPTOB6cvYmbPlyN01Xz6dMul8E/vlzPJW/8QeLhvAasUkREjqbg1NwEtILrvoeA6LLwNAGyD7i7KhFxg/vGd6FDmB+Hcoq4/+sNuGrxl/c/27QvixXx6ditFq4Z2vq454T5e/HghK4AvDB3O0mH8094vd+2HGkG8cSFPegTE1SrekL9HPzjnM7me/26g9Tswlq9vqG9syS+oq36uqRMPqpFuJu1IpHPV+9lTWIGl725jJ1/2uhYREQahoJTcxTcDq7/AQJj4fCusvC0391Vicgp5uVh4+Ur+mC3WvhlcwrXzVxFWm7dpo2VjyCN79mKVoHeJzzv8gExDG0XQmGJizs/W8fbi3YzY/4uXpq7g2d/3saTP2zhkW83c9dncQBMGdqaywfE1KmmqwbG0jsmiNyiUh7/of7Wcp2sNYnpPP2T2bjijI5mA41nf97G/syCal+bdDifp340X9vCx4PUnCKueHs5m/ZlNVzBIiICKDg1Xy3amCNPQbGQvhveOxey9rq7KhE5xXpEBfL8Zb1x2K0s2nGIc19ZzB+70mp1jUM5RXy33vzHl6nD21R5rsViYfrFPXHYraxNyuSpH7fx3C/beWXeTv6zYDf/XRzPzD8SyCkqZVDbYB46r1tdPxpWq9kIw2qB79bvZ/HOQ1WeX1Ravx0Gj+dwbhG3zlpHqctgYu9I3r9+EANatyCv2MlDczZhVNHx1OUyuPfL9RSUOBnSLph5d4+kV3Qg6XnFXPX2ctYkpjd4/SIizZnFqOq/0qeh7OxsAgMDycrKIiAgwN3luF9mkrnWKTPRDFPXfg9BdfvXXRFpurYfzOG2j9eyMzUXiwX+b1QHbh/dEbut+n9fe/m3Hbz82076xAQx59bhNXq/Xzcf5LsNB/CwWvCwWfGwm7eeNiseNistfD25bEA0AV4eJ/vReOTbzcz8I4G2ob78dMcZeHmY66+cLoO45EzmbU1h3tZUtqfk0Dncn3N6RDC+ZwSdw/0rOgPWB6fL4Lr3VrJ4ZxrtWvry7W0j8HPY2ZmSw7mvLqbEafD6pL6c1yvyuK+fuTSeR77bgo+njZ/vOJPYEB9yCku4YeZqViak4+1h479TBjCibBSrOXO6DD5blUy/1kF0idCf9SJyYrXJBgpOApnJ8P55kJEAQa2PjESJSLNSUOzkkW8381nZBraD2gbzypV9qpx6V1TqZPjTv5OWW8yrV/Xl/N7H/0u/O+UUljD6hYWk5hRxy8j29IoO5LetqczflsrhKppitA31NUNUjwh6RgWedIh65bedvPTbDrw8rHxz6wg6R/hXPFcePkP9PPlt2lkE+XhWem1CWh7jX1lMQYmTxy/ozjVD21Q8V1Ds5KYPV7N4ZxqeNiv/mdyPMd3CT6rWpu6thbuZ/tM2YoK9WXDPKGzW+gvAInJ6UXCqgoLTCWTtM8NT+h4IjIHJX0JYF3dXJSJu8E3cPh74eiN5xU5a+Hjw/GW9ObtL2HGDw1dr9nL3F+uJCPBi8T9H4VGDESp3+Hb9fm7/ZN0xj/t72TmrU0vGdA2nf+sWrEpI58eNB1m08xDFpUfamEcFeXPHmI51Xm+1eOchpry7EsOAFy7rzSX9oys9X1TqZMKrS9iVmsvlA6J59tLeFc+5XAZXvL2MVQkZDGsfwkc3DMb6pyBQVOrk9k/W8cvmFOxWCy9e0adRhthTISW7kLOfX0Be2ebOb17dj3N6tHJzVSLSWCk4VUHBqQrZ++H9881ue45AuHIWtD3D3VWJiBvEp+Xxf5+sZdM+c7NaP4ed1iE+tAnxrXT76Hdb2HIgm3vHdebWUR3cXPWJGYbBje+vZt62VNqE+DC6aziju4YxsE3wccNeblEp87el8tOmA8zfdoiCEicWC7xz7QDO7lK70ZyDWYVMeHUxh/OKuXJgDE9f0uu4561JTOfSN5dhGPDxjYMZ1sGccvfOknge/34Lvp42fr7zTGKCfY77+lKni3u/3MDsdfuwWOCuMZ24dVSHZjfactdnccxetw+71UKpy2BA6xZ8+fdh7i5LRBopBacqKDhVIz8dPrkKkpeDzRMu+A/0uszdVYmIGxSVOnn6p218uCyR0ipalTvsVpbfP5oWvp4nPKcxKHG6SM8rJszfUatpd0dPYfR32Jlz23Dat/Sr8Xte9fZyVidm0K1VAF/fMqxijdXxPDRnEx8uT6R1iA+/3Hkm+zMLOPfVxRSWuHjyoh5MHnz8Vu/lXC6Dh7/dxEfLkwAY3DaYl67oQ2TQiadbHi2roARPm/W4+3A1BasTzPBpscDb1wzglllrKHEazLl1eK1b2otI86DgVAUFpxooKYTZf4Mtc8yfR/8bRtwF9bhIWkSajsISJ3sz8klIyyfhcB6Jh83bhMN5pGQVcfPI9kwb28ndZTao4lIXk/5rBqD2LX2Zc+tw/KtpXFHqdPHg7E0Vgeu7/xtBm1DfKl+TU1jC2BcXcTC7kL+d2Y7ViRmsScxgRIdQPrxhUI0D39dr9/LQnE3kFTsJ9PbgmUt6cU6PiBOev/1gDm8t3M236/cTG+LDnFuH10tjjlPJ6TKY+NoSthzI5ooBMTxzaS+mfR7H12v3MbF3JK9d1dfdJYpII9RkgtOiRYt47rnnWLNmDQcOHGD27NlceOGFVb5mwYIFTJs2jc2bNxMTE8O//vUvrrvuuhq/p4JTDblcMPchWPa6+fOAqTD+ObDZ3VuXiDQqhmHUa+e5xiw1p5DzX1vKwexCxnQN5+1r+h+z1qhcblEpt328lgXbD2GxwBuTa77OZu6WFP76weqKn/0cdn6560yiajhqVC4hLY/bP13Hhr3mHk+TBsfy0IRuFaNJhmGwKiGDNxfu5vdtqZVee2GfSF6+snZBo7DEWeVoWkObtSKRB2dvwt/Lzvx7RhLq52Dz/iwmvLoEm9XC4n+MqvHIm4g0H7XJBm5dxZuXl0fv3r2ZMWNGjc6Pj49nwoQJjBo1iri4OO68805uvPFGfvnllwautBmyWmHckzD+WcACq9+FTydBUa67KxORRqS5hCaAMH8v3rqmP552K79tTeGVeTuPe96BrAIue3MZC7YfwsvDyhuT+9eqOcHYbuGc2/PI6NC/JnStdWgCaBPqy5c3D+NvZ7UD4OMVSZz/+hK27M/m180HueSNP7j8rWX8vi0ViwXO7RnBs5f0wma1MCduP7PX1WxvP8MwePz7LXT/9y88/v0WSpyu6l9UzzLzi3n+l+0ATBvbiVA/BwDdIwMZ2i4Ep8vg/T8STnldInJ6aTRT9SwWS7UjTv/85z/54Ycf2LRpU8VjV155JZmZmfz88881eh+NONXB1u/hqxugtBBa9YYL34Twum9KKSLSlH2xOpl7v9wAwJtX9680BW7z/iymzlxFSnYRoX6e/O/agXVaW5OaU8iUd1bStVUAL17e+6QD6uKdh5j2+XoO5RRVetzTZuWS/tHcdGY72pZNIyxvm+7nsPPj7WcQG3L8ZhTlXv99J8//uqPi50Ftgnl9cl/C/L1OqubcolIe+XYzG/dmce+4zlW2WC9fG9Y53J8fbh9Raf+xeVtTuOH91fh72Vl+/2h8HZo5ISJHNJkRp9patmwZY8aMqfTYuHHjWLZs2QlfU1RURHZ2dqVDaqnreebGuD4hcGA9vDkCfn4ACvW7FJHm57IBMVw3rA0Ad38ex46UHAB+35bCZW8uIyW7iI5hfsy+pe4NCcL8vfj5zjN56Yo+9TKqd0bHlvx8xxmc3SUMAH+HnZvPas+Sf45i+sU9K0ITwK2j2jOwTQtyi0q547N1lFYxgvTZqqSK0HTlwBj8HHZWJqRz3qtLWJWQXud6d6TkcMHrS/hyzV62p+Rw4weruf2TdRzOLTrm3C37s5m1IhGAR87vfsymzaM6h9Eu1JecwlK+KNujTESkLppUcDp48CDh4ZX/xSk8PJzs7GwKCgqO+5rp06cTGBhYccTE1G0PjmYvZiDctBC6nAeGE5bPgNcHwPrPoHEMWoqInDIPTujK0HYh5BU7uemD1by1cDc3vr+a/GInwzuE8OXfh52wbbi7hPg5eOfaAcy5dThL7z+b+8Z3ISzg2FEhu83KS1f0wd/LzrqkTF49wZTE37akcP/XGwG4ZWR7nr6kF9/cNpxO4X6k5hRx1dvLeXdJPLWd2DJn3T4ueH0puw/lERHgxdVDYrFazL24xry4kG/i9lVc0zAMHvl2My4DJvRqxdD2Icdcz2q1cP2ItgC890cCzio6RIqIVKVJBae6uP/++8nKyqo4kpP1r011FhRj7u109VcQ3B5yU2D2TfDeuXBwU/WvFxE5TXjYrLw+qS9RQd4kHM5n+k/bcBlw+YBoZl4/iEDvxtmRzmKx0CcmqNqOedEtfHjyop4AvD5/FyvjK48erUnM4LZP1uIy4NL+0dw7rjMA7VuaI20Te0dS6jJ47Pst3P5pHHlFpdXWVlji5MHZG7nzszgKSpyM6BDKD7eP4IkLezLn1uF0ifAnI7+EOz6N48b3V3Mgq4Bv1+9nZUI63h42Hjy36wmvfUm/KAK9PUg8nM9vW1OqrUVE5HiaVHCKiIggJaXyf/BSUlIICAjA2/v4C2cdDgcBAQGVDjlJHcbALctg9MPg4QNJf8BbZ8JP/zQ30RURaQZC/By8PaU/Xh7mH6X3juvMM5f0Ou6Guk3R+b0jubhfFC7D3FQ2q6AEgF2pOdzw/ioKS1yM6tyS6Rf3rDSd0Ndh59Ur+/Dvid2wWy18t34/F/1nKd+t38/m/VnkFx8bopLT87nszWXMWpGExQK3j+7I+1MHEVLW5KFXdBDf/d8I7h7bCU+blXnbUhn74iIe/W4LYE4vrKpjno+nnUmDYwFzQ2ERkbpocs0hfvzxRzZu3Fjx2KRJk0hPT1dzCHfJTIZfH4Qt35Q9YIH2o6D3JOgyATwb11QVEZH6tudQLvnFTnpEBbq7lHqXW1TKua8sJik9n/N6teJfE7pxyRt/sC+zgD4xQXz818H4eJ642cLqhHRumbWW1D81pYgI8KJtqC9tW/oS5u/gvaUJZBWUEOTjwctX9GFk57ATXnNnSg7/+GoD65IyAYgN9uHXu86sthX6waxCRjzzO6Uug+9uG0HP6OP/7+V0GRSUOPFTEwmRZqHJ7OOUm5vLrl27AOjbty8vvvgio0aNIjg4mNjYWO6//3727dvHBx98AJjtyHv06MGtt97K1KlT+f3337n99tv54YcfGDduXI3eU8Gpgez+HRY+Z44+lXMEQPeLoM8kiBmsDXRFRJqgdUkZXPrmMpwug1A/B2m5RbQL9eXLvw8j2Nez2ten5hTy2rxdbDmQTXxaHul5xcc9r3dMEP+Z3K9GrdfL24t/v2E/D5zblQFtgmv0We78dB1z4vYfd5+q1OxCPlmZzCcrk0jPL+adawdwRseWNbquiDRdTSY4LViwgFGjRh3z+LXXXsvMmTO57rrrSEhIYMGCBZVec9ddd7Flyxaio6N56KGHtAFuY5IeD+s/hfUfQ2bSkceD28PwO6DfFAUoEZEm5uiW4y39HXx9Es0vMvOLiU/Lq3R0Dvfnb2e1x9PesNMcN+7NYuLrS7BbLSz559mEBzhYtucwHy1P5NfNKZQe1Tgi1M/Bz3eeUbEn1OnGMAzyi51qzy7NXpMJTu6g4HSKuFyQuBTWfwKb50BJnvl4u1Fw/mtmowkREWkSnC6D2z5ey4a9Wfx3ygC6RTbdPz8vf2sZK+PTGdEhlANZBew+lFfx3IDWLZg0OJY3FuxmZ2ouozq35N3rBp6WGz0//dM23ly4m94xQVzYJ5LzekXS0v/0DIkiVVFwqoKCkxsU5cKa9+D3J8xNdD394ZynoO81Gn0SEWlCXC4Dq7Vp/3f7180HuenDNRU/+3rauLBvFFcPaU3XVubfC7YdzOb815dSXOri3xO7cf3wtu4qt0HsTMnhnFcWV2rNbrNaGNEhlAv7RvKXbhEaiZJmQ8GpCgpObpS2E+bcAntXmj93GAMTX4XAKPfWJSIizYbTZXDLrDUcyCrksv7RXNg3Cv/jtGd//48E/v3tZjxtVubcOtxto2yGYXA4r5gQX896G/m69t2VLNxxiFGdW3Jmp5bMidvP+uTMiue9PWz8pXs4t43qQMdw/3p5z+rszchn2ufrubRfNJcP1KwUOXUUnKqg4ORmLicsm2GOPjmLwBEI50w3G0ho9ElERBoJwzD46wer+W1rKu1b+vL9/52Bt2fVnfvqQ3peMev3ZhKXlElccibr92aSmV/ClQNjjmn9Xhfzt6dy/Xur8LBZmHvXWbQJ9QXM7pDfxO1nTtw+Eg/nA+DnsPPG1f1OSZOMOz5dxzdx+/H3srPs/tHqaiinjIJTFRScGolDO2DOzbCvbLpE6xHQ5yroch54B7m1NBERETBDzDkvLyI1p4hJg2N5qmxT4LoqLnWRkV9MWm4R6XnFHM4t5nBeMel5RSSnF7B+b2ZFaDmeO0Z35K6xner8/iVOF+NfWcyu1Fz+ekZbHpzQ7ZhzDMMgLjmT6T9tY2V8Onarhacu7snlAxpuFGj7wRzOeWUR5X8jffi8bkwdcXpNj5TGS8GpCgpOjYizFJa9BvOfAmdZe1qbJ7QfDT0uhs7jwXFqpgiIiIgcz5KdaVzz7goMA968uh/n9GhV62ts3p/FQ3M2sbZs76nqtGvpS5/oIPrEBtE7OogNezN56JvNADx7Sa86T2X7YFkCD3+zmWBfT+bfM5JA72OnKJYrKnVy7xcb+Ha9ubH9HaM7cueYjg3SKOPmD9fw8+aDhPh6cjivmOgW3iy4ZyT202QzaWncapMNNA4q7mOzw4i7zL2eNnwBm7+G1C2w4yfzsHtBx7HQ/WLoNA48fd1dsYiINDMjOoZy05nteGvhHv751UZ6RQcRWYO9pgAKS5y8Om8nby3aU9GIwWa10MLHkxBfT0L8PAn29STUz0FLfwc9owLpHR1EoE/lQNM7JogDWYX8Z8Fu7p+9kfBAL87qVLvpc1n5Jbw412wpf9fYTlWGJgCH3cbLV/QhuoU3/1mwm1fm7WRvRgHTL+5Zr23jN+3L4ufNB7FY4L3rB3LtuyvZm1HAr1tSOLdn7UOqSEPSiJM0LqnbzAC16Ws4vPPI43ZvMzx1vwg6/gU867Z/iIiISG0Vl7q49M0/2LA3i8Ftg/n4r0OwVdNdcGV8Ovd9tYE9aWa783N7RvDAuV2JDPSuU2dCwzC467M45sTtx9fTxuc3D6V7ZGCNX//491t4Z0k8ncL9+PH2M2o1mjNrRSIPzdmEy4DhHUJ44+r+BBynoUZdTJ25it+3pVZsSvzir9t59fdd9I0NYvYtw+vlPUSqoql6VVBwaiIMAw5uNEPU5tmQkXDkOQ+fIyGqw1iFKBERaXAJaXmc++pi8oudRLfwZki7EAa3DWZIuxCiW3hXTGHLKSzhmZ+38dFycxP4lv4OHr+gB+f0iDjpGopLXVz77kqW7TlMmL+D2bcOJ6oGo197DuXyl5cWUeoy+GDqIM6s5WgVwPxtqdz68Vryi510Dvfnhct7ExHohb+XHYe9bk0z1iRmcMkbf2CzWvht2lm0DfUlNaeQEU/Pp9jp4qu/D6N/6xZ1una55PR8vtuwn8v6x2ifKjkuBacqKDg1QYYBB+LMjXQ3z4bMxCPPefhC38kw7HZtqisiIg3q+w37mfb5eopLXZUejwz0YlDbYLq0CuD9PxI4kFUIwJUDY7j/3K7VTourjayCEi578w92pOTSKdyPL24eVu31b3x/Nb9tTWFU55a8d/2gOr/3pn1ZXD9zFYdyiio97rBbCfD2IMDLToC3B10i/LlvfPWf++r/rWDJrjQuHxDNs5f2rnj8H1+u5/PVexnfI4I3ru5f53o378/i2ndXkZZbRN/YIL7421Ctm5JjKDhVQcGpiTMM2L8OtswpC1Hmv+hhtUOvK2D4ndCy7h2HREREqpJTWMLqxAxW7ElnRfxhNu7NotRV+a9SscE+PH1xT4Z1CG2QGvZnFnDRf5aSkl3EkHbBvD910AlHfZbuSmPy/1Zgs1r45c4z6RDmd1LvvTcjn3u+WM/mfdnkFJWe8LweUQF8OHUwLXw9j/v8st2Hueq/y/GwWfj97pHEBB+ZPbL9YA7jXl6E1QIL7hlFbEjtZ5as2HOYG99fXanGk+1K2BhkF5bg77A3SJOO5krBqQoKTqcRw4D4hbD4RfMWAAt0Ox9GTIPIPu6sTkREmoH84lLWJmayIv4wG/Zm0TMqkFtHdWjwPZ+27M/m8reWkVtUSrdWAYzoGErv6CB6xwQSFWROHXS6DCa8uphtB3O4blgbHjm/e73W4HQZ5BaWkl1YYh4FpaTmFPLYd1s4nFdM53B/PrxxEGH+XpVeZxgGl7+1jFUJGVw9JJYnLjy2zfuUd1eyaMehOtU9d0sKt328lqJSF4PaBnN+70j+NWcTVgt8cXPNpv+VOl28Om8npS6DaWM7uX2kas+hXO77eiMr49Nx2K1EtfAmpoUP0S28iW7hQ0ywN62DfekeGVCnNXTNmYJTFRScTlN7V5sBavsPRx7rMAaG/B3ajjQ7+ImIiJxGFu88xA0zV1PsrDx1MNTPk97RQfh52fkmbj+B3h4suGfkCUd/6tuu1Bwm/XcFqTlFtAv1ZdZfB9Mq8MharEU7DjHl3ZV42q0suncUEYFex1yj/BwfTxvL7h9d4+mOX6xO5r6vN+J0GYzpGs7rk/ri5WGr2GA3NtiHH+84o8oNdp0ug3u+WM/sdfsAuGpQLE9d1MMtozylThfvLInnxbk7KPrTFNHjOaNjKK9P6lev00NPdwpOVVBwOs2lbIElL8GmL8Eo+w+Mbxj0uAR6XQ6RfUHD2yIicprYl1nAH7vSWL83k/XJWWw9kH3M1EF3bCibkJbH5P+tYF9mATHB3nx84xBign0wDIMLZyxl/d4sbhjRlofOO3YTXjBHpc55eTHbU3K4b3wXbj6rfbXv+fai3Tz14zYALu0fzdMX96wYKcoqKOHcVxazL7OAS/tH8/xlvY97DZfL4B9fbeDLNXuxWS0YhoHLgDvHdOTOMad2mt+2g9n848sNbNibBZih6PELemC1WNibkU9yRj57MwrKjnw27M2iqNRFhzA/3r12YJ2mODZHCk5VUHBqJtL3wLL/wKavoCD9yOMhHcy1UD0vheB27qtPRESkARSWONm8P5v1yZms35tJgJcHD0/shocbpprtyyxg0n+Xk3g4n1aBXsy6cTC7D+Xx1w9W4+1hY/E/RxHqd+JOd5+vTuYfX24gIsCLxf8cdcLPYBgGT/+8jbcW7gHgpjPbcf/4LseMEK2MT+fKt5fhMmDGpH5M6FV5nyiXy+DBORv5ZGUyNquFV6/sS0Z+Mf+aswmA6Rf35KpBsSfzKyE1u5Bv1+/HYrHQMcyPjuF+RAR4Vaq1uNTFfxbsYsb8XZQ4Dfy97Dx0Xjcu6x9d5ajXpn1Z3Pj+ag5mFxLs68l/p/Snf+vgk6q3OVBwqoKCUzPjLIFd82Dj57DtRygtOPJcaGcIioXAaAiMgsAYCIgyfw6IBLvaloqIiJyMlOxCJv9vBbtScwn1cxDgbWfPoTz+PrI9/zynS5WvLSp1Mvzp+aTlFvHyFX24sG9UpecNw2BNYgYz5u9i/vZDANWOTj33yzZmzN9NoLcHP995RsUUQsMw+Pe3m/lgWSJWC7x0RR8u6GO+X/neUlYLvHXNAMZ2C6/V78AwDFbGp/PB8kR+2XTwmBFBP4ed9mF+dAzzo11LX76N28+2gzkAjOkazpMX9SA84NjpjMdzMKuQG95fxeb92XjarTx3aa+KzyHHp+BUBQWnZqwoB7Z+b4aoPQuOTOU7EZ8Q8I8E/4iyo5V5GxgNbc8Ej5rtHC8iItKcHc4t4pp3VrLlQDYA/g47i/85iiCf6tdcvTZvJy/M3UGPqAC+u21ERdOLXzYf5O1Fe4hLzgTAZrXw1EU9uGJg1SNCJU4Xl7xhbmY8rH0IH90wGIsFHv9+K+8ujcdigecv7c0l/aMrXmMYBvd9tZHPVifjsFv5+K+DazSSk1dUyux1+/hoeWJFEAIY0LoFLf0d7EzNJSEt75ggBRDs68kj53dnYq9WtV5blV9cyh2fxjF3SwoAd43pxO2jO6gT3wkoOFVBwUkAyE2FlE2Qtbfs2AdZyZC9z/y5tLDq1wfFwvhnofP4U1OviIhIE5aVX8KU91ayPjmTe8d15tZRHWr0uvS8YoY9PY/CEhfvXDuApPR83l0aT3K6OYPE02blor5R/PXMtnQI86/RNfccymXCq0soKHHywLldOJxbzFuLzGl+z1zS87jhq9Tp4m8frmHetlQCvT346u9Dj/t+BcVO1iRm8NvWFL5as7eiHbq3h40L+0ZyzZA2dIs88vfP4lIXiYfz2JWay86yI9TPk9tGdSCkimmM1XG6DJ75eRtvl32ui/pG8fQlPeu8WfHpTMGpCgpOUi3DgPx0yD0I2Qcg5wDkHDxyu2+N+RxA53PhnKehRWv31iwiItLIFZU62X4wh55RgbUa/Xhw9kZmrUiq9FgLHw+uGdKaa4a2oaV/7QPGJyuTuP/rjVgs5h/7AE9c2IOrh5z4z/OCYieT/recdUmZRAZ68fUtwwny8WBtUgbLdx9m+Z501iVnUOI88lfrNiE+XD2kNZf1jyHQ59R3uvt4RRIPfbMJp8ugS4Q/d/+lM2O6hjWK0afswhICvNzf/U/BqQoKTnLSinJh0bOwbAa4SsHuDWfdC0P/D+ynptWriIhIc7HnUC5jX1qE02XQNtSXG0a05ZJ+0Se1V5ZhGPztwzX8Wjad7ZGJ3bhuePWdB9Pzirn0jT/Yk5ZHiK8nOUWlFP+pTXirQC+Gtgvhgr5RnNEh1O37Ki3ZmcYts9aQXWiOfvWKDuSusZ0Y2anlKQ1QLpfB5v3ZzN+eyvztqWzYm8Xy+0fXKfjWJwWnKig4Sb1J3Qo/3AOJS8yfQzvBuc9Du7PAWWp288tLg/y0stvDUFoEnr7g6Vd2e9R931DzEBERkUpWJaSTX+ys1yCSkVfM9J+2MrhtSKU1TdVJTs/n4jf+4FBOEQBh/g6Gtg9hSLsQhrYLoXWIT6MY0TlaRl4xby/ew8ylCRSUOAHoGxvEtLGdGNEhtFK9pU4X8Wl5bN6fzZYD2SSn5+PtYcPfy46flx0/hwf+XnbzZ4edAG8PArw8CPC2E+DlgY+nreJ6WQUlLNmZxvztqSzYfoi03KJKdb15dX/O6RFx6n4Rx6HgVAUFJ6lXhgEbPodfH4Q8s6MPXkFQmFm36/W8DEY/bK6hEhERkUYpOT2flfHp9IkNol2ob6MLSieSllvEWwt388GyxIoNdQe2acE5PVqxKzWXLQey2XYgu0ab7Z6I3WohwNsDP4edfZkFOI9qfuHjaWNEh1BGdQljZOeWlTZGdhcFpyooOEmDKMiE35+AVf8Dyv8vZQHvFuYokk8o+IaA3QuK86E4F4rzjjpyoCDDfJnNAUNuhhHTwDvIPZ9HRERETlup2YW8sXA3s1YkHTPVEMDX00bXVgF0iwygXagvRaUucotKySksP0qO+rmE7MJSsgpKKoWkcu1b+jKqcxijuoQxoE2LRtegQsGpCgpO0qCy9kFRthmUvFuAzV7z1+6Pg1//BQmLzZ+9g+Gsf8KAqVWvnSotBqvNPERERERq6GBWIW8v2kPi4Tw6R/jTLTKA7pGBtA72qfWUSMMwyC92kl1YQnZBKdmFJUQEeBET7NNA1dcPBacqKDhJo2YYsPNX+PUhSNtuPhbczpy+FxAFGQnmkR5/5H7OfnAEQMxgaD0UWg+HyL7awFdERESkGgpOVVBwkibBWQrrPoD50yEvtfavt3tBVH9oPQyC2/+pUcXhIw0rSovMczqPhw5jwEv/nxAREZHmQ8GpCgpO0qQU5cDSV2H1u+DhDS3amHtGtWhbdr+t2UgiZz8kLoPEpZC07EijitqwekDbM8y9qTqPh8CadxgSERERaYoUnKqg4CSnPcOAw7sg8Q8zRGXvP6pBRSj4hBz52XDCzrmw/UfzNUeL6GWOQrU7y5wG6OH+zjciIiIi9UnBqQoKTiInkLbTDFDbfoTkFRzpDojZ6S9mELQ9C9qeCVH9wOb+3b5FREREToaCUxUUnERqIC/NbFKxZyHEL4ScA5Wf9/Qz10a1PcsckQrrDlare2oVERERqSMFpyooOInUUvnUv/iFZpBKWHxkz6lyPqHm+qjyINWiLTSRzQBFRESk+VJwqoKCk8hJcrkgZSPEL4I9C8y1VCX5lc/xbWnuY+UIAIe/2a3PEQBegebPHt5g9wYPr8q3nj7Qqjd4+rrlo4mIiEjzouBUBQUnkXpWWgz7Vh+Z1rd3FbhK6349v3AY8wj0ulLT/0RERKRBKThVQcFJpIEV5UL6bijMhqLsstscKMo6cr+kAEoLoKSw8m1OypF9q6L6w/jnILp/1e/ncpnB7dB2M3QFREJgFHgFabqgiIiIVKk22cB+imoSkebC4WdOt6uL0mJY8QYsfBb2rYH/nQ19JsPof4N/+JHzysPS5jmwZQ5k7zv2Wh4+EBBVFqRizGYWHceCX1jdahMREZFmTSNOItL45KTAvEchbpb5s6c/nHWvuZ/Ulm+PDUuefuYIVUE6ZO0zb08ksi90HAcd/2Le13RAERGRZqvJTdWbMWMGzz33HAcPHqR379689tprDBo06ITnv/zyy7zxxhskJSURGhrKpZdeyvTp0/Hy8qr2vRScRJqQvavhp3+Yo09/5ukHncdDtwuhw+jKG/SWFJgb/2bvM2/TdsCu3+DA+srX8Ak1R6Han22OSAVGV19Tejzs+Bm2/wQ5B2HA9TDgBrB7ntRHFRERkVOvSQWnzz77jClTpvDmm28yePBgXn75Zb744gu2b99OWNixU2o+/vhjpk6dyrvvvsuwYcPYsWMH1113HVdeeSUvvvhite+n4CTSxLhcsOFTmPe4uT6q83jofiG0H21246uNnIOwc665R9Xu+VCcU/n5oFhoPdwMUa2HQ3A7sx37vjXm5sA7fobULcdeN7gdjH0MupyndVUiIiJNSJMKToMHD2bgwIG8/vrrALhcLmJiYvi///s/7rvvvmPOv+2229i6dSvz5s2reOzuu+9mxYoVLFmypNr3U3ASacJcrvqbWldaDMnLzRCVsNQcjTKclc/xizAfyzt05DGLzQxWnceDzRMWPnPk+dhhMO5JiOpXPzWKiIhIg2oyzSGKi4tZs2YN999/f8VjVquVMWPGsGzZsuO+ZtiwYXz00UesXLmSQYMGsWfPHn788Ueuueaa455fVFREUVFRxc/Z2dn1+yFE5NSpz/VIdk9oe6Z5gDmalbzS3Jcq8Q+z+UTuQfM5R4A5pa/TeOg4xtyjqlzvK2HJy7DsdUj6A/47CnpeDqMfhqCY+qtXRERE3MqtwSktLQ2n00l4eHilx8PDw9m2bdtxXzNp0iTS0tIYMWIEhmFQWlrKzTffzAMPPHDc86dPn86jjz5a77WLyGnG4W+uleow2vy5pLBsbZUB0YNOvIbJ4Q+jH4IBU+H3x2H9J7Dxc9jyDXS/CHpeCu1Ggs3jVH0SERERaQBNrp3UggULeOqpp/jPf/7D2rVr+frrr/nhhx94/PHHj3v+/fffT1ZWVsWRnJx8iisWkSbJwwvaDIc2I2rW+CEwCi56E25aCG3OAGeRuTZr1qXwQmf4/i5IWGJONzwRZylk7YWMBHCW1NtHqVJ6PCx6Dn57xLwvIiIix+XWNU7FxcX4+Pjw5ZdfcuGFF1Y8fu2115KZmck333xzzGvOOOMMhgwZwnPPPVfx2EcffcRNN91Ebm4u1mqm8miNk4g0OMOA5BWw8UvYPBvy04485x8JPS4G/4gjnf+yyrr/5R4EoyxYWWxml7/gttCizZHDNwzyD0NuCuSmmq/JTTV/zj8MoZ3LpiCeARG9wGo7tr78dLOuDZ+b67zKWe3QZxKccQ+0aN2AvyAREZHGocmscfL09KR///7MmzevIji5XC7mzZvHbbfddtzX5OfnHxOObDbzLwaNoLO6iIjZWS92iHmc8zTEL4RNX8PW7yBnv7ke6kSsHmCxmiNWmYnmURuZSbBrrnnfKxBajzCDVJsRkL4HNnwGO34BV/mIlgXanWW+5+7fYe0HEPcx9L3aDFBapyUiIgK4OTgBTJs2jWuvvZYBAwYwaNAgXn75ZfLy8rj++usBmDJlClFRUUyfPh2AiRMn8uKLL9K3b18GDx7Mrl27eOihh5g4cWJFgBIRaTRs9iNrpya8YO4nte17cypeQCQERJnT/AIiISAafFuar8s9aE7Z+/ORmwq+oeAXftQRZo5gOfxhfxwkLDY7BRZmwfYfzOPPwntC7yugxyXmewMkrYAF02HPfFgzE9bNgn7XwBl312yPKxERkdOY29uRA7z++usVG+D26dOHV199lcGDBwMwcuRI2rRpw8yZMwEoLS3lySef5MMPP2Tfvn20bNmSiRMn8uSTTxIUFFTte2mqnog0C85Ss8V6/EIzSCUtN7sB9rwUel0B4d1P/NrEZbDgKYhfdOQxuzfYHeZGw3YH2L2O3Frt5oiVxVJ2e9ThLIGS/LKjoOzIh+J88/kWraFF27IpiUfdBsVqU2EREWlwTWofp1NNwUlEmiXDqP3mvAlLzRGohMUNU1NVrHazG2GPS6HLBPDSf69FRKT+KThVQcFJRKSW8g5DcS6UFkFpYdltwZGfXU6zqYXhMgOa4TI3DnY5zU2CPbzBwwc8fY7c9/A2R6My4s0piOlH38abo1Ll7F7QaZwZojr+xex4WF9cLnMdWcom8/1bdjXXpjn86u89RESk0VJwqoKCk4hII2cYkLYTNn8NG7+Aw7uOPOcIgC7nQeuhR6b2+UdWvzmyy2l2E8xMhIMbzaB0cBOkbIbinMrnWu0Q2c/sTNjmDIgZbIY+ERE57Sg4VUHBSUSkCTEMc63Wpi/NzoTZ+449x+aovFbK7oDcQ2aL9rxUs6FGXpo5CnY8Nk9o2cW8xv71kJV07PNRA4400TiegEjodTlE9Kz7ZxURkVNOwakKCk4iIk2Uy2XuO7X1Ozi03ZzSl5kErtKaX8MvHMK6QUQPs7NgRE8I7Qg2jyPnZCRA/GJzbVf8YrOFfE2F94Q+V0HPy8GvZc1fB2ZILMyCvENlYe+QubYrpKPZfbG6UTUREak1BacqKDiJiJxGnKWQvffI2qj0eHPtlF/YkVbtfmHmxsG+oZUDUk0Yhrn/VeIfUPSnKX3lzTbKNzze/iM4i8ues5nrsfpcBZ3OgaJcyDlgHtn7j9zPOVi2mfEhc3Ss/PV/5uEDIR3MkBfaybz1CjJH0vIOHXuUFkFUf2h7ljnl0D+idp9bRKSZUHCqgoKTiIg0iPx0c11W3Cewb3Xdr+MIMPfz8m0JBelmcKvNqNrxhHY2N0Iu3wzZaoeCDCjMNG8LMo/cx2I2x/AsO46+7xVo1mVz+zaQIiL1QsGpCgpOIiLS4A7tgPUfw/rPjkz18wmFgFbgX3YERJojQX7h5oiYX1lY8vCufC1nCWQkwuGdkLbDbJyRttMcAfMNPRKyyl/v29IcBUv6w9yL68AGoD7/qLeAT0hZ7WFHNmL2CTFH4Sq6LDrNOlxO8/0Do82uhS07q728iDQaCk5VUHASEZFTxuU01yv5hLhvQ9/8dEhcaoao+EVwaJv5uM1hbors3QK8g8xbryDzueIcc3phcZ7Zir4o17wtzDpxk43aCIyBsK5mU46wbmaQKsyGomzzPQqzyu5nm6NtXkFmjeW35bX6BJvX+XPYFBGpIQWnKig4iYhIs1aYba71qkvYKG/rnpvypyMV8g8DFrBYzUYWFqu51stiBQyz6UbqVnNtV32y2s0mH9EDy44BZofFP2/4XFJgri8rPwqzwFVijui5Ssz1cs5i8z4WM8x5BZnTEyuOIDO0+YXVbkNpw4DULeaaNp+QI4fa3Iu4nYJTFRScRERE3KggA1K3mUEidas5AlZSYAYVR8BRt4Hmrc1uhpyCzKPWZWWat9kHID/t2PfwCTGbY0BZUNpXtn6rngTFQocx0H60uW7seFMPnSVmU5HtP5pHZtKx53j4lIWoYLNzYqdx0PV882cROSUUnKqg4CQiInKaMAzISoa9q2DvavP2wPqquxMGRJlrzbxbgNXD3KfLZi+772GOYIE5VbAg88jUwYoj01zDVc5qh5gh0OFsaDfSDEjbfoSdv5jnl7N7QXA7M8DlpZWNbB2HxWZep8fF0GWCWefRnKWQshGSVpjt+fetNdeb9bwMelyi0CVSSwpOVVBwEhEROY2VFsHBjbB/nbkZckCkGZb8W5mjWLWZYnc8xXmQsAR2/WYe6XtOfK5PCHQaD13ONcOQp6/5uGGYzT3yD5tTH/MPm2Fo82yz9nJWD+gwGjqPh6x9ZlDauwZK8o7/flYPc9Sq1xXmrd1x7DmFWeY+aIe2mdf0CjSbjPgEl41+hWoaoTQrCk5VUHASERGRepO+B3bNM4/EpWZXwy7nQucJEDMIrLbaXS9tl9nWfvNsczrj8TgCzWvHDoaoAeZ56z+pHLq8gqD7RRDZx+zCWD4tMntfzeqwe1e975lfmLm2LKIXtOoFEb1rv+mzSCOg4FQFBScRERFpElK3mgEqfhEEtTaDUswQsxuh1Xrs+SlbYMOnsOGLI23wj8e/lXmNFq3NZiEVI19p5v0TTXWsjn+kGaJCOx3p1ljeVKO8I6KH95HpinmHzNv8svv56ebUR0/fsr3DfCvfd/hVXgdXft/udfIjidJsKThVQcFJRERETmsupxm2Nn5hdjEM7VTW+r1sH60/r5s6mmGYrefzD5ftwXWCczITzD3CDm4wb9N3N8hHqRGrhxmgKtrrtwDv4CP3vQKPrF+rOGxHbkuLoCS/rP1+Xtn9fHNKpMV6VFgr765YFto8vM2QWVoIpeW3Reatq8SsoWKvszAzACrgNToKTlVQcBIRERGpZ0U5cHCTGaQyEo4006hosFF2W5xrhhnfluZ6Kt/QIxs5+4SYYa0490iIKd9LrHw/saKcI3t8FWVTv5s7NzAPn7LNqsuClH8E+EWAf3jlW08fKCk0A1xJwVG3BWZQ8/QBD1/z1tO37L6vGeTqI5iVFpWNBh6C3EPmvm7+rcz91/xbmc1Uqnt9zgGz/X5pkbnWzu4w946zO8yGLOWPefrVfjprPatNNqjmk4uIiIiIVMPhD62Hmsep4nKZo0KF2Ufa1BdkHHsUZpbt1+U0N1SuOMp+tjvMUOPpWzmUePiaHRTLN2YuD2zl90sKzY2t7V6Vg4HdywwD5Xue5R0yg19JPmQmmkdDsFjN8OkbdtRIV1lQ8y3be6wwqyx85hwJoUU5ZdMny4JSUVYV72EzG64ERpuHfyvzGtkHzOmhJ9oi4ESm/gKxQ07+s58iCk4iIiIi0vRYrWZgc/hDYJS7q6laUS7kpZrBJPeguWl0zkHzfs5Rm0nnHTrS7t7DxxxF8vAxw5hHWcOOkoKyUbj8stGofPN8w3VkpCh188nVa7Wbo2O+Lc1AmXPA7MLoKjG3AMhKrvr1NofZ9t/uZY46OYvLpjEWgbPoyDo6m+fJ1XmKKTiJiIiIiDQkh595BLer+jxnqRlOatPwwuUyw1NRjjnak5tqHnmpR+7nppSt1/Iva6zhf+TwKttw2jesLCyFmtMp//z+Lqd5rfLglLXXHGHyCjBHofwjzbDkH2m2t6+qfsMww5O1aUWRplWtiIiIiMjpymavfg3Rn1mtR4JZQKuGqQvM6YcBrcwjZtDJXctiOf4+Y43ccXpZioiIiIiIyNEUnERERERERKqh4CQiIiIiIlINBScREREREZFqKDiJiIiIiIhUQ8FJRERERESkGgpOIiIiIiIi1VBwEhERERERqYaCk4iIiIiISDUUnERERERERKqh4CQiIiIiIlINu7sLONUMwwAgOzvbzZWIiIiIiIg7lWeC8oxQlWYXnHJycgCIiYlxcyUiIiIiItIY5OTkEBgYWOU5FqMm8eo04nK52L9/P/7+/lgsFneXQ3Z2NjExMSQnJxMQEODucqQJ0ndITpa+Q3Ky9B2S+qDvkZysunyHDMMgJyeHyMhIrNaqVzE1uxEnq9VKdHS0u8s4RkBAgP4jISdF3yE5WfoOycnSd0jqg75HcrJq+x2qbqSpnJpDiIiIiIiIVEPBSUREREREpBoKTm7mcDj497//jcPhcHcp0kTpOyQnS98hOVn6Dkl90PdITlZDf4eaXXMIERERERGR2tKIk4iIiIiISDUUnERERERERKqh4CQiIiIiIlINBScREREREZFqKDi50YwZM2jTpg1eXl4MHjyYlStXurskaaSmT5/OwIED8ff3JywsjAsvvJDt27dXOqewsJBbb72VkJAQ/Pz8uOSSS0hJSXFTxdLYPf3001gsFu68886Kx/QdkprYt28fV199NSEhIXh7e9OzZ09Wr15d8bxhGDz88MO0atUKb29vxowZw86dO91YsTQmTqeThx56iLZt2+Lt7U379u15/PHHObpXmb5DcrRFixYxceJEIiMjsVgszJkzp9LzNfm+pKenM3nyZAICAggKCuKGG24gNze31rUoOLnJZ599xrRp0/j3v//N2rVr6d27N+PGjSM1NdXdpUkjtHDhQm699VaWL1/O3LlzKSkp4S9/+Qt5eXkV59x111189913fPHFFyxcuJD9+/dz8cUXu7FqaaxWrVrFW2+9Ra9evSo9ru+QVCcjI4Phw4fj4eHBTz/9xJYtW3jhhRdo0aJFxTnPPvssr776Km+++SYrVqzA19eXcePGUVhY6MbKpbF45plneOONN3j99dfZunUrzzzzDM8++yyvvfZaxTn6DsnR8vLy6N27NzNmzDju8zX5vkyePJnNmzczd+5cvv/+exYtWsRNN91U+2IMcYtBgwYZt956a8XPTqfTiIyMNKZPn+7GqqSpSE1NNQBj4cKFhmEYRmZmpuHh4WF88cUXFeds3brVAIxly5a5q0xphHJycoyOHTsac+fONc466yzjjjvuMAxD3yGpmX/+85/GiBEjTvi8y+UyIiIijOeee67isczMTMPhcBiffPLJqShRGrkJEyYYU6dOrfTYxRdfbEyePNkwDH2HpGqAMXv27Iqfa/J92bJliwEYq1atqjjnp59+MiwWi7Fv375avb9GnNyguLiYNWvWMGbMmIrHrFYrY8aMYdmyZW6sTJqKrKwsAIKDgwFYs2YNJSUllb5TXbp0ITY2Vt8pqeTWW29lwoQJlb4roO+Q1My3337LgAEDuOyyywgLC6Nv377897//rXg+Pj6egwcPVvoeBQYGMnjwYH2PBIBhw4Yxb948duzYAcD69etZsmQJ48ePB/Qdktqpyfdl2bJlBAUFMWDAgIpzxowZg9VqZcWKFbV6P3v9lC21kZaWhtPpJDw8vNLj4eHhbNu2zU1VSVPhcrm48847GT58OD169ADg4MGDeHp6EhQUVOnc8PBwDh486IYqpTH69NNPWbt2LatWrTrmOX2HpCb27NnDG2+8wbRp03jggQdYtWoVt99+O56enlx77bUV35Xj/fmm75EA3HfffWRnZ9OlSxdsNhtOp5Mnn3ySyZMnA+g7JLVSk+/LwYMHCQsLq/S83W4nODi41t8pBSeRJubWW29l06ZNLFmyxN2lSBOSnJzMHXfcwdy5c/Hy8nJ3OdJEuVwuBgwYwFNPPQVA37592bRpE2+++SbXXnutm6uTpuDzzz9n1qxZfPzxx3Tv3p24uDjuvPNOIiMj9R2SRk9T9dwgNDQUm812TLeqlJQUIiIi3FSVNAW33XYb33//PfPnzyc6Orri8YiICIqLi8nMzKx0vr5TUm7NmjWkpqbSr18/7HY7drudhQsX8uqrr2K32wkPD9d3SKrVqlUrunXrVumxrl27kpSUBFDxXdGfb3Ii9957L/fddx9XXnklPXv25JprruGuu+5i+vTpgL5DUjs1+b5EREQc03yttLSU9PT0Wn+nFJzcwNPTk/79+zNv3ryKx1wuF/PmzWPo0KFurEwaK8MwuO2225g9eza///47bdu2rfR8//798fDwqPSd2r59O0lJSfpOCQCjR49m48aNxMXFVRwDBgxg8uTJFff1HZLqDB8+/JitEHbs2EHr1q0BaNu2LREREZW+R9nZ2axYsULfIwEgPz8fq7XyXz9tNhsulwvQd0hqpybfl6FDh5KZmcmaNWsqzvn9999xuVwMHjy4dm94Uq0tpM4+/fRTw+FwGDNnzjS2bNli3HTTTUZQUJBx8OBBd5cmjdDf//53IzAw0FiwYIFx4MCBiiM/P7/inJtvvtmIjY01fv/9d2P16tXG0KFDjaFDh7qxamnsju6qZxj6Dkn1Vq5cadjtduPJJ580du7cacyaNcvw8fExPvroo4pznn76aSMoKMj45ptvjA0bNhgXXHCB0bZtW6OgoMCNlUtjce211xpRUVHG999/b8THxxtff/21ERoaavzjH/+oOEffITlaTk6OsW7dOmPdunUGYLz44ovGunXrjMTERMMwavZ9Oeecc4y+ffsaK1asMJYsWWJ07NjRuOqqq2pdi4KTG7322mtGbGys4enpaQwaNMhYvny5u0uSRgo47vHee+9VnFNQUGDccsstRosWLQwfHx/joosuMg4cOOC+oqXR+3Nw0ndIauK7774zevToYTgcDqNLly7G22+/Xel5l8tlPPTQQ0Z4eLjhcDiM0aNHG9u3b3dTtdLYZGdnG3fccYcRGxtreHl5Ge3atTMefPBBo6ioqOIcfYfkaPPnzz/u34GuvfZawzBq9n05fPiwcdVVVxl+fn5GQECAcf311xs5OTm1rsViGEdt1SwiIiIiIiLH0BonERERERGRaig4iYiIiIiIVEPBSUREREREpBoKTiIiIiIiItVQcBIREREREamGgpOIiIiIiEg1FJxERERERESqoeAkIiJSCwsWLMBisZCZmenuUkRE5BRScBIREREREamGgpOIiIiIiEg1FJxERKRJcblcTJ8+nbZt2+Lt7U3v3r358ssvgSPT6H744Qd69eqFl5cXQ4YMYdOmTZWu8dVXX9G9e3ccDgdt2rThhRdeqPR8UVER//znP4mJicHhcNChQwfeeeedSuesWbOGAQMG4OPjw7Bhw9i+fXvDfnAREXErBScREWlSpk+fzgcffMCbb77J5s2bueuuu7j66qtZuHBhxTn33nsvL7zwAqtWraJly5ZMnDiRkpISwAw8l19+OVdeeSUbN27kkUce4aGHHmLmzJkVr58yZQqffPIJr776Klu3buWtt97Cz8+vUh0PPvggL7zwAqtXr8ZutzN16tRT8vlFRMQ9LIZhGO4uQkREpCaKiooIDg7mt99+Y+jQoRWP33jjjeTn53PTTTcxatQoPv30U6644goA0tPTiY6OZubMmVx++eVMnjyZQ4cO8euvv1a8/h//+Ac//PADmzdvZseOHXTu3Jm5c+cyZsyYY2pYsGABo0aN4rfffmP06NEA/Pjjj0yYMIGCggK8vLwa+LcgIiLuoBEnERFpMnbt2kV+fj5jx47Fz8+v4vjggw/YvXt3xXlHh6rg4GA6d+7M1q1bAdi6dSvDhw+vdN3hw4ezc+dOnE4ncXFx2Gw2zjrrrCpr6dWrV8X9Vq1aAZCamnrSn1FERBonu7sLEBERqanc3FwAfvjhB6Kioio953A4KoWnuvL29q7ReR4eHhX3LRYLYK6/EhGR05NGnEREpMno1q0bDoeDpKQkOnToUOmIiYmpOG/58uUV9zMyMtixYwddu3YFoGvXrixdurTSdZcuXUqnTp2w2Wz07NkTl8tVac2UiIiIRpxERKTJ8Pf355577uGuu+7C5XIxYsQIsrKyWLp0KQEBAbRu3RqAxx57jJCQEMLDw3nwwQcJDQ3lwgsvBODuu+9m4MCBPP7441xxxRUsW7aM119/nf/85z8AtGnThmuvvZapU6fy6quv0rt3bxITE0lNTeXyyy9310cXERE3U3ASEZEm5fHHH6dly5ZMnz6dPXv2EBQURL9+/XjggQcqpso9/fTT3HHHHezcuZM+ffrw3Xff4enpCUC/fv34/PPPefjhh3n88cdp1aoVjz32GNddd13Fe7zxxhs88MAD3HLLLRw+fJjY2FgeeOABd3xcERFpJNRVT0REThvlHe8yMjIICgpydzkiInIa0RonERERERGRaig4iYiIiIiIVENT9URERERERKqhEScREREREZFqKDiJiIiIiIhUQ8FJRERERESkGgpOIiIiIiIi1VBwEhERERERqYaCk4iIiIiISDUUnERERERERKqh4CQiIiIiIlINBScREREREZFq/D8QAgYGQqThtAAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 1000x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize = (10, 4))\n",
    "plt.plot(train_losses)\n",
    "plt.plot(valid_losses)\n",
    "plt.legend([\"train\", \"vlid\"])\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.ylabel(\"loss\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pred, train_y, train_alert = model_eval(train_dataloader, model, criterion, mode = \"test\")\n",
    "valid_pred, valid_y, valid_alert = model_eval(valid_dataloader, model, criterion, mode = \"test\")\n",
    "test_pred, test_y, test_alert = model_eval(test_dataloader, model, criterion, mode = \"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alert_key</th>\n",
       "      <th>probability</th>\n",
       "      <th>sar_flag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>365126.0</td>\n",
       "      <td>0.578901</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>365163.0</td>\n",
       "      <td>0.098110</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>365166.0</td>\n",
       "      <td>0.245101</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>365167.0</td>\n",
       "      <td>0.232864</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>365168.0</td>\n",
       "      <td>0.077038</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   alert_key  probability  sar_flag\n",
       "0   365126.0     0.578901       NaN\n",
       "1   365163.0     0.098110       NaN\n",
       "2   365166.0     0.245101       NaN\n",
       "3   365167.0     0.232864       NaN\n",
       "4   365168.0     0.077038       NaN"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_result = torch.concat((train_alert, train_pred, train_y), dim = 1)\n",
    "train_result = pd.DataFrame(train_result, columns = [\"alert_key\", \"probability\", \"sar_flag\"])\n",
    "\n",
    "valid_result = torch.concat((valid_alert, valid_pred, valid_y), dim = 1)\n",
    "valid_result = pd.DataFrame(valid_result, columns = [\"alert_key\", \"probability\", \"sar_flag\"])\n",
    "\n",
    "test_result = torch.concat((test_alert, test_pred, test_y), dim = 1)\n",
    "test_result = pd.DataFrame(test_result, columns = [\"alert_key\", \"probability\", \"sar_flag\"])\n",
    "test_result.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_result = train_result.sort_values(\"probability\", ascending = False).reset_index(drop = True)\n",
    "valid_result = valid_result.sort_values(\"probability\", ascending = False).reset_index(drop = True)\n",
    "test_result = test_result.sort_values(\"probability\", ascending = False).reset_index(drop = True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recall N-1 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train total: 5362\n",
      "(171 - 1) / 3279 = 0.0518450747179018\n",
      "\n",
      "Valid total: 2299\n",
      "(74 - 1) / 907 = 0.0804851157662624\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_sar = int(train_result[target].sum())\n",
    "train_len = train_result[train_result[target] == 1].index[-2] + 1\n",
    "print(f\"train total: {len(train_result)}\")\n",
    "print(f\"({train_sar} - 1) / {train_len} = {(train_sar - 1) / train_len}\\n\")\n",
    "\n",
    "valid_sar = int(valid_result[target].sum())\n",
    "valid_len = valid_result[valid_result[target] == 1].index[-2] + 1\n",
    "print(f\"Valid total: {len(valid_result)}\")\n",
    "print(f\"({valid_sar} - 1) / {valid_len} = {(valid_sar - 1) / valid_len}\\n\")\n",
    "\n",
    "# test_sar = int(test_result[target].sum())\n",
    "# test_len = test_result[test_result[target] == 1].index[-2] + 1\n",
    "# print(f\"Test total: {len(test_result)}\")\n",
    "# print(f\"({test_sar} - 1) / {test_len} = {(test_sar - 1) / test_len}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alert_key</th>\n",
       "      <th>probability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>356602</td>\n",
       "      <td>0.866303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>355724</td>\n",
       "      <td>0.944693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>358453</td>\n",
       "      <td>0.931213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>361617</td>\n",
       "      <td>0.885478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>359668</td>\n",
       "      <td>0.900306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3845</th>\n",
       "      <td>371792</td>\n",
       "      <td>0.170550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3846</th>\n",
       "      <td>373453</td>\n",
       "      <td>0.754557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3847</th>\n",
       "      <td>375469</td>\n",
       "      <td>0.208148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3848</th>\n",
       "      <td>369969</td>\n",
       "      <td>0.702704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3849</th>\n",
       "      <td>366252</td>\n",
       "      <td>0.926682</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3850 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      alert_key  probability\n",
       "0        356602     0.866303\n",
       "1        355724     0.944693\n",
       "2        358453     0.931213\n",
       "3        361617     0.885478\n",
       "4        359668     0.900306\n",
       "...         ...          ...\n",
       "3845     371792     0.170550\n",
       "3846     373453     0.754557\n",
       "3847     375469     0.208148\n",
       "3848     369969     0.702704\n",
       "3849     366252     0.926682\n",
       "\n",
       "[3850 rows x 2 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "public = pd.read_csv(\"data/submit/1217_1.csv\")\n",
    "\n",
    "result = pd.concat([train_result, valid_result, test_result], ignore_index = True)\n",
    "result = result.drop(target, axis = 1)\n",
    "result[\"alert_key\"] = result[\"alert_key\"].astype(int)\n",
    "\n",
    "result = pd.merge(public[\"alert_key\"], result, on = [\"alert_key\"], how = \"left\")\n",
    "\n",
    "result[\"probability\"] = result[\"probability\"].fillna(0)\n",
    "\n",
    "result.to_csv(\"data/submit/1226.csv\", index = False)\n",
    "result"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### sar probability distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alert_key</th>\n",
       "      <th>probability</th>\n",
       "      <th>sar_flag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [alert_key, probability, sar_flag]\n",
       "Index: []"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_result[test_result[target] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alert_key</th>\n",
       "      <th>probability</th>\n",
       "      <th>sar_flag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [alert_key, probability, sar_flag]\n",
       "Index: []"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_result[test_result[target] == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alert_key</th>\n",
       "      <th>probability</th>\n",
       "      <th>sar_flag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>218840.0</td>\n",
       "      <td>0.976447</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>248256.0</td>\n",
       "      <td>0.975110</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>194991.0</td>\n",
       "      <td>0.973416</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>215933.0</td>\n",
       "      <td>0.970203</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>203149.0</td>\n",
       "      <td>0.969693</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>543</th>\n",
       "      <td>196191.0</td>\n",
       "      <td>0.439615</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>762</th>\n",
       "      <td>279637.0</td>\n",
       "      <td>0.303999</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>902</th>\n",
       "      <td>363033.0</td>\n",
       "      <td>0.242923</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>906</th>\n",
       "      <td>214426.0</td>\n",
       "      <td>0.240642</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1316</th>\n",
       "      <td>179789.0</td>\n",
       "      <td>0.160213</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>74 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      alert_key  probability  sar_flag\n",
       "3      218840.0     0.976447       1.0\n",
       "4      248256.0     0.975110       1.0\n",
       "5      194991.0     0.973416       1.0\n",
       "7      215933.0     0.970203       1.0\n",
       "8      203149.0     0.969693       1.0\n",
       "...         ...          ...       ...\n",
       "543    196191.0     0.439615       1.0\n",
       "762    279637.0     0.303999       1.0\n",
       "902    363033.0     0.242923       1.0\n",
       "906    214426.0     0.240642       1.0\n",
       "1316   179789.0     0.160213       1.0\n",
       "\n",
       "[74 rows x 3 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_result[valid_result[target] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alert_key</th>\n",
       "      <th>probability</th>\n",
       "      <th>sar_flag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>193308.0</td>\n",
       "      <td>0.980247</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>204193.0</td>\n",
       "      <td>0.978836</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>192503.0</td>\n",
       "      <td>0.977519</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>230638.0</td>\n",
       "      <td>0.975971</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>189123.0</td>\n",
       "      <td>0.975826</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1802</th>\n",
       "      <td>244115.0</td>\n",
       "      <td>0.283004</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2121</th>\n",
       "      <td>257134.0</td>\n",
       "      <td>0.233491</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2809</th>\n",
       "      <td>303923.0</td>\n",
       "      <td>0.179979</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3278</th>\n",
       "      <td>171770.0</td>\n",
       "      <td>0.149625</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4335</th>\n",
       "      <td>184581.0</td>\n",
       "      <td>0.094378</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>171 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      alert_key  probability  sar_flag\n",
       "1      193308.0     0.980247       1.0\n",
       "2      204193.0     0.978836       1.0\n",
       "3      192503.0     0.977519       1.0\n",
       "4      230638.0     0.975971       1.0\n",
       "5      189123.0     0.975826       1.0\n",
       "...         ...          ...       ...\n",
       "1802   244115.0     0.283004       1.0\n",
       "2121   257134.0     0.233491       1.0\n",
       "2809   303923.0     0.179979       1.0\n",
       "3278   171770.0     0.149625       1.0\n",
       "4335   184581.0     0.094378       1.0\n",
       "\n",
       "[171 rows x 3 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_result[train_result[target] == 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "X_train = train[features]\n",
    "y_train = train[target]\n",
    "\n",
    "X_valid = test[features]\n",
    "y_valid = test[target]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from imblearn.over_sampling import SMOTE, ADASYN\n",
    "oversample = SMOTE(random_state=99)\n",
    "X_train, y_train = oversample.fit_resample(X_train, y_train)\n",
    "y_train.value_counts()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Target encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import category_encoders as ce\n",
    "\n",
    "ce_target = ce.TargetEncoder(cols = cat_feats)\n",
    "X_train = ce_target.fit_transform(X_train, y_train)\n",
    "X_valid = ce_target.transform(X_valid)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.naive_bayes import ComplementNB\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "#from catboost import CatBoostClassifier\n",
    "from imblearn.ensemble import EasyEnsembleClassifier, BalancedRandomForestClassifier, BalancedBaggingClassifier, RUSBoostClassifier\n",
    "\n",
    "\n",
    "random_state = 99#None\n",
    "models = {\n",
    "    \"Logistic\": LogisticRegression(),\n",
    "    \"Bayes (Gaussian)\": GaussianNB(),\n",
    "    \"KNN\": KNeighborsClassifier(),\n",
    "    # \"SVC\": SVC(probability = True),\n",
    "    # \"Neural Network\": MLPClassifier(),\n",
    "    \"Decision Tree\": DecisionTreeClassifier(random_state = random_state),\n",
    "    \"Random Forest\": RandomForestClassifier(random_state = random_state, class_weight=\"balanced\"),\n",
    "    \"Gradient Boost\": GradientBoostingClassifier(),\n",
    "    \"XGBoost\": XGBClassifier(random_state = random_state),\n",
    "    \"LightGBM\": LGBMClassifier(random_state = random_state), # feature name should be number\n",
    "    # \"Cat Boost\": CatBoostClassifier(random_state = random_state),\n",
    "    # \"Bayes (Complement)\": ComplementNB(), # for imbalance data (X cannot be negative)\n",
    "    \"Easy Ensemble (AdaBoost)\":EasyEnsembleClassifier(random_state = random_state),\n",
    "    \"Easy Ensemble (Logistic)\":EasyEnsembleClassifier(random_state = random_state, base_estimator = LogisticRegression()),\n",
    "    # \"Easy Ensemble (SVC)\":EasyEnsembleClassifier(random_state = random_state, base_estimator = SVC(probability = True)),\n",
    "}\n",
    "\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train, y_train)\n",
    "    print(name + \" trained.\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, recall_score, precision_score, f1_score, fbeta_score\n",
    "from sklearn.model_selection import ShuffleSplit, cross_val_score\n",
    "\n",
    "#acc_bound = 0.7\n",
    "#f1w_bound = 0.5\n",
    "\n",
    "score = []\n",
    "flag = 1\n",
    "cv_flag = 0\n",
    "for key, model in models.items():\n",
    "    pred_train = model.predict(X_train)\n",
    "    pred_test  = model.predict(X_valid)\n",
    "\n",
    "    acc_train  = accuracy_score(y_train, pred_train).round(2)\n",
    "    acc_test   = accuracy_score(y_valid, pred_test).round(2)\n",
    "\n",
    "    recall_train  = recall_score(y_train, pred_train).round(2)\n",
    "    recall_test   = recall_score(y_valid, pred_test).round(2)\n",
    "\n",
    "    precision_train  = precision_score(y_train, pred_train).round(2)\n",
    "    precision_test   = precision_score(y_valid, pred_test).round(2)\n",
    "\n",
    "    f1_train = f1_score(y_train, pred_train).round(2)\n",
    "    f1_test = f1_score(y_valid, pred_test).round(2)\n",
    "    \n",
    "    if flag == 1:\n",
    "        col1 = [acc_train, acc_test, recall_train, recall_test, precision_train, precision_test, f1_train, f1_test]\n",
    "        col2 = [\"Accuracy_train\", \"Accuracy_test\", \"Recall_train\", \"Recall_test\", \"Precision_train\", \"Precision_test\", \"f1_train\", \"f1_test\"]\n",
    "    else:\n",
    "        col1 = [acc_test, recall_test, precision_test, f1_test]\n",
    "        col2 = [\"Accuracy\", \"Recall\", \"Precision\", \"f1\"]\n",
    "\n",
    "    if cv_flag:\n",
    "        # cv = ShuffleSplit(n_splits = 3, test_size = 0.2)\n",
    "        cv_scores = cross_val_score(model, X_train, y_train, cv = 3, scoring = 'accuracy')\n",
    "        cv_score = cv_scores.mean().round(2)\n",
    "        col1 += [cv_score]\n",
    "        col2 += [\"f1_cv\"]\n",
    "\n",
    "    score.append(col1)\n",
    "    \n",
    "    # if (acc_test >= acc_bound) & (f1_test >= f1w_bound):\n",
    "    col3 = sorted(list(set(y_valid) | set(pred_test)))\n",
    "    confusion = pd.DataFrame(confusion_matrix(y_valid, pred_test), index = col3, columns = col3)\n",
    "    confusion[\"Total\"] = confusion.sum(axis = 1)\n",
    "    confusion.loc[\"Total\"] = confusion.sum(axis = 0)\n",
    "\n",
    "    \n",
    "    confusion = confusion.astype(int)\n",
    "    \n",
    "    print(f\"<< {key.lstrip()} >>\")\n",
    "    print(f\"\\nConfusion Matrix:\\n {confusion}\")\n",
    "    print(f\"\\nClassification Report:\\n{classification_report(y_valid, pred_test)}\")\n",
    "    print(\"-\"*60)\n",
    "    \n",
    "index  = [i.lstrip() for i in models.keys()]\n",
    "score  = pd.DataFrame(score, index = index, columns = col2)\n",
    "score = score.sort_values([\"Recall_test\", \"Precision_test\", \"f1_test\", \"Accuracy_test\"], ascending = False)\n",
    "score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "best_model = \"Bayes (Gaussian)\"\n",
    "pred_valid  = models[best_model].predict_proba(X_valid)\n",
    "pred_valid = pred_valid[:, 1]\n",
    "pred_valid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "test_result = test[[\"alert_key\", \"sar_flag\"]]\n",
    "test_result[\"probability\"] = pred_valid\n",
    "test_result = test_result.sort_values(\"probability\", ascending = False).reset_index(drop = True)\n",
    "test_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "test_sar = int(test_result[target].sum())\n",
    "test_len = test_result[test_result[target] == 1].index[-2] + 1\n",
    "print(f\"Test total: {len(test_result)}\")\n",
    "print(f\"({test_sar} - 1) / {test_len} = {(test_sar - 1) / test_len}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6a07fcf0145f94b3f971c13d061528107de20ab7b779375f96dab9bbac6a85db"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
